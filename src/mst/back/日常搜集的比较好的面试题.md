---
title: Java面试题
date: 2024-10-14
icon: line-md:chat-filled

---

### 																			日常搜集的比较好的比较经典的面试题

写在开头：

​	这篇文章用来记录日常搜集到的比较经典、或者比较有难度的面试题



#### 一、Spring中的循环依赖

​	题目：什么是Spring中的循环依赖？如何解决？

​	Spring中的循环依赖：

​	Spring中的循环依赖就是多个Bean对象循环依赖，比如Bean A依赖Bean B ,Bean B 又依赖Bean A

​	如何解决？

​		方案一：Spring框架中使用三级循环来解决循环依赖。Spring中的三级缓存对应的就是三个Map

```java
//一级缓存
// Cache of singleton object;bean name to bean instance;
private final Map<String,Object> singletonObjects=new ConcurrentHashMap<>(256);
// 二级缓存
// cache of early singleton object;bean name to bean instance;
private final Map<String,Object> earlySingletonObjects=new HashMap<>(16);
// 三级缓存
// cache of singleton factory;bean name to ObjectFactory;
private final Map<String,ObjectFactory<?>> singletonFactories=new HashMap<>(16); 
```

​	

> 补充三级缓存：
>
> ​		一级缓存：存放最终形态的Bean。已经完成了初始化、属性赋值、实例化。我们获取Bean一般就是从一级缓存中获取Bean
>
> ​		二级缓存：存放半成品的Bean（没有完成属性填充）。一般和三级缓存配合使用，三级缓存getObject()方法得到的前期暴露对象就放到二级缓存中。可以保证AOP的时候多次调用三级缓存的getObject()的时候只会生成一个代理对象而不会生成多个代理对象。
>
> ​		三级缓存：存放ObjectFactory。调用getObject()可以生成原始的Bean或者代理对象。但是三级缓存只会对单例Bean生效。

​	

​	三级缓存解决循环依赖的大体流程：

1. Bean A中依赖了Bean B,在创建A的时候会去创建B ，但是Bean B 又依赖了Bean A,所以又需要去创建A，此时循环依赖了。
2. 在B创建A的时候，因为A还没有初始化完成，所以一级缓存和二级缓存中肯定是没有A的，所以去三级缓存中，调用getObject()去获得一个A的 **前期暴露对象**
3. 然后将A的前期暴露对象从三级缓存中删除，放到二级缓存中。那么B就将这个A的前期暴露对象注入到依赖，来解决循环依赖问题。


> 注意： 非单例的 Bean和 @Async注解 Bean是不支持使用三级缓存来实 现循环依赖的



​	方案二：使用@Lazy注解

​	被@Lazy注解注释的会进行懒加载/延迟加载。Bean A中依赖Bean B ,Bean B中依赖Bean A，但是A的构造方法使用了@Lazy注解 这个例子。@Lazy解决循环依赖的逻辑大致如下：

​	在创建A的时候，发现A依赖B，所以会创建一个B的 **代理对象** ，然后将B的代理对象注入到A中，完成A的创建。

​	然后开始执行创建B的过程，B中依赖A但是这个时候A已经创建完成了，所以B可以成功创建，不会发生循环依赖。

​	注意： 之前发生循环依赖是因为A在创建的时候去**创建了一个B对象**引发了循环依赖， **使用了@Lazy之后，A只会去创建一个B的代理对象** 。



#### 二、Bean的生命周期了解吗？

​	Bean的生命周期简单来说可以分成四个阶段：**实例化->属性赋值->初始化->销毁**

​	其中初始化的过程比较复杂，会先调用实现的Aware接口来进行增强。然后还可能调用BeanPostProcessor在初始化前后的处理。

​	其中销毁并 **不会立即将这个Bean进行销毁** 。而是会 **注册相关的回调接口** ，然后再进行销毁。



#### 三、如何来设计一个数据迁移方案？

​	首先一个大部人能够立刻想到的也是最low的方案就是： **停机迁移** 。

​	下面说一个标准的 **不停机** 的数据迁移方案：

​	一般不停机进行数据迁移的方案的流程如下：

​	①、创建目标表

​	②、用源表中的数据对目标表进行初始化：我们一般可以使用 **mysqldump** 工具进行数据的导入和导出

​	③、进行第一次的数据校验与修复：

​	在 **我们导出和导入数据的这段时间中，源表中的数据也是会变的** ，所以目标表进行初始化后我们需要进行第一次的校验和修复。比如我们可以使用表中的 **update_time** 字段在作为增量校验的标识。去查询源表中update_time大于目标表中的数据的数据，然后和目标表进行校验。 **修复数据** 的时候可以 **直接使用源表中的数据** 进行 **覆盖** 即可。

​	④、开启 **双写模式** ，先写源表。读源表，**先写源表** ，然后再写目标表，**数据以源表为准** 

​	⑤、再次进行数据校验和修复

​	在这一步也是为了保证源表和目标表中的数据保持一致，有两种方案，第一种方案是使用update_time更新时间戳来更新新的数据；第二种方案是利用源表的binlog来校验和修复目标表中的数据。

​	方案一：**使用update_time更新时间戳来更新新的数据**

​	我们可以定时查询源表和目标表中的update_time比较新的数据，然后比较源表和目标表中的数据是不是一致，如果不一致那个就用源表中的数据覆盖目标表。但是还会有一个问题就是我们 **源表中的数据删除了** 但是 **目标表中的数据还没有删除** 这个时候我们就需要一个 **反查机制** ，就是需要 **查询目标表的全部数据然后去和源表核对**，如果 **源表中不存在就在目标表中进行删除** 。

​	方案二：**通过binlog日志来进行校验和修复数据**

​	我们将binlog日志 **当做** 一个 **触发器** 。当我们 **接收到** binlog日志之后就会利用binlog中的 **主键** 或者 **唯一索引** 去 **查询源表和目标表** 中的数据，然后进行 **校验** ，如果不一致则用源表中的数据对目标表中的数据进行覆盖。

​	⑥、切换双写顺序，改成读目标表，先写目标表，然后再写源表

​	⑦、完全切换到读写都只操作目标表



#### 四、@AutoWired和@Resource有什么区别？

​	这是一个比较经典的Java面试题目。@Autowired和@Resource两个注解都可以用来注入Bean。但是两者的区别可以简单总结如下：

 1. @AutoWired是Spring提供的注解； @Resource是JDK提供的注解

 2. @AutoWired默认是通过byType进行注入的，而@Resource默认是通过byName进行注入的。下面通过一个具体的例子来帮助理解：

    有一个接口SmsService，这个接口有两个实现类分别为SmsServiceImpl1和SmsServiceImpl2

    ```java
    // 下面使用@Autowired注入是会报错的，因为默认是通过byType通过类型来进行注入，但是此时这个接口有两个实现类，所以就无法找到具体的实现类
    @Autowired
    private SmsService smsService;
    // 通过指定名称来指定对应的实现类
    @Autowired
    @Qualifier(value="smsServiceImpl1")
    
    //下面使用@Resource注入会报错，因为默认是通过name来注入，但是此时没有smsService对应名字的Bean
    @Resource
    private SmsService smsService;
    //通过指定name来注入Bean,成功注入
    @Resource(name="smsServiceImpl2")
    private SmsService smsService;
    
    ```

    3. @Autowired可以作用于方法、构造函数、字段、参数上；@Resource不可以作用于构造函数和参数上



#### 五、SpringBoot是如何实现自动装配的？

​	其实在Spring框架中就已经有了自动装配的功能，Spring Boot可以理解为通过 **SPI** 机制，做了进一步的优化和增强。

​	Spring Boot在启动的时候会去加载外部jar中的 **META-INFO** 下的 **spring.factories** 文件。外部组件可以将自己的配置放到这个文件中，Spring Boot会将里面的配置加载到Spring容器中。

​	在使用Spring Boot的时候，**核心** 是通过一个 **@SpringBootApplication注解** 实现自动装配的。这个注解其实是多个注解的复合注解，里面包含了 **@EnableAutoConfiguration** 、 **@ComponentScan** 、 **@SpringBootConfiguration** 这三个注解。

​	@SpringBootConfiguration注解其实就是@Configuration注解，允许在上下文中注册额外的bean或者导入其他配置类。

​	@ComponentScan注解是去扫描指定包下面的所有的bean,默认是扫描启动类包下的所有的类

​	**@EnableAutoConfiguration注解是开启自动配置机制**，也是Spring Boot自动装配实现主要依赖的注解

​	其实@EnableAutoConfiguration只是一个简单的注解，它底层其实是通过AutoConfigurationImportSelector类来实现的。

![](https://s3.bmp.ovh/imgs/2024/05/17/9adfb7ad5387522b.png)



#### 六、什么是TCP的粘包问题？以及如何解决

​	粘包问题： 当我们使用TCP协议进行发送消息的时候，**TCP** 是有可能会对 **消息进行分组** 的，当我们发送多条消息后，可能会出现多 **个消息的某一部分粘在了一个消息中** ，这就是TCP的粘包问题。 粘包问题的出现是 **不知道** 一个 **消息的边界** 在哪里，那就会导致 **无法** 正确的划分出一个有效的消息。

​	解决方案：一般来说有三种粘包问题的解决方案，分别是：1. 固定长度的消息 2. 使用特殊字符作为边界 3. 自定义消息结构

​	  1. **固定长度的消息** ：每个消息的长度都是固定的，当读取到这个长度之后就认为读取完了一个消息。是最简单的方案，但是不灵活，一般在实际中 **基本不使用**这种方案。

2. **使用特殊字符作为边界** ：在一个完整的消息后面添加一个特殊的字符作为结束。当读取到这个特殊字符之后就认为读取完毕了一个完整的消息。
3. **自定义消息结构** ：自定义一个消息结构，比如包含包头和消息体，包头中声明这个消息的长度，然后在消息体中存放真正的消息，当读取到这个结构体之后，先读取包头，根据包头中的消息长度去消息体中读取数据。



#### 七、当我们在浏览器中输入一个地址到页面显示的过程是什么？

​	1.**组装HTTP请求** 

​	当我们在浏览器中输入url的时候，浏览器会先将 **url进行解析** ，生成发送给web服务器的请求信息，**生成HTTP请求**

​	2.**DNS解析**

​	我们在url中输入的一般都是域名，那么如何通过这个 **域名** 得到对应的 **服务器的IP地址**，就需要 **DNS解析** 。DNS解析根据输入的域名得到对应的目标IP地址

​	3.**通过协议栈进行包装**

​	在经过DNS解析之后得到了IP地址，然后就通过 **协议栈** 层层对HTTP请求进行 **包装**，主要是添加 **各种协议** 的 **头信息**

​	4.**添加TCP包头信息**

​	**HTTP需要依赖TCP协议进行传输**。在这一步中TCP包头中包含了 **源端口** 和 **目标端口** 。 然后与目标进行 **三次握手** 来进行 **连接** 。最后在请求信息中 **添加上TCP包头信息** 。

​	5.添加IP包头信息

​	**TCP需要依赖IP协议进行传输**。在这一步中IP包头中包含了 **源IP地址** 和 **目标IP地址** 。最后在请求中添加上了 **IP包头** 信息。

​	6.添加MAC包头信息

​	MAC包头信息中包含了 **源MAC地址** 和 **目标MAC地址** 。MAC协议通过 **ARP协议** 来找到目标MAC地址

​	7.**网卡**

​	网卡主要负责将 **数字信息转成电信号** 。网卡还会继续对请求信息进行添加。在请求的开头加上 **报头和起始帧分界符**，在请求的末尾加上 **检测错误的帧校验序列**

​	8.**交换机**

​	交换机负责将网络包原封不动的转发到路由器。

​	9.**路由器**

​	将网络包转发到下一个路由器或者目标设备。最终得到目标设备。 注意 **MAC包头的目的就是找到路由器** ，路由器在接收到网络包后会将 **MAC包头信息删除** 。

​	10.服务端接收到网络包之后进行‘扒皮’

​	服务端接收到网络包之后进行扒皮，然后执行对应的操作，将结果发送给客户端。客户端收到之后进行页面渲染

​	

#### 八、TCP如何保证传输的可靠性的？

​	1.**基于数据块传输** ：TCP会将应用数据分为TCP认为最合适的块来进行传输。

​	2.**对失序数据包进行排序和去重** ：TCP为了保证不丢包，会给每一个包一个序列号，有了序列号就可以对这些数据包进行排序和去重。

​	3.**校验和** ：通过校验和来判断数据在传输过程中是否发生变化。

​	4.**重传机制** ：当数据包发生丢包或者延迟的时候，TCP有重传机制，包括基于计时器的重传机制、基于ACK的重传机制

​	5.**流量控制** ：TCP连接的每一方都有一个固定大小的缓冲区，TCP的接收方只允许发送方发送接收方缓冲区大小的数据，流量控制TCP主要是使用**滑动窗口**来实现的。

​	6.**拥塞控制** ：TCP的发送方可以根据接收方的缓冲区大小或者网络的拥塞情况来控制自己的发送速度，TCP是通过**拥塞窗口**来实现的。发送方自己维护一个拥塞窗口，其中发送方发送的数据大小是**拥塞窗口和滑动窗口的最小值**。



#### 九、TCP是如何实现流量控制的?

​	TCP使用**滑动窗口**来实现流量控制，主要是来控制发送方发送数据的速率，让接收方来得及接受，从而让发送方和接收方处于一种**动态平衡**。

​	客户端和服务器端都有一个**发送窗口**和**接收窗口**，其中**发送窗口**由四部分组成：

​	1.**已经发送并且被接收方确认的TCP段**

​	2.**已经发送但是还没有被接收方确认的TCP段**

​	3.**未发送并且接收方准备接收的TCP段**

​	4.**未发送但是接收方不准备接收的TCP段**

​	**接收窗口**由三部分组成：

​	1.**已经接收并且确认的TCP段**

​	2.**等待接收但是允许发送方发送的TCP段**

​	3.**不可接收且不允许发送方发送的TCP段**

​	接收窗口是由接收方**动态调整**的。



#### 十、Redis中的有序集合ZSet底层为什么使用跳表而不使用红黑树、B+树、平衡树

​	与平衡树相比，跳表创建的初始就是为了 **避免** 平衡树中插入和删除的时候进行 **旋转维护平衡** 的问题。跳表的实现也比平衡树简单，迅速。

​	与红黑树相比，在插入和删除的时候跳表 **不需要** 进行 **旋转和染色** 来 **维护黑平衡** ，跳表比红黑树实现简单。并且跳表的 **范围查询** 比红黑树效率高。

​	B+树主要是用于数据库中存储索引的，主要目的是 **减少磁盘IO的次数** 来提高查询的效率。但是对于Redis来说，是把数据存放在内存中的，所以 **不会存放大量的数据** ，所以没有必要使用B+树来存放索引。另外B+树在 **插入** 数据的时候可能会发生节点的 **分裂** 和 **合并** ，而跳表只需要在对应的索引位置添加元素，然后再 **随机维护一定高度的索引** 即可。

> ​	补充 : 跳表中每级索引的个数是下一层的个数的一半，跳表中索引的高度为 h=（log 2^h） -1



#### 十一、Redis过期Key删除策略

​	Redis中针对过期Key的删除策略有两个，第一个是 **惰性删除** 、第二个是 **定期删除** 。

​	惰性删除：  **只会在查询key的时候** 对数据进行检查，如果key过期了才会删除。这种策略对CPU比较友好，但是会导致很多过期的key一直在内存中没有删除，所以对内存不是很友好。

​	定期删除： Redis会 **定期去扫描一部分key** ,然后检查是不是过期，如果过期就会将key删除。这种策略对内存比较友好，但是对CPU的压力比较大。其中在定期删除策略有很多的细节，比如 **定期删除** 的 **频率** 可以通过配置文件中的 **hz** 参数来设置，hz=10代表每秒执行10次定期删除策略。另外hz参数可以配合**dynamic-hz** 参数来使用，会 **自适应** 确定hz的值。并且在执行定期删除策略的时候会收到两个参数的影响，一个是 **执行时间的阈值** 另一个是 **过期key的比例** 。 如果本次定期删除策略执行的时间 **超过** 了 **执行时间阈值** 那么就会 **中断** 本次的定期删除。 如果本次定期删除中的过期key的比例 **超过** 了 **过期key的比例阈值** 的话就会重复执行定期删除。 如果本次定期删除的过期key的比例 **小于** 过期key的比例的时候，就会中断本次定时删除。 

​	Redis中默认使用的是 **惰性删除+定期删除配合** 的策略，这样可以对CPU和内存进行一个平衡。



#### 十二、什么是Redis的缓存击穿、缓存穿透、缓存雪崩？以及针对这三个问题的解决方法？

​	缓存击穿:高并发访问下，**某个热点key过期了**，导致大量的请求来到了数据库层。解决方案： 合理设置热点数据的过期时间；加锁然后查询数据库再将数据缓存起来

​	缓存穿透：访问缓存中一定不存在的key，由于缓存没有命中，大量的请求来到了数据库层。解决方案： **对于不存在的数据缓存null值** ，但是要设置合理的过期时间；使用 **布隆过滤器** ；对用户IP进行 **限流** 。

​	缓存击穿和缓存穿透的区别：缓存穿透是访问**一定不存在于缓存中的数据** 导致查询直接穿透到了数据库层；缓存击穿是访问一个存在的key,**在key过期的一刻**，**同时有大量的请求** ，大量的请求来到了数据库层。

​	Redis缓存雪崩一般是 **Redis服务不可用** 或者Redis中 **大量key同时过期** ，导致**大量请求来到了数据库**，然后把数据库干宕机了，从而导致了服务器崩溃。解决方案： **随机设置过期时间** ，在基本的过期时间上再加一个随机值；**Redis服务使用集群部署** 比如Sentinel或者Cluster方式；提前预热，将 **热点数据** 提前缓存到redis中。



#### 十三、Redis可能发生阻塞的原因？

​	①、执行O(N)时间复杂度的命令

​	②、查询大Key

​	③、删除大Key

​	④、Redis执行完命令之后还没来得及写到AOF的时候Redis宕机了可能会阻塞后续其他命令的执行。

​	⑤、使用SAVE命令来生成RDB，而没有使用bgSave命令来生成RDB文件，会阻塞Redis主线程

​	⑥、AOF刷盘的时候导致阻塞

​	⑦、AOF重写的时候导致阻塞。因为在AOF重写的时候，新的Redis操作会放到AOF重写缓存区中，然后再将AOF重写缓冲区中的数据追加到AOF文件的末尾。这个过程可能会导致阻塞。

​	⑧、清空Redis

​	⑨、Redis扩缩容

​	⑩、CPU竞争，因为Redis是很消耗CPU的，如果你的Redis和对CPU消耗比较大的服务在同一台机器上的时候会对Redis的性能有很大的影响，可能发生阻塞。

​	⑪、 网络问题导致Redis发生阻塞



#### 十四、Redis和Memcached的异同

​	相同：

​	两者都是基于内存的，性能都很高

​	两者都有过期key的删除策略

​	不同：

​	Redis支持更多的数据结构，而Memcached只支持k-v键值对

​	Redis支持持久化，重启之后数据不会丢失，而Memcached不支持持久化，重启后数据会丢失

​	Redis支持发布订阅模型、事务、lua脚本等，而Memcached不支持

​	Redis使用单线程执行命令，采用IO多路复用的模型。而Memcached是多线程，非阻塞IO复用的网络模型

​	Redis支持惰性删除、定期删除的过期key删除策略。而Memcached只支持惰性删除



#### 十五、你知道缓存模式有哪些吗？

​	1.**旁路缓存策略**

​		写：**先写db，然后删除cache**

​		读：**读cache,如果存在直接返回；如果cache没有的话读db,然后将结果放入cacahe中**，最后返回

​	2.**读/写穿透策略**

​		写：**先查cacahe,如果cache中不存在直接更新db;如果cache中存在则更新cache,然后再更新db**

​		读：**先查cache，有就直接返回；如果cache中没有则查询db然后写入cache,再由cache返回**

​	3.**异步缓存写入策略**

​		写：先写入cache中，然后**由cache异步批量写入db**

​		读：**先读cache，如果存在直接返回；如果cache不存在则读db然后写入cache，最后返回**



#### 十六、请你介绍一下MySQL中的几种日志

​	MySQL中有三个日志是比较重要的，分别是 **undo log** 、**redo log** 、**binlog** 。

​	undo log 是MySQL中用来进行 **回滚** 的日志，当一个事务开启的时候，在这个 **事务中** 进行的操作都会记录对应的undo log中，比如我们执行了一个INSERT 操作，那么undo log 中就记录一个 DELETE 操作，我们执行一个 DELETE 操作，undo log 中就记录一个 INSERT 操作。undo log主要是用于我们在事务提交之前让这个事务进行了 **回滚** ，那么我们就需要依靠undo log中的日志将数据进行 **还原** ，还原到事务开始之前的时候。**当事务成功提交之后，本次事务的 undo log 也就没有了** 。

​	redo log 日志中记录了我们在MySQL中进行的 **增删改** 操作，**事务开始之后** 我们将对应的增删改操作都记录在redo log中，如果事务还 **没有提交** 但是发生了 **宕机** ，那么MySQL重启之后需要依靠redo log将这个事务中的操作复现回来。当然redo log的写入语义也是比较复杂的，具体来说就是： redo log 有一个 **buffer pool** ,写入redo log 的时候会**先**将数据写到redo log 的  **buffer pool**  中，然后**再**从buffer pool中刷新到**操作系统的 page cache中** ，然后再由刷盘机制**最终刷到磁盘中**。所以说如果redo log 没有成功刷新到磁盘中就宕机了，那么这个过程中的数据就会丢失了。

其中redo log刷新磁盘中的时机有对应的参数：**innodb_flush_log_at_trx_commit** 

innodb_flush_log_at_trx_commit=0： **每秒** 刷新到磁盘一次，直接由buffer pool刷新到磁盘

innodb_flush_log_at_trx_commit=1:  **每次事务提交之后**，将数据刷新到磁盘上。

innodb_flush_log_at_trx_commit=2： **事务每次提交的时候刷新到page cache中** ，然后**由操作系统决定什么时候将数据刷新到磁盘**

​	binlog: **二进制操作日志文件**。里面记录了MySQL的增删改操作，主要是用于进行MySQL**出现故障之后进行数据恢复** 以及 **主从同步** 。其中binlog的写入是 **和redo log的写入结合在一起** 组成一个 **两阶段提交** 的，**先写入redo log** ,这个阶段是redo log的 **prepare阶段**，**成功之后写入binlog ,写入成功之后，再进行redo log 的提交** 。 binlog 也有对应的 **刷新到磁盘中的时机**，由参数 **sync_binlog**决定　

**sync_binlog=0:由操作系统决定什么时候将binlog中的数据刷新到磁盘中**

**sync_binlog=N:N个事务提交之后将数据刷新到磁盘中** 。

​	总结： undo log是用来进行**事务回滚**的日志，redo log是**事务执行过程中**宕机之后进行**数据恢复**的，**保证事务的持久化**，binlog是用来MySQL**故障之后** **数据恢复和主从同步**的。

​	

#### 十七、你知道什么是值传递、什么是引用传递吗？Java使用的是什么？

​	值传递就是将实参进行 **拷贝** ，生成一个 **副本** ，然后将副本传给方法，如果方法中 **对实参进行了修改** 也 **只会修改副本** ，**原始的** 实参的值是 **不会变** 的

​	引用传递 **不会** 进行 **拷贝** ，会将原始的实参传给方法，所以方法中如果 **对实参进行修改** 会 **直接影响到原始的实参** 

​	**Java使用的是值传递** 。对于 **基本类型** 的实参来说，对实参进行 **拷贝** ，传递的是 **副本的值** ， **会生成副本** 。如果是 **引用对象** 的话，会将实参的 **引用对象在堆中的*地址* 进行拷贝** ，同样 **也会生成副本**。



#### 十八、你做过哪些MySQL的优化吗？

1. **添加索引** 。比如对联查作为条件的字段创建索引。排序使用的字段添加索引。尽可能的使用 **联合索引**。
2. **尽量避免多表join联查** 。
3. 避免使用select * 。 因为使用select * 查询可能导致无法使用覆盖索引。会消耗更多的CPU。会传输更多的字段，增加网络传输的开销。
4. **使用子查询来优化深层分页** 。 比如 select id from tableA where id>(select id from tableA limit 100000,1) limit 10;
5. **更新和插入使用批量操作** 。
6. **查询慢SQL** 。然后不断调整索引以及SQL语句来提高效率。
7. **避免索引失效** 。**like查询不要%开头** 。 **不要使用OR并且两边有一个没有索引** 。**不要** 在 **索引列** 上进行 **类型转换** 或者 **使用函数** 。**in后面的列表不要太大** ，不然容易走全表扫描。
8. **使用合适的字段类型** 。



#### 十九、ElasticSearch的优化你知道吗？

1. 物理优化，使用更好的机器，更大的内存。
2. ES中 **只保存** 会进行 **检索的字段** ，不进行检索的字段不保存，这样既可以节省内存空间，又可以提高检索效率。
3. ES使用 **批量提交替代单条提交** ，比如一个场景是将 **数据库中的数据同步到ES中** ，那么我们可以批量提交。比如 **从MQ中消费消息保存到ES中** 的时候也可以使用批量消费，批量提交。
4. **优化分页查询** ，使用search_after来优化。
5. **冷热数据分离** 。**时间比较久** 或者 **搜索少** 的数据放到 **性能差点** 的ES机器中，**热数据** 放到 **性能高的ES机器** 中。其中我们可以使用ES的 **生命周期管理** 来进行冷热数据分离。
6. **调大refresh的时间间隔** 。 ES会定期将内存中的数据刷新到磁盘中，增大这个时间间隔可以在一定程度少减少性能开销。
7. 擅于使用keyword，不走分词器，可以提高查询效率
8. 开启慢查询配置来定位慢查询
9. 将多个字段使用copy_to合并为一个
10. 避免大型文档存储，单个文档不要超过100M



#### 二十、说一下什么是数据库的三范式？

​	**第一范式** ：表中的各个**列**是**不可分割**的基本数据项。

​	**第二范式** ：**在第一范式的基础上** ，表中所有的**非主键属性完全依赖于主键** 。

​	**第三范式** ：**在第二范式的基础上** ，各个**非主键属性之间相互独立** ，**不存在传递依赖函数** 。



#### 二十一、你知道哪些线程安全的集合类？

1. ArrayBlockingQueue
2. LinkedBlockingQueue
3. ConcurrentHashMap
4. ConcurrentLinkedQueue
5. CopyOnWriteArrayList



​	ArrayBlockingQueue和LinkedBlockingQueue的区别：①ArrayBlockingQueue底层是基于**数组**实现的，而LinkedBlockingQueue底层是基于**链表**实现的；②ArrayBlockingQueue是**有界队列**，**创建时需要指定大小**，而LinkedBlockingQueue初始化的时候可以指定大小也可以不指定大小，如果**不指定大小的话默认是Integer.MAX_VALUE**也就是无界队列；③ArrayBlockingQueue的**生产和消费使用同一把锁** ，而LinkedBlockingQueue**生产和消费使用的是不同的锁**④ArrayBlockingQueue需要**提前分配数组内存**，而LinkedBlockingQueue是**动态分配链表节点内存** ⑤ArrayBlockingQueue支持公平和非公平两种锁访问机制，而LinkedBolckingQueue只支持非公平的锁访问机制

​	

#### 二十二、说一下HashMap的初始容量，以及扩容机制？为什么在创建的时候指定了集合大小之后会变成2的幂次方？

​	HashMap在创建的时候如果我们没有指定容量大小的时候，**默认大小是16** 。

​	HashMap在每次进行 **扩容** 的时候每次变成 **原来容量的两倍** 。

​	HashMap在 **创建** 的时候如果我们 **指定了容量** 的大小的话，那么会 **调整为2的幂次方**。 目的是： 我们得到 **散列值** 之后一般需要对 **数组长度** 进行**取模** 运算，然后得到的值才是对应的位置。**hash%length** 的结果和 **(n-1)&hash** 的结果是一样的，但是 **&运算的效率比%运算的效率高很多** 。



#### 二十三、说一下什么是数据的零拷贝技术？

![](https://s3.bmp.ovh/imgs/2024/06/13/94635ad25bf318ad.png)

> 补充： 什么是DMA拷贝。 DMA拷贝是在两个内存区域之间直接进行数据拷贝，而不需要依赖于CPU而是依赖于硬件特性。



#### 二十四、文件读写和网络发送接收的最小单位是字节，那么为什么IO流中还要出一个字符流呢？

​	1、字符流是JVM虚拟机将字节流转换而来的，这个过程是比较耗时的

​	2、如果我们不知道字符的编码格式的话，使用字节流的话读取出来的数据可能是乱码



#### 二十五、常见的字符编码格式所占的字节数？

​	utf8中**英文占1个字节**，**中文占3个字节**。

​	Unicode中**所有字符都占2个字节**

​	gbk中**英文占1个字节**，**中文占2个字节**



#### 二十六、JVM中如何判断一个对象是死亡对象？如何判断一个常量是废弃常量？如何判断一个类是无用的类？

​	判断一个对象死亡的方法：

 1. 引用计数法：当一个对象有一个引用的时候这个对象的引用计数器就加一，当一个引用释放掉这个对象的时候计数器就减一，当这个对象的引用计数器=0的时候说明没有任何地方引用它了，就可以判断对象死亡，可以进行垃圾回收了。

 2. 可达性分析算法：从一个“GC ROOTS”出发，然后向下搜索，如果GC ROOTS可以达到这个对象，说明这个对象是有用的，不能进行回收，如果一个对象不能从GC ROOTS到达的话，说明这个对象是无用的了，就可以进行垃圾回收了。

    可以作为GC ROOTS的对象有：

    - 虚拟机栈中引用的对象
    - 本地方法栈中引用的对象
    - 方法区中静态属性引用的对象
    - 方法区中常量引用的对象
    - JNI引用的对象
    - 被同步锁引用的对象



​	判断一个常量是废弃常量的方法：比如堆中的字符串常量池中存在字符串"abc"，如果没有任何String对象引用该字符串常量的话，说明这个常量是废弃常量

​	

​	判断一个类是无用类的方法：如果想要**判定一个类是无用的类** ，必须同时满足下面的三个条件：

1. **该类没有任何的对象实例**
2. **该类的ClassLoader已经被回收**
3. **该类对应的Class对象没有任何引用，也就是不能在任何地方通过反射访问这个类中的方法**



#### 二十七、说一下什么是类加载中的双亲委派模型？

​	类加载器分为 **启动类加载器** 、**扩展类加载器** 、**应用程序类加载器** 、**自定义类加载器** , 其中**启动类加载器是最顶级的类加载器** 。

​	当我们在进行类加载的时候，会进行下面的几个步骤：

​	step1: 首先判断当前类是不是已经被加载过了，如果已经被加载了就直接返回，如果没有被加载的话，才会尝试进行加载。

​	step2: 在进行类加载的时候，也 **不是** 自己这个类加载器直接加载，而是将类加载 **委托给父类加载器** 进行加载，然后父类加载器也执行step1和step2

​	step3: 如果父类加载器反馈 **无法加载** 这个类的时候， **子类加载器** 才会尝试进行加载这个类

​	step4: 如果所有的类加载器都没有办法加载这个类的时候会 **抛出异常**

​	如果我们想要**打破双亲委派模型**的话，我们在自定义类加载器中，继承ClassLoader后**重写loadclass()方法** ，因为类在进行类加载的时候是会调用父类加载器的loadclass()方法的，所以我们可以**在这个方法中自定义我们自己的逻辑** 。

​	双亲委派模型的**好处** ：

1. **防止类的重复加载**
2. **防止JAVA核心API被篡改** 





#### 二十八、Java对象的创建过程是什么？

​	step1: **类加载检查** 

​	step2: **分配内存** 

​	在类加载检查的时候就可以确定对象需要的内存大小，进行内存分配的时候有两种方法，一种是： **指针碰撞** ，另一种是 **空闲列表** 

​	指针碰撞:适用于 **堆内存规整** 的情况下。使用过的内存移动的一边，没有使用过的内存移动到另一边，中间使用分界指针来划分，我们只需要**移动** 这个 **分界指针** 就可以了

​	空闲列表：适用于**堆内存不规整** 的情况下。虚拟机会维护一个列表，记录哪些内存是可以使用的，从可以使用的内存中选择一块分配这个对象即可。

​	**注意** ：在分配内存的时候会有 **线程安全** 问题，因为同一个类的对象可能同时被多个线程new,所以一般使用 **CAS+重试** 的机制来保证线程安全。

​	step3: **初始化零值** 

​	保证了在 **不赋初始值** 的情况下就 **可以使用** ，初始化对象类型的零值

​	step4: **设置对象头** 

​	step5: **执行init方法** 



#### 二十九、说一下什么是Java中的JMM?

​	JMM是Java内存模型，**不是真实存在的** ，**而是一组规范** 。

​	**主内存** 中存放 **共享变量** ，其他的线程不能直接操作主内存中的变量，而是先将主内存中的变量**拷贝**到自己的工作内存中。然后在自己的工作内存中对这个共享变量进行修改，再将**修改后的结果写回到主内存中** ，然后**其他的线程**要拿主内存中**最新** 的共享变量的值。

​	JMM保证了多线程下共享变量的**可见性** 、**原子性** 、**一致性** 。

​	其中使用**volatile** 来保证可见性，一旦**修改了共享变量后** 就会**立刻刷新到主内存中** ，并且**每次读取的时候** 都**去主内存中读取最新的值** 。

​	使用了 **synchronized** 来进行**互斥** ，保证了在**退出同步块的时候刷新数据到主内存中** ，**进入同步块之前先从主内存中读取数据** 。



#### 三十、==和equals()的区别？

​	对于**基本数据类型**来说，**==比较的是值** ，对于**引用类型** 来说， **== 比较的是引用的地址** 。**equals()**方法是Object类中的方法，如果我们的类**没有重写父类Object中的equals()方法** 的话，比较的时候其实和 == 一样，**比较的是引用地址** ，如果重写的话会比较值。而且**equals()方法不能用于比较基本数据类型** 。String类中的equals()方法就是对Object类中的equals()方法进行了重写。

​	并且**一般重写equals()方法必须重写hashCode()方法** , 因为**相同的对象的hashCode()的结果一定是一样的** ，如果我们没有重写的话，会出现equals()方法判断两个对象是相等的，但是两个对象的hashCode()结果不同的问题。



#### 三十一、CAS的底层原理是什么？

​	CAS的底层原理是**Unsafe类+自旋**  来实现的。其中Unsafe类调用底层的native方法，来基于**cpu的原子指令** 保证了原子性。

​	CAS的优点就是对于读多写少的场景，比起悲观锁来性能更好。 缺点是：①**有ABA问题 ** ②**自旋循环时间长开销大**  ③ **只能保证一个共享变量的原子操作** 



#### 三十二、说一下什么是分布式系统中的CAP理论和Base理论？

​	CAP理论是：**一致性** 、**可用性** 、**分区容错性** 的简称。

​	在现在的互联网环境中，分区容错性是必须的，所以我们必须要保证P，在保证P的前提下，一致性和可用性只能选择一个。也就是AP或者CP，比如Zookeeper就是CP，Euraka是AP。

​	Base理论是：**基本可用** 、**软状态** 、**最终一致性** 的简称。其实可以理解为对CAP中的一致性和可用性的一种**折中**。没有保证强一致性，但是保证了数据的**最终一致性** 。数据会在**一定的时间内**达到最终的一致。

​	其中Base理论中的**基本可用**是在一些情况下可以**牺牲系统的部分可用性** ，但是不代表系统不可用，比如**损失接口响应时间**、**部分接口不可用** 等等。

​	其中**软状态** 就是**多个节点之间数据不一致的状态** 。

​	其中**最终一致性**就是数据会在**一定的时间内**达到最终的所有节点上**数据一致** 的结果。



#### 三十三、介绍一下你知道的分布式系统的共识算法？

​	分布式系统中的共识算法就是**分布式系统**中**多个节点** 就一个**提案** **达成共识** 的算法。最早的分布式系统的共识算法是Paxos算法，使用最多的是Raft算法。 Raft算法是在Paxos算法的基础上演进而来的。

​	Paxos算法：Paxos算法其实就是提出了**共识算法**的思想，核心就是**多个节点就一个提案达成共识**。 所有的节点分成三个角色：**提议者** 、**接受者**、**学习者** 。 首先由**提议者**就一个问题**提出议案**，然后**发送给所有的接受者**，**接受者**对这个提议进行**投票** ，同意或者拒绝，当**半数以上**的接受者就一个提案**达成共识**的时候，那么这个提案就**通过**了，由**学习者**去**执行这个提案** ，并且最终**返回给客户端**。

​	但是由于Paxos算法只是提出了思想，但是实现比较复杂，也没有具体落地。所以出现了目前使用比较多的，基于Paxos算法的简化以及落地方案：Raft共识算法。

​	Raft算法中，分为**Leader** 、**候选人** 、**Follower** 三个角色。其中每个Leader都对应自己的一个**任期** ，并且每个Follower都有一个**随机** 的超时时间，如果到达自己的超时时间内，**没有收到Leader或者候选人的消息的时候** ，就会**由Follower变为候选人** ，**任期加一** ，然后**给所有的节点** 发送选举请求，当收到**过半以上的节点**发来的同意请求后，就会**由候选人变成Leader节点**。

​	并且对于Raft算法来说，日志**entry只能由Leader来进行生成** ，然后Follower负责收到Leader发来的entry后对自己的日志文件进行更新。



#### 三十四、介绍一下UUID和雪花算法，以及两者的区别？

​	UUID是全球唯一id的简称，算法的底层是基于**时间+MAC地址**来生成一个唯一的**32个字符串**的ID。

​	优点：使用简单

​	缺点：依赖于时间，所以**可能发生重复ID**的问题、**无序** 、没有业务性、不安全（基于MAC地址，可能会泄漏MAC地址）、消耗存储空间大。

​	补充：使用UUID作为数据库的主键ID有什么**缺点** ：

​		①、**存储空间较大** ，占用128位空间大小。

​		②、可能会消耗更多的网络带宽。

​		③、无序ID，**排序性能较差** ，可读性也较差。

​		④、**索引效率差** ，在往数据库中插入数据的时候会**更容易发生页分裂** ，**影响插入的性能** ，不利于高写的场景。

​	

​	雪花算法：原始的**雪花算法是由64位组成** ，分别为：

​	**符号位   时间戳   机房ID   机器ID   序列号** 

​	**1位       41位      5位             5位        12位** 

​	优点：生成速度快、有序ID、灵活性好，可以对雪花算法的各个位进行更改。

​	缺点：发生时钟偏移后会生成重复的ID；依赖于机房ID和机器ID，所以发生扩缩容的时候容易出现问题；ID有序可能会导致业务数据泄漏。

​	UUID和雪花算法两者的区别就是：UUID是依赖于时间和MAC地址来生成的。而雪花算法是依赖于符号位、时间戳、机房、机器号、序列号来生成的。



​	

#### 三十五、请你手写一个双重检查机制的单例模式？

```java
    public class Singleton {
        private static volatile Singleton uniqueInstance;

        public Singleton() {

        }

        public static Singleton getUniqueInstance() {
            if (uniqueInstance == null) {
                synchronized (Singleton.class) {
                    if (uniqueInstance == null) {
                        uniqueInstance = new Singleton();
                    }
                }
            }
            return uniqueInstance;
        }
    }
```

​	为什么要进行两次检查？**第一次检查**是为了**避免**已经创建对象之后还进行了**无意义的加锁**；**第二次检查**则是为了**避免重复创建对象**。



#### 三十六、Mybatis中推荐使用#{}而不是${}，为什么，使用#{}比起使用${}有什么优点？

​	#{}的好处有：

1. **可以防止SQL注入** 。使用#{}，Mybatis会**自动将参数值进行转义**，防止发生SQL注入。而使用${}的话，Mybatis会直接将**参数拼接到SQL中** ，会发生SQL注入问题。
2. **可以完成自动类型转换** 。使用#{}，Mybatis可以根据参数类型完成**自动的类型转换**，而使用${},Mybatis**不会进行自动类型转换** ，只会进行SQL的拼接，所以会发生**类型不匹配**的问题。
3. **可读性与可维护性更好** 。使用#{}可读性和可维护性更好。



#### 三十七、MyBatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？

​	B标签是**可以**定义在A标签的后面的，Mybatis中所有的**标签都是顺序解析的** ，所以当解析到A标签的时候，发现A标签需要B标签，但是B标签还没有解析，所以A标签会被标记为**未解析标签** ，然后会**继续解析后面的标签** ，当解析完后面的所有标签后，也就是B标签也被解析完毕了。会**重新解析**所有标记为**未解析的标签** ，此时A标签就会被解析成功了。

​	

#### 三十八、说一下HTTPS是如何保证通信的安全性的？

​	首先HTTPS协议是基于**SSL/TLS协议**的，而SSL/TLS协议又是基于**TCP协议**的。HTTPS在进行通信的时候**底层**其实是使用的**对称加密算法** ，只是为了保证对称加密算法密钥的安全性，**对于对称加密算法的密钥进行了非对称加密**。

​	其中对于对称加密算法的密钥的加密过程涉及到了第三方机构**CA机构** ，流程是这样的：

1. CA机构会提供一个**证书文件** ，这个证书文件中**包含** 了**服务器的公钥**和一些其他的数据信息。然后CA机构对这个证书文件使用**HASH算法**生成一个文件**Hash值** 。进一步再使用**CA的私钥**对这个证书文件的**Hash值进行加密**生成一个数字签名，发送给服务器。
2. 服务器将这个数字签名和证书文件发送给客户端。
3. 客户端使用CA机构的**公钥**对数字证书进行解密，得到文件的Hash值。同时使用相同的HASH算法对证书文件进行运算，判断生成的Hash值和解密出的Hash值是不是相同，相同才被认可，否则认为文件被篡改了。
4. 使用文件中的**服务器的公钥**对自己生成的用来进行**对称加密的密钥**进行加密，然后将加密后的数据发送给服务器。
5. 服务器对这个数据使用**自己的私钥进行解密**，可以得到最终进行对称加密通信的时候使用的密钥。
6. 以后的通信中都使用这个密钥进行加解密通信。



#### 三十九、说一下MySQL中主键索引和普通索引的区别？

1. 主键索引的每个值都**不能重复** ，是**唯一**的；而普通索引是**可以有重复的** ，**不是唯一的**
2. 主键索引的值**不能为null** ;而普通索引的值**可以为null**
3. 如果我们在指定了表中的主键，那么插入数据的时候会自动创建一个唯一的索引；而普通索引需要手动创建
4. 主键索引使用了**聚簇索引** ，意味着**索引顺序和物理存储顺序是一致**的；而普通索引是**非聚簇索引** ，意味着**物理存储顺序和索引顺序不一致**



#### 四十、说一下什么是回表？什么情况下会发生回表操作？

​	回表是指：通过索引找到对应的索引记录之后，依然需要**再次访问数据库** 来获取完整的行数据。

​	出现回表操作有两种情况：1. 命中了非聚簇索引 2. 覆盖索引失效

1. **命中了非聚簇索引** ：当查询使用了非聚簇索引，**查询到的列不能完全包含在索引中**，需要**借助索引中的主键**再次去数据库中查询完整的行数据。
2. **覆盖索引失效**：如果查询的列，**没有完全被索引覆盖**，需要再次去数据库中查询完整的行数据。

​	

#### 四十一、数据库的索引结构使用的是B+树而不是哈希表、AVL树、红黑树、二叉搜索树、B树，是因为什么？

​	哈希表对于**范围查询和排序查询的性能是非常差的** ，每次获取一个数据都需要进行一次回表。

​	二叉搜索树在元素有序插入的情况下**会变成一个链表** ，这将会严重降低查询性能。

​	AVL树在插入和删除的时候会通过旋转来保证自身的平衡性，所以插入和删除的性能比较差。另外AVL中的每一个节点只能存储一个数据，而查询每个节点都需要进行一次磁盘的IO过程，如果我们查询的数据在多个节点的时候将会发生多次的磁盘IO，性能较差。

​	红黑树是黑节点平衡的，所以在插入和删除的时候也是会通过旋转来保证黑节点平衡的，所以插入和删除的时候的性能较差。另外和B+树比起来红黑树的树高还是比较高的，可能会导致查询某些数据的时候会发生多次的磁盘IO，查询性能下降。

​	B树的每个节点既可以存储key又可以存储value而B+树的非叶子节点只可以存储key,叶子节点才可以存储key和value,所以B树相对于B+树来说高度更高，查询数据的时候可能会发生更多的磁盘IO，查询性能较低。

​	B树在进行查找的时候可能还没有到叶子节点就已经查询到数据了，而B+树的查询一定是从根节点到叶子节点的过程，所以B+树的查询性能比B树更加稳定。

​	B+树的叶子节点之间有链表相连，而B树是独立的，所以B树的范围查询性能比B+树更差。



#### 四十二、讲一下JVM的内存模型？

​	Java的内存模型大体可以分为两个部分，一个是运行时数据区域，另一部分是本地内存。

​	其中运行时数据区域又分为：堆（线程共享）、程序计数器（线程私有）、虚拟机栈（线程私有）、本地方法栈（线程私有）

​	本地内存又分为：元空间、直接内存

![](https://s3.bmp.ovh/imgs/2026/01/21/4764cd3a824ce5d5.png)



![](https://s3.bmp.ovh/imgs/2026/01/21/0d2adf3b4ec4f668.png)





#### 四十三、TCP如何实现拥塞控制的？

​	TCP的发送方通过**拥塞窗口**来实现拥塞控制。TCP拥塞控制使用四种算法来实现：**慢开始** 、**拥塞避免** 、**快重传** 、**快恢复**

​	



#### 四十四、说一下什么是MySQL的MVCC机制？以及原理？

​	MVCC是**多版本并发控制**的缩写。目的是**提高**数据库的**并发性**。

​	当一个**事务执行读命令**的时候，会使用**快照**读取。在**事务开始**的时候，生成一个快照，**其他事务的操作**对于当前这个事务来说是**不可见**的。并且在生成的这个快照中存放着当前事务开始的时候，其他**活跃的事务(已经开启但是事务还没有提交的事务)的id列表**，这些事务id对应的事务相对于当前这个事务来说就是不可见的，**即使活跃的事务提交了，当前事务也是看不到的**。所以当前视图中的数据是不会收到其他事务的影响的。 当这个事务开始的时候，如果**某个数据行有多个版本**，那么会**读取不晚于当前时间的最新的数据**。

​	当一个事务执行**写操作**的时候，会给当前某行数据**开启一个新的数据版本**，然后将数据插入到这个新的数据版本中。新版本的数据的修改不会影响到原始的数据版本。

​	而且MVCC会**定期的清除老版本的视图**的。

​	MVCC机制的实现需要借助于**Read View、隐藏字段、undo log**

​	对于**可重复读**和**读已提交**隔离级别来说，MVCC机制读操作**生成快照的时间是不同的**，对于**读已提交**隔离级别，**每次select之前都会生成一个快照** 。对于**可重复读**隔离级别来说，**事务开启之后，*第一次*select之前才会生成快照**。

​	**可重复读**隔离级别使用**MVCC+临键锁**其实可以保证**不出现幻读**的问题。比如对于**普通的select读取**，使用MVCC机制，事务开启之后，第一次select之前生成Read View，一直持续到事务提交。在此过程中如果有其他的事务对数据进行了插入，**对于当前这个事务来说也是不可见的** 。对于**select...for update、insert、update**这种**当前读**的命令来说，读到的行使用**行锁** ，同时使用**间隙锁**来锁住读到的行的**附近的范围数据**来保证不出现幻读。



#### 四十五、说一下堆中的分代结构？

​	Java堆分为新生代和老年代。其中新生代又分为Eden、幸存者0区（from区），幸存者1区(to区)，其中幸from区和to区是会不断变化的，谁上次是from区，那么下次就是to区。



#### 四十六、Minor Gc 和 Full GC 有什么不同呢？什么时候会触发Minor Gc？什么时候会触发Full Gc?

​	其中**Minor Gc针对的是新生代**，而**Full Gc**针对的是**整个Java的堆内存**。

​	当我们创建一个对象的时候，**如果Eden的空间无法放下时**，会触发一次Minor GC。

​	**触发Full GC**的情况有如下几种：

1. 当创建一个大对象的时候，是会直接放到老年代中的，如果此时老年代中的空间无法放下的话，就会触发Full GC
2. 每次在执行**Minor GC之前**，都会先判断**老年代中的空闲空间是否能够存放新生代中的所有对象**，如果不能并且老年代中的**空闲空间小于历次新生代晋升的平均大小**的时候，会触发Full GC
3. 当元空间大小到达设置的阈值的时候，会触发Full GC



#### 四十七、说一下TCP的三次握手过程？

​	1.**第一次握手** ：Client发送带有**SYN标志**的消息给Server,然后Client进入**SYN_SEND状态**

​	2.**第二次握手** ：Server发送带有**SYN+ACK标志**的消息给Client,然后Server进入**SYN_RECV状态**

​	3.**第三次握手** ：Client发送带有**ACK标志**的消息给Server，然后双方进入**连接状态**



#### 四十八、为什么必须要进行三次握手？

​	TCP建立连接进行三次握手的根本目的是保证通信双方发送和接收消息都是正常的。

​	第一次握手，**Client既不能确定自己发送正常，也不能确定自己接收正常**。Server可以**确认自己接收正常，对方发送正常**，但是**不能确定自己发送正常**。

​	第二次握手，**Client可以确认自己发送和接收都正常**。**Server不能确认自己发送正常**

​	第三次握手，**Server可以确认自己发送和接收都正常** 。

​	

#### 四十九、说一下TCP的四次挥手过程？

​	1.**第一次挥手** ：Client给Server发送一个带有FIN标志的消息，Client进入FIN_WAIT-1状态

​	2.**第二次挥手** ：Server给Client发送一个带有ACK标志的消息，Server进入CLOSE_WAIT状态，Client进入FIN_WAIT-2状态

​	3.**第三次挥手** ：Server给Client发送一个带有FIN标志的消息，Server进入LAST_ACK状态

​	4.**第四次挥手** ：Client给Server发送一个带有ACK标志的消息，Server进入CLOSE状态，Client在等待2*MSL时候后没有收到Server的消息，变成CLOSE状态



#### 五十、常见的垃圾收集算法有哪些？

​	1. **标记-清除算法**

标记清除算法分为两个阶段，第一个阶段是标记阶段，对所有的不会被回收的对象进行标记；第二个阶段是清除阶段，会将所有没有被标记的对象进行回收

缺点：会产生大量的内存碎片；收集效率比较低

​	2. **复制算法**

将内存一分为二，当回收的时候，将所有不会被回收的对象复制到另一半内存中，然后一次性将一半的内存进行回收。

缺点：内存空间减少，每次只能使用一半的内存；不适合老年代，大对象的复制过程很慢。

​	3. **标记-整理算法**

分为两个阶段，第一个阶段是标记阶段，对所有存活的对象进行标记；第二个阶段是整理阶段，会把所有存活的对象移动到一端，然后将后面的所有空间释放。

​	4. **分代垃圾收集算法**

针对不同的区域使用不同的垃圾收集算法，比如针对新生代可以使用标记-复制算法；针对老年代可以使用标记-清除/标记-整理算法



#### 五十一、常见的垃圾收集器有哪些？

​	**串行垃圾收集器**

​	**单线程**的垃圾收集器，只有一个线程来执行垃圾收集的任务，同时进行垃圾收集的时候会**将用户的工作线程暂停** ，所以会导致**长时间的STW（stop the world）**。其中串行垃圾收集器对**新生代**使用了**标记-复制**算法；对**老年代**使用了**标记-整理**算法。	

​	**并行垃圾收集器**

​	并行垃圾收集器是**多线程**垃圾收集器，对**新生代**使用**标记-复制**算法；对**老年代**使用**标记-整理**算法。

​	**CMS垃圾收集器**

​	第一款真正意义上的**并发**垃圾收集器，垃圾收集和用户线程**基本**上**同时工作 ** 。采用了**标记-清除**的算法。但是更加复杂，具体如下:

​	**初始标记** ：暂停其他的所有线程，标记**与root直接相连**的所有对象，速度很快

​	**并发标记** ：同时开启用户线程和标记过程，在这个过程中用户线程可能会不断的改变引用域。所以会**记录下发生引用变化的地方**

​	**重新标记** ：对发生引用变化的地方再次进行标记

​	**并发清除** ：清除所有没有被标记的对象。

​	缺点：对CPU资源敏感、容易产生**内存碎片**、无法处理**浮动垃圾**

> 补充 ： 浮动垃圾是指 CMS 垃圾收集器在**重新标记**和**并发清除**的过程中，**用户线程是一直在执行的**，用户线程可能会**创建对象**或者**更新对象的引用域**把**原来可达的变成了不可达对象**，这些**新对象**或者**不可达对象**在**本次**垃圾收集的过程中不会被回收，而是需要等到下一次的垃圾回收，被称为浮动垃圾。

​	CMS垃圾收集器在jdk9中被标记为过时，在jdk14中被移除了。

​	**G1垃圾收集器**

​	G1垃圾收集器适合**多核CPU**和**大内存**的机器上，是jdk9之后的默认垃圾收集器。既可以保证尽可能少的STW的时间，又可以保证较高的吞吐量。

​	G1垃圾收集器从**整体**上看是基于**标记-整理**算法的，从**局部**看是基于**标记-复制算法**的。

​	G1垃圾收集器有**可预测**的**停顿时间**模型，我们可以指定**在M毫秒的时间段内进行垃圾收集的时间不能超过N毫秒** ，实现原理是G1垃圾收集器在后台维护了一个**优先列表** ，在我们规定的垃圾收集时间内**优先对性价比最高的区域进行垃圾回收** 。



#### 五十二、说一下MySQL的架构，以及一条SQL语句的执行过程是什么？

​	MySQL架构分为两层，一个是**Server层**，另一个是**存储引擎层**。其中存储引擎层是**插件式可插拔**的。

​	Server层分为**连接器**、**查询缓存（MySQL8之后移除）**、**分析器**、**优化器**、**执行器**。

​	首先客户端连接MYSQL的时候，会经过**连接器进行身份认证和权限认证**。

​	对于一条**查询SQL**来说，**先判断是不是有权限**，如果**没有权限报错**，有的话**先经过查询缓存**，查询缓存中SQL语句作为key,结果集作为value,**如果存在的话直接返回，不存在的话经过分析器**。分析器对SQL语句进行**词法分析**和**语法分析**，**再到达优化器** ，由优化器选择一个MYSQL认为**最优的执行方案**，当执行方案确定之后，**到达执行器**，执行SQL,去**调用存储引擎的接口**，然后**返回数据** 。

​	对于一个**更新SQL**来说，先进行**权限认证**，如果**没有权限就报错**，有的话直接到达**分析器**，进行**词法分析**和**语法分析** 。然后经过**优化器**来确定方案，最后由**执行器**去调用**存储引擎**的接口。但是对于更新SQL来说，会**记录日志**，**执行器**会记录**binlog日志**，**Innodb存储引擎层**会记录**redo log日志** 。其中redo log和binlog日志的记录组成了**两阶段提交**，先由存储引擎执行redo log的prepare，然后由执行器记录binlog，完成之后存储引擎再提交redo log日志。

​	如果redo log prepare完成，binlog记录完成，但是宕机了，恢复后会通过下面的两种方式来**保证数据一致性**：

1. 判断redo log日志是否完整，如果redo log日志完整，就直接提交
2. 如果redo log 日志只prepare没有commit,这个时候会检查binlog是不是完整，如果binlog完整的话redo log commit，否则直接回滚。



#### 五十三、说一下Explain中各个列代表什么？

​	1.**id**

​	SELECT标识符，**同一个id的话从上往下依次执行**，**如果id不同的话，id越大优先级越高** 。

​	2.select_type

​	查询类型，如果是普通查询为simple,如果包含子查询的话，外层查询标识为Primary,如果是UNION查询的话，标记为UNION；子查询中的第一个SELECT标识为SUBQUERY

​	3.table

​	查询的表名

​	4.possible_keys

​	查询**可能用到的索引**

​	5.type

​	查询执行的类型，值有system>const>range>index>ALL

​	**const** ：代表表中最多只有一行匹配的数据，一次查询就能查到

​	**range** : **对索引进行了范围查询**

​	**index**: **查询遍历了整棵索引树**

​	**ALL** : **全表扫描**

​	6.key

​	查询真正用到的索引

​	7.ken_len

​	索引的长度

​	8.rows

​	查询实际扫描的行数

​	9.ref

​	**在查询过程中使用索引时，索引列与哪个值或表达式进行比较**

​	**const** : 索引列与常量进行比较

​	**column_name**:索引列与某一列进行比较

​	**NULL** :索引列没有任何参考值

​	10.filtered

​	经过过滤后，**留下的行数与总行数的比值**，如果filtered值越小说明我们过滤掉的数据越多，索引越好。



#### 五十四、什么是自动拆装箱？以及什么时候会触发拆箱和装箱的操作？

​	装箱：将基本数据类型变成对应的包装类型。

​	拆箱： 将包装类型变成对应的基本数据类型

​	注意： 如果频繁的拆装箱的话，也会严重影响程序的性能，所以要避免频繁的拆装箱。

​	自动装箱举例： public void print(Integer val)    调用的时候使用print(10)

​	自动拆箱举例： public void print(int val)   调用的时候 Integer val=10;print(val)



#### 五十五、接口和抽象类有什么相同和不同？

​	相同: 

1. 都不能被实例化
2. 都可以定义抽象方法
3. 都可以定义有默认实现的方法



​	不同：

1. 接口定义行为，实现一个接口就具备了接口中的所有行为，而抽象类多用于代码复用，强调的是所属关系
2. 一个类只能继承一个抽象类，但是可以实现多个接口
3. 接口中的成员变量只能使用public static final修饰，必须有初始值；抽象类中的成员变量默认default,子类可以重新定义或者重新赋值



#### 五十六、什么是深拷贝、浅拷贝、引用拷贝?

​	深拷贝：将整个对象完全复制，包括这个对象所包含的内部对象

​	浅拷贝：在堆上创建一个对象，如果原对象内部有引用，则直接复制这个引用

​	引用拷贝: 两个不同的引用指向同一个对象



#### 五十七、Java中常见的IO模型？重点说一下NIO模型

​	BIO: 同步阻塞IO模型

​	当**应用程序**调用**read**请求后，**阻塞等待**，直到数据**由内核拷贝到用户空间**中。

​	NIO: 同步非阻塞IO模型

​	应用程序调用**select/epoll**来询问内核**数据是否准备就绪**了，当内核将数据准备就绪后**给应用程序发送一个ready请求**，然后**应用程序再去调用read请求**，但是在数据由内核拷贝到用户空间的时候依然是阻塞的。

​	使用I/O多路复用模型，核心组件是**Buffer**、**Selector** 、**Channel** 。

​	其中每个客户端**读写数据**会直接**和buffer进行数据交互**，而每个buffer又对应一个channel,多个channel**注册**到一个Selector上，我们可以通过一个线程来操作selector就能实现管理多个client。

​	**读数据的时候是将Channel中的数据读到Buffer中，写数据的时候是将数据从Buffer写到Channel中，Channel是一个全双工的数据通道** 。

​	Selector是基于**事件驱动**的IO多路复用模型。Selector会**轮询监听**注册在其上的Channel,当一个Channel发生了**接收连接** 、**连接完成** 、**准备好进行读取** 、**准备好进行输入数据** 的事件后，Selector就会监听到，然后将这个Channel加入到**就绪集合**中，然后执行对应的IO操作。

![](https://s3.bmp.ovh/imgs/2024/07/31/ce9822c6abd8db2d.png)

​	AIO: 异步IO模型

​	异步非阻塞IO模型，当应用程序发起read请求后，**不阻塞**而是继续去执行别的任务，当内核将数据拷贝完之后，再通过**回调**来通知应用程序继续执行当前任务。



#### 五十八、什么是Java中的反射？以及反射的优缺点是什么？

​	Java中的反射让我们可以在运行时分析对象，并可以执行对象中的方法,获取对象中的属性。

​	优点： 可以让我们的代码更加灵活；为各种框架提供开箱即用的功能提供了方便。

​	缺点： 性能稍微差点；会带来安全问题，比如**反射会逃脱泛型参数的安全检查** 。



#### 五十九、什么是SPI？SPI与API的区别是什么?

​	SPI是服务提供者接口，将服务**调用方**和服务**实现方**进行**解耦**，提升程序的扩展性、可维护性。

​	**调用方**和**实现方**之间一般都是通过**接口**来进行连接，所以我们在调用方和实现方之间增加了一个接口层。

​	API的**接口是由实现方来定义和实现的**，属于实现方 。而SPI的**接口是由调用方来定义的** ，属于调用方，不同的实现方按照调用方给的这个规则进行实现即可。



#### 六十、说一下TCP/IP四层模型和OSI七层模型

​	TCP/IP四层模型：网络接口层、网络层、传输层、应用层

​	OSI七层模型： 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层



#### 六十一、你知道Java中的哪些语法糖？

​	增强for循环、try-with-resource、lambda表达式、枚举、泛型、自动拆装箱、可变长参数



#### 六十二、AtomicInteger底层是如何保证原子性的？

​	AtomicInteger底层保证原子性是**无锁**的，通过**volatile**修饰value,保证可见性，然后通过unsafe类来使用**CAS+重试机制**保证了原子性。



#### 六十三、说一下CAS的问题？

 1. **ABA问题**

    如果我们的**V初始值为A**，然后在我们进行更新之前，由**另一个线程进行了修改改成了B又改回了A**，那么当我们要进行提交的时候发现V还是A就认为V没有被修改过，**可以成功提交**，这就是ABA问题

    2. **循环时间长开销大**

    CAS更新失败后会**不断的进行重试**，开销还是比较大的

    3. **只能保证一个共享变量的原子操作**

    CAS只能保证**一个**共享变量的原子操作，如果涉及到**跨共享变量**的场景，CAS是**无法保证原子性**的



#### 六十四、什么是偏向锁？

​	偏向锁是JVM中的一种锁优化策略，主要来提高单线程环境下的锁性能。偏向锁可以减少单线程环境下的锁获取和释放。

​	当一个线程第一次获取锁的时候，JVM会将对象头中的锁标记为偏向模式，并将线程的ID记录在对象头中。

​	对于已经偏向的锁，持有锁的线程再次访问资源的时候，不需要获取锁

​	偏向锁的持有线程退出同步块的时候，不需要显式的释放锁，因为锁已经偏向该线程了。

​	如果有其他线程尝试获取偏向锁的时候，偏向锁会升级为轻量级锁或者重量级锁



#### 六十五、说一下synchronizd的底层原理？

​	synchronized是**基于JVM层面**的。并且针对synchronized修饰代码块和修饰方法的原理有所不同。

​	**synchronized修饰代码块** ，通过**monitorenter**和**monitorexit**指令来标识，同步代码块的**起始位置**和**结束位置**。基于对象监视器来实现的。

​	**synchronized修饰方法** ，通过**ACC_SYNCHRONIZED** 标志来标识这是一个同步方法。如果是**实例方法**会**尝试获取实例对象的锁**，如果是**静态方法**会尝试**获取当前class的锁** 。



#### 六十六、说一下线程池的几个核心参数是什么？

1. 核心线程数
2. 最大线程数
3. 工作队列
4. 存活时间
5. 时间单位
6. 拒绝策略
7. 线程工厂



#### 六十七、说一下线程池的工作流程是什么样子的？

​	首先当一个任务到达的时候如果工作线程还有空闲的话，直接交给空闲的工作线程来工作，如果工作线程满了，先判断工作队列是不是已满，如果没有满就放在工作队列中，如果工作队列满了，会判断线程池中的最大线程数是不是达到了设置的值，如果没有达到那么就会启动线程去执行队列中的任务，然后把任务放在队列中；如果线程数达到了最大线程同时队列也已经满了，则会执行拒绝策略。

![](https://s3.bmp.ovh/imgs/2024/07/18/146fed88fe886397.png)



#### 六十八、CountDownLatch和CyclicBarrier的区别是什么？

1. CountDownLatch是**一次性**的，CyclicBarrier是可以**重复使用**的
2. CountDownLatch用于到**计数器达到0**的时候，继续执行；而CyclicBarrier则是多个线程**同时**达到**某个屏障**的时候继续执行
3. CountDownLatch多用于**一次性**的等待操作；而CyclicBarrier多用于**多次同步**的场景



#### 六十九、为什么不能把服务端发送的 ACK 和 FIN 合并起来，变成三次挥手？

​		因为当服务端接收到客户端发来的FIN标志消息后，给客户端返回一个ACK标志的消息是告诉客户端，我知道你要关闭连接了。但是**服务端可能依然有数据需要进行传输**，当服务端把消息传输完毕之后，才会给客户段发送一个FIN标志的消息，告诉客户端我没有要发送的数据了，可以关闭连接。

​                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                

#### 七十、什么是泛型？使用泛型的好处是什么？什么是泛型擦除机制？

​	泛型是Java中的一个特性。

​	使用泛型的好处是：①可以增强代码的可读性和稳定性②编译器在编译的时候对泛型参数进行类型检测，我们可以指定参数的类型是什么

​	**泛型擦除** ：编译器在**编译**的过程中，会将所有的**泛型都擦除** ，这就是泛型擦除机制。比如会将**T类型擦除为Object类型** ，会将**T extends xxx类型擦除为xxx类型**。

​	擦除是为了**不创建新的类型**，**降低**虚拟机启动时的**开销** 。

​	有了**泛型擦除机制** ，为什么还要使用泛型而不直接使用Object类型呢?

​	1.使用泛型可以在**编译**的阶段完成**类型检测**

​	2.编译器可以帮我们将返回结果进行自动的**类型转换**

​	3.使用Object类型的话，需要自己**手动实现强制类型转化** ，增加了编码的复杂度，降低了代码的可读性

​	4.泛型可以使用**自限定类型** ，比如 T extends Comparable



#### 七十一、JDK动态代理和CGLIB动态代理的区别？

​	JDK动态代理**只能代理实现了接口的类**或者**接口** ，而**不能代理没有实现接口的类** 。而CGLIB动态代理可以代理没有实现接口的类。

​	**CGLIB动态代理** 的底层其实是**生成**一个**被代理类的子类**，然后来实现对目标类的代理。所以CGLIB**无法代理**被final修饰的类和方法

​	JDK动态代理的性能比CGLIB动态代理的性能更高。



#### 七十二、静态代理和动态代理的区别是什么？

​	**静态代理**会在**编译**的时候将对应的**接口** 、**实现类** 、**代理对象**加载成为class文件；而**动态代理**是在**运行**的时候生成**类字节码**，然后**加载到JVM中** 。

​	静态代理的**灵活性**比动态代理**差很多**。如果我们要在一个接口中增加一个方法，那么**对应的接口和实现类都需要进行修改**；动态代理比较灵活，可以**直接代理实现类** ，并且**不需要**针对**每一个目标类都创建一个代理类** 。



#### 七十三、HTTP协议是无状态的，那么应该如何保存用户状态？

​	使用**Session**来保存用户状态，最经典的场景就是购物车，因为HTTP协议是无状态的，添加购物车的时候我们不知道是哪个用户来添加的，所以我们一般是由**服务器端**生成一个Session,使用这个Session来**标识** 、**跟踪**用户。**客户端**将Session信息保存在**Cookie**中进行用户的追踪。如果**Cookie被禁止了** ，一般是通过**URL重写**，**将SessionID写到URL的后面** 。



#### 七十四、说说HTTP1.0和HTTP1.1的区别？HTTP1.1和HTTP2.0的区别？HTTP2.0和HTTP3.0的区别

​	HTTP1.0和HTTP1.1的区别：①HTTP1.0是**短连接**，HTTP1.1是**长连接**②HTTP1.1增加了**更多的状态码**③HTTP1.1增加了**更多的缓存策略**④HTTP1.1可以节省带宽，HTTP1.0不能只传输对象中的一部分，**只能将整个对象传输**，而HTTP1.1是**可以只传输对象的一部分的**，并且HTTP1.0**不支持断点续传**

​	HTTP1.1和HTTP2.0的区别：①HTTP2.0使用了**多路复用**，多个请求可以使用**同一个TCP连接**，而HTTP1.1每个请求都需要一个独立的连接②HTTP1.1只能对**body进行压缩**，**不能**对**header进行压缩**，而HTTP2.0可以对header进行压缩③HTTP2.0使用**二进制帧**的格式进行传输，而HTTP1.1使用**文本格式**进行传输④HTTP2.0支持**服务器推送**，我们可以将多余的信息一起推送给客户端，而HTTP1.1不可以

​	HTTP2.0和HTTP3.0的区别：①HTTP2.0是基于**TCP协议**的，而HTTP3.0是基于**QUIC协议**的，底层是UDP的改进②HTTP2.0需要**三次握手**，而HTTP3.0只需要**一次握手**③HTTP2.0多个请求复用一个TCP连接，如果一个请求发生了丢包问题会**阻塞**其他的请求，而HTTP3.0一个连接建立多个独立的数据流，各个数据流之间不影响，发生丢包问题不会发生阻塞④HTTP3.0发生丢包、延迟等网络问题后可以**更快的进行恢复和重传**



#### 七十五、Cookie和Session的区别？

​	**Session**是**服务器**用来**记录用户状态**的，是由**服务器生成和存储**的，更加**安全**。

​	**Cookie**是保存在**客户端**的，如果使用Cookie的话**敏感数据不要保存在Cookie中**或者进行**加密保存**，然后由**服务器进行解密**。



#### 七十六、Kafka消息消费失败后会不会卡住？

​	Kafka消息消费失败后，**不会卡住** ，当**达到重试次数**后依然无法处理的话，就会**跳过这个消息**，继续消费后面的消息。Kafka中**默认重试次数为10次**，并且**重试时间为0**，也就是**立即重试**。我们可以引入死信队列，将重试后依然无法成功消费的消息放到死信队列中，然后进行人工干预。



#### 七十七、ElasticSearch中keyword和text的区别是什么？

​	**keyword不走分词器**，而**text走分词器**，并且keyword的查询效率更高。



#### 七十八、DNS服务器有哪些？

​	1.**根DNS服务器** ：全世界有**13组**，**记录顶级域DNS服务器的IP地址** 。

​	2.**顶级域DNS服务器**：比如com、net、org、edu, **记录权威DNS服务器的IP地址** 。

​	3.**权威DNS服务器**

​	4.**本地DNS服务器** ：每个互联网服务提供商都有一个自己的本地DNS服务器，当主机发起DNS请求后，该请求发到本地DNS服务器上然后起着一个代理的作用，将DNS请求发到DNS层次结构中。



#### 七十九、说一下ArrayList的扩容机制？

​	当我们调用ArrayList的无参构造方法的时候，默认是创建了一个空数组，当我们**放进去第一个元素的时候才扩容为10**，之后如果超过ArrayList的容量的时候，每次**扩容为原来容量大小的1.5倍左右**。当我们往ArrayList中添加元素的时候，**先判断添加之后的容量是不是会超过当前容量**，如果超过就会执行扩容。

```java
int newCapacity=oldCapicity+(oldCapacity>>1);
```



#### 八十、HashMap为什么线程不安全？

​	**JDK7**的HashMap在**多线程**中会发生**扩容导致死循环**、**数据丢失**问题，JDK8之后虽然没有了扩容导致死循环问题，但是**依然存在数据丢失问题**。

​	**JDK7**在**多线程扩容**的时候采用的是**头插法**，会导致链表中的节点指向错误的位置，形成了**环形链表** ，导致查询数据的时候发生了死循环，**JDK8**之后将头插法改成了**尾插法**来避免了死循环问题。

​	数据丢失问题举个例子：有两个线程1，2，**同时执行put操作**，线程1在插入数据的时候，判断发生了哈希冲突，此时CPU时间片结束了，线程1挂起来，**线程2**判断发生了哈希冲突，解决后**先完成了数据的插入**，此时线程1又获得了CPU时间片，因为之前已经完成了哈希冲突的判断了，直接插入数据，导致线程2插入的数据被线程1插入的数据覆盖了。



#### 八十一、ConcurrentHashMap为什么key、value不能为null?

​	主要是因为**二义性**的问题。对于**多线程环境**下，我们**不能使用ConcurrentHashMap的containskey(key)来判断这个key是不是存在** ，所以如果我们key、value为null,我们**无法判断本身就不存在还是存在就是null**

​	但是对于HashMap来说，key是可以作为null的，因为**单线程环境**下是**可以使用containsKey(key)来判断是不是存在这个key**的。



#### 八十二、ThreadLocal的 key 是**弱引用**，那么在 ThreadLocal.get()的时候，发生**GC**之后，key 是否为**null**

​	在ThreadLocal.get()的时候，其实在**调用这个方法的时候是存在强引用的**，所以此时**发生GC之后，key是不会被回收的**，是**不会变成null的**，但是ThreadLocalMap中的key是ThreadLocal的**弱引用**，所以如果我们**没有调用get()方法**的时候发生了GC的话，**key是可能被回收变成null的** ，此时**会出现key为null**，但是value不为null的情况，如果这种ThreadLocalMap多的话，就会造成**内存泄漏** 。



#### 八十三、说一下ThreadLocalMap中的Hash算法?

​	**每创建一个ThreadLocal对象**，这个**ThreadLocal.nextHashCode**就会增加一个**斐波那契数** ，然后使用这个**斐波那契数作为哈希因子** ，然后会让**哈希值分布的更加均匀** 。



#### 八十四、说一下ThreadLocalMap是如何处理哈希冲突的？

​	因为ThreadLocalMap**底层没有使用链表** ，所以在发生哈希冲突的时候使用的是**开放寻址法** 。当通过哈希算法计算哈希值来确定**slot槽位** ，如果这个slot槽位已经有数据了，如果entry中的**key和当前的key相等的话** ，直接**进行更新** ；如果entry中的key和当前的key**不同**则会向后扫描，**如果碰到了key相同的entry进行更新**，如果没有碰到key相同的entry碰到了**slot槽位null的话** ，**直接插入** 。



#### 八十五、说一下ThreadLocalMap的两种过期key的清除方式？

​	ThreadLocalMap中的**过期key**的清除方式有两种，**探测式清除** 、**启发式清除** 。

​	探测式清除，启发式清除都是**遍历每个slot然后寻找key为null需要被清除的entry** ,然后进行清除。但是探测式清除和启发式清除的**执行时机**是不同的，探测式清除是在执行get(),set(),rehash()方法的时候会进行触发。而**启发式清除可以在任何时候触发** ，不一定是在扩容和rehash的时候继续触发，所以可以更灵活的管理内存。



#### 八十六、说一下ThreadLocalMap的扩容机制？

​	当我们在执行**ThreadLocalMap.set()** 方法的时候**可能会触发清除** ，清除之后如果**entry的数量超过了阈值**,即size>=threshold，（补充：**threshold=len*2/3**)。然后会**触发rehash()方法** ，在执行rehash()的时候会进行**过期key的清除** ，如果清除完成之后**size>=3/4threshold的话** ，则会**触发扩容** ，**扩容成原来容量的2倍** 。



#### 八十七、CompletableFuture的底层原理？

​	CompletableFuture实现了**Future**和**CompletionStage**两个接口，其中Future接口是**异步编程**中的一种**设计模式** ，我们可以得到异步任务的结果，CompletionStage可以将一个任务分为**多个阶段或者步骤** ，然后可以将这些阶段和步骤**编排组合**起来完成一个任务。

​	所以CompletableFuture是基于这两个接口来实现的。



#### 八十八、什么是通配符？通配符的好处是什么？

​	通配符是**？** 。**泛型类型是固定的** ，某些场景使用起来不灵活。通配符可以**允许类型参数变化** ，用来解决**泛型参数无法协变**的问题。

​	

#### 八十九、通配符？和常用的泛型T有什么区别？

​	1.**T可以用于声明变量或常量，而？不可以**

​	2.**T在编译期间会被擦除为Object，而?用于捕获具体类型**

​	3.**T一般用来声明泛型类和方法，而？一般用来作为泛型方法的调用代码或形参**



#### 九十、说一下什么是上边界通配符和下边界通配符？

​	**上边界通配符**：**extends**指定传入的类型实参必须是指定类型的**子类** 。比如<? extends Person> 指定实参比如是Person的子类

​	**下边界通配符** ：**super**指定传入的类型实参必须是指定类型的**父类** 。比如<? super Employee> 指定实参必须是Employee的父类



#### 九十一、泛型有哪些限制？

​	1.**只能声明不能实例化T泛型变量**

​	2.**不能用static修饰泛型变量**

​	3.**泛型参数不能是基本数据类型，必须是Object的子类**，所以需要用对应的包装类型

​	4.**不能实例化泛型数组**



#### 九十二、什么情况会导致@Transactional注解失效

​	1.@Transactional注解其实是基于Spring AOP来实现的。如果我们的**@Transactional注解加在了非public方法上** ，会导致@Transactional注解失效。

​	2.**手动捕获异常但是没有抛出异常** ，会导致@Transactional失效

​	3.**@Transactional标注的方法内部调用了同一个类中的其他@Transactional注解标注的方法**



#### 九十三、说一下MySQL主从复制的过程是什么？

​	1.**主库将数据库中的变化写入binlog中**

​	2.**从库连接主库**

​	3.**从库创建一个io线程请求获取主库更新的binlog**

​	4.**主库创建一个binlog dump线程来发送binlog,从库的io线程负责接收binlog**

​	5.**从库的io线程将接收到的binlog写入到relay log中**

​	6.**从库的SQL线程读取relay log同步数据到本地**



#### 九十四、什么是水平分库、什么是垂直分库、什么是水平分表、什么是垂直分表？

​	**垂直分库**：**将单一数据库按照业务进行划分，每个业务使用单独的数据库**

​	**水平分库**：**把一个数据表按照一定的规则拆分到不同的数据库中，每个库放在不同的服务器上**

​	**垂直分表**：**将一个表按照不同的列进行拆分，拆成多个表**

​	**水平分表**： 将一个多行的表按照一定的规则拆成多张表，比如1~30w放在一张表，30w~60w放在另一张表



#### 九十五、常见的分片算法有哪些？

​	1.**哈希算法** ：根据分片键进行哈希运算，确定分表位置，数据随机分布，分布的较均匀

​	2.**一致性哈希算法** ：相比于哈希算法有更好的扩展性

​	3.**范围分片** ：按照特定的范围区间来进行分配数据。

​	4.**地理位置分片** ：根据地理位置来进行分片



#### 九十六、如何减少数据库的主从延迟问题？

​	1.**从库使用主库性能一致或者更好的机器**

​	2.**避免使用大事务和慢sql**，将一个大事务拆成**批量操作**，对慢sql进行**优化**

​	3.**增加网络带宽**

​	4.**从库的数量应该合理安排**，**不要设置太多的从库** ，如果有太多的从库，可以对从库进行**分层**，让上层的从库再将数据同步到下层从库

​	5.从库在进行数据同步的时候既需要执行主从的写操作，又要执行到来的读操作，所以会消耗很多CPU资源，所以我们可以**增加缓存**或者**使用一主多从的架构**来减轻单一从库的读写压力。



#### 九十七、为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？

​	因为在第四次挥手是客户端给服务端发送ACK标志的消息，服务端可能没有收到，导致服务端一直给客户端发送带有FIN标志的消息，如果客户端在2*MSL内再次收到了服务端发来的FIN标志的消息后，会重新发送带有ACK标志的消息，并重新等待2 * MSL时间，**防止服务端没有收到ACK而不断给客户端发送FIN** 。



#### 九十八、Redis持久化策略有哪些？详细说一下AOF的流程是什么？

​	Redis的持久化策略有三种，**RDB、AOF、RDB+AOF混合模式**。

​	AOF的流程：1.**命令追加append到AOF缓冲区中** 2.AOF缓冲区调用write将缓冲区中的内容写到**操作系统缓冲区**中 3.系统缓冲区调用**fsync**将系统缓冲区中的数据**持久化到磁盘中** 。



#### 九十九、AOF持久化方式有哪些？

​	AOF的持久化方式就是fsync的时机，主要有三种：

​	1.**appnedfsync always**: 主线程write后立刻调用fsync进行刷盘

​	2.**appendfsync everysec:** 主线程调用write后立刻返回，由后台线程每秒调用fsync进行刷盘

​	3.**appendfsync no** : 主线程调用write立即返回，由操作系统自己决定什么时候调用fsync进行刷盘

​	

#### 一百、AOF追加文件为什么在执行完命令之后而不是在执行命令之前？

​	1.避免了语法检查，命令执行后就不需要进行语法检查了

​	2.不会阻塞命令的执行

​	缺点：

​	1.会阻塞后面的命令的执行

​	2.如果命令执行完后还没有写入aof文件中发生了宕机，那么会丢失数据



#### 一百零一、AOF 校验机制了解吗？

​	AOF会对**文件内容**使用**CRC64算法**计算得到一个数字，**保存在文件的末尾** 。当我们启动Redis的时候，会**对AOF文件中的内容进行CRC64算法计算得到一个校验码**，然后**用这个校验码和AOF文件末尾的校验码进行比较** ，如果不一致会报错。

> 补充：CRC64算法是一种**64位循环冗余校验算法**。多用于检测数据在传输和存储过程中是否出现错误。



#### 一百零二、AOF和RDB的优缺点是什么？

​	AOF的优缺点:

​	优点：可读性好；可以做到秒级持久化；

​	缺点：生成的aof文件体积比较大；数据恢复的时候其实是依次执行aof文件中的命令，所以恢复时间比较久

​	RDB优缺点：

​	优点：生成的rdb文件是压缩后的二进制文件，体积小；数据恢复速度快

​	缺点：不同版本的redis之间可能存在RDB文件的兼容性问题；无法做到秒级持久化；可读性差；



#### 一百零三、ES中的各种概念你知道吗?

​	index: 相当于MySQL中的表

​	document: 相当于MySQL中的行

​	mapping: 相当于MySQL中表的定义

​	filed: 相当于MySQL中的列



#### 一百零四、为什么Redis会有内存碎片问题？

​	1.Redis在申请内存的时候**会申请比需要存储的内存更多的内存**，比如实际需要存储的内存需要100MB，那么Redis可能会向操作系统申请200MB的内存

​	2.**频繁的修改Redis中的数据也会导致内存碎片的产生** 。因为当Redis中的键删除的时候，Redis不会轻易将内存归还给操作系统



#### 一百零五、TCP和UDP的区别是什么？

​	1.**TCP是面向连接的** ，建立连接需要三次握手，释放连接需要四次挥手，而UDP不是面向连接的。

​	2.**TCP可以保证可靠传输**，而UDP不能保证可靠传输，只负责发出去，发出去之后就不管了。

​	3.**TCP是有状态的**，会记录消息是否发送了，是否被成功接收了。而**UDP是无状态的**

​	4.**TCP的首部开销比UDP大**

​	5.**TCP的传输效率比UDP低**

​	6.**TCP只支持点对点通信**，而UDP支持**一对一**、**一对多**、**多对一**、**多对多**

​	7.**TCP面向字节流，UDP面向报文**



#### 一百零六、说一下使用TCP的协议和使用UDP的协议有哪些？

​	使用TCP的协议：**HTTP协议**、**FTP协议**、**SMTP协议**、**SSH协议**、**POP3协议**

​	使用UDP的协议：**HTTP3.0协议**、**DHCP协议**、**DNS域名系统（其实它同时支持TCP和UDP）**



#### 一百零七、IPV4和IPV6的区别是什么？

​	1.IPV4和IPV6的最主要的区别就是IPV6可以分配更多的IP地址。

​	2.IPV4是用.分割的，而IPV6是用:或者::分割的



#### 一百零八、如何获取客户端真实的IP地址?

​	1.通过**请求头**中的**X-Forwarded-For**获取，但是不可靠，因为X-Forwarded-For是可以篡改的

​	2.通过**TCP Options字段**承载真实IP地址。



#### 一百零九、说一下什么是NAT协议？

​	NAT协议是**网络地址转换**。主要用于**不同网络之间进行IP地址转换** 。我们的一个**局域网中的所有设备**可以通过NAT协议**映射成一个公网IP地址接入万维网中** ，从而实现了**多个设备通过单一的公有IP地址访问互联网**，既可以**缓解IPV4地址不够用的问题**，又可以**隐藏局域网中的网络拓扑结构**，使得**外部网络无法直接访问局域网中的设备**，**提高了局域网的安全性** 。



#### 110、说一下ARP协议的工作过程？

​	ARP协议是用来进行IP地址和MAC地址之间转换的。ARP的工作过程也分为两类，第一类是同一个局域网下的MAC寻址。第二类是不同子网中的网络设备的MAC寻址。

​	ARP协议的核心是ARP表，每个网络设备都会维护一个ARP表，其中存放IP地址和MAC地址的映射。ARP表中的数据以<IP地址，MAC地址，TTL>三元组的形式保存。

​	**同一个局域网中的设备进行MAC寻址的过程**（主机A将消息发送给主机B）：

​	1.主机A**先查询自己的ARP表**，看看有没有对应的主机B的IP地址和MAC地址的映射，如果有就直接找到了主机B的MAC地址

​	2.如果没有主机B对应的MAC地址，则**主机A会发生一个广播**，同一局域网中的所有的网络设备都会接收到这个广播消息，然后通过**判断这个广播消息中的目的IP地址是不是自己的IP地址**，如果不是则直接丢弃，如果是自己的IP地址，则先将这个广播中的**源IP地址和源MAC地址放到自己的ARP表中**，然后再给主机A发送自己的MAC地址

​	3.主机A收到消息后，将主机B的IP地址和MAC地址放到自己的ARP表中

​	**不同子网中的网络设备的MAC寻址过程**（主机A发送消息给主机B）：

​	1.主机A先**判断自己的ARP表中是否存在**主机B的IP地址和MAC地址的映射关系

​	2.由于目标主机和主机A不在同一个局域网中，所以**ARP请求无法直接到达**，这时候**路由器**会根据**路由表**将IP数据包转发给目标局域网

​	3.数据包到达目标局域网之后，主机B会进行**ARP应答**，**提供自己的MAC地址**

​	4.主机A接收到ARP应答后，会将主机B的IP地址和MAC地址的映射关系保存到自己的ARP表中



#### 111、Redisson如何实现的分布式锁？

​	Redisson实现分布式锁，其实**底层还是依赖于Redis**,依赖于Redis的命令：**Set key value EX 3 NX**

​	但是Redisson在此基础上增加了**看门狗机制**，会根据你的业务是否处理完来对锁的**过期时间进行续期** ，**默认过期时间是30s** ,然后**每过10s后进行判断是否需要续期**，如果**需要续期就再将过期时间设置为30s** ；

​	其中Redisson在进行判断是否续期的时候，会进行**异步续期** ，判断是不是当前持有锁的线程，然后再**使用Lua脚本来进行续期** 。



#### 112、什么是Gossip协议？Gossip协议的传播模式有哪些？Gossip协议有什么优缺点？

​	Gossip协议是**分布式系统**中用来进行**数据/信息共享**的协议。

​	Gossip协议的传播模式：**反熵模式**、**谣言传播**

​	反熵模式：**熵代表两个节点之间的数据混乱程度**。通过反熵模式可以将两个节点之间的数据进行同步达到**最终的一致性**。其中反熵模式有**推、拉、推拉结合三种方法**。**推：将自己的数据推给别的节点，让它来和自己进行数据同步** ；**拉：拉取别的节点的数据来和自己的数据进行同步** ；**推拉：将自己的数据推给别的节点，同时拉去别的节点的数据，然后来进行数据的同步** 。

​	缺点：反熵模式的缺点是如果我们**节点数量比较多**，并且**节点数量会动态的变化的话**，那么我们的反熵模式就不太适合了。并且因为是会**将全部的数据进行传输**，所以对网络的**带宽消耗还是比较大** 。

​	一般我们在使用反熵模式的时候会设计成一个**闭环**，而不是随机选择一个节点来进行反熵，这样可以让所有的节点中的数据达到**最终一致性** 。

​	**谣言模式**：当一个节点**接收到新的数据**的时候，会变成**活跃节点**，然后将数据**向外扩散**，当新的节点收到数据后又会变成新的活跃节点继续向外扩散。

> 注意：谣言模式只会传输新的数据而反熵模式则会将所有的数据进行传输

​	 总结：Gossip协议的优缺点：

​	优点：**去中心化**，数据可以很快的在多个分布式服务器之间进行**传播和同步**；**理解性好**；**支持节点数量的动态变化**；

​	缺点：因为数据的同步可能需要经过多个轮次的传播，所以**会存在数据不一致的问题** ，但是会**达到最终一致性** ；**对网络带宽的消耗比较多**；可能会存在**消息冗余**的问题，**谣言模式中会随机选择节点进行传播**，所以会出现一个节点收到多个相同消息的情况；**不允许存在恶意节点** 。



#### 113、synchronized 和 ReentrantLock 有什么区别？

​	1.synchronized是不可中断锁；而ReentrantLock是可中断锁

​	2.synchronized只支持非公平锁；ReentrantLock支持公平锁和非公平锁

​	3.synchronized是基于JVM层面的；ReentrantLock是基于API层面的

​	4.ReentrantLock有超时、轮询等功能



#### 114、说一下Java中的四种权限修饰符？

​	1.**public** :**相同包**或者**不同包**下的**所有类**都可以访问

​	2.**protected** ：**同一个包下的类**都可以访问；**不同包下的子类**可以访问，但是其他类不可以访问

​	3.**无权限修饰符（default）** ：**只能被同一个包中的类访问**

​	4.**private** ：**只能被当前类访问**



#### 115、多服务器节点下Session-Cookie方案如何做？

​	1.可以通过**特定的哈希策略**，将**同一个用户的请求转发到固定的机器上**，这样只需要在一台机器上存储该用户的Session信息就可以了

​	2.在**所有服务器上**都存放所有用户的Session信息，多个服务器节点会**进行数据的同步**

​	3.**使用Spring Session框架**，可以借助外部的**分布式存储系统**比如**Redis**、**Mongodb**来存储用户的Session信息

​	

#### 116、什么是CSRF攻击和XSS攻击？

​	CSRF攻击：跨站请求伪造，简单来说就是用你的身份发送一些不好的请求。

​	XSS攻击：跨站脚本攻击，攻击者通过各种方式将恶意代码注入到用户的页面上，来窃取用户的信息



#### 117、为什么Cookie不能防止CSRF攻击但是Token却可以？

​	**Cookie中携带后端生成的SessionId**,我们客户端的每次请求都携带这个Cookie，里面就携带了这个SessionId然后由服务端进行验证，CSRF攻击的话，可以获取到你的Cookie中的SessionId信息，然后伪装成你发送一些不好的请求。而如果是使用**Token**的话，Token一般是存储在**localstorage**中的，CSRF攻击的话，是无法把这个token给服务端发送过去的。



#### 118、说一下什么是OAuth2.0?

​	OAuth2.0是一个第三方授权协议，是一种规范，一般用来我们接入了第三方的登录系统的时候，比如我们在我们的系统里面接入了允许用户通过微信登陆，然后我们拿着微信开放的用户信息来登录我们的系统，那么我们就需要使用OAuth2.0协议了。具体的流程如下：

​	1.用户从我们系统点击微信登录，跳转到微信APP中

​	2.**微信APP会给用户一个授权请求**，用户点击同意授权才会往下走

​	3.我们系统会拿着用户的授权信息去微信的**授权服务器**去申请授权，微信认证通过了，会给我们系统返回一个**token**

​	4.我们系统再拿着这个token去微信的**资源服务器**，申请获取这个用户的信息

​	5.微信的资源服务器对这个**token进行认证**，认证通过后会**把用户的信息给我们系统**

![](https://s3.bmp.ovh/imgs/2024/11/26/336bf3273bdb4a7e.jpg)



#### 119、什么是JWT？使用JWT有什么优缺点？

​	JWT其实就是一个**JSON格式的字符串**，用来进行**认证授权**。其中JWT由三部分组成：**Header**、**Payload**、**Signature**

​	其中Header里面主要保存使用的**加密算法**、**token类型**。对结果**使用Base64加密后保存**

​	**Payload**里面包含各种声明信息，对结果使用**Base64加密**后保存

​	Signature会根据**Header和Payload中的信息**再使用**密钥+Header中的签名算法**进行签名。

​	最后这三个字符串中间使用**"."来进行分割**

​	我们使用JWT来进行认证和授权的流程是这样的：

​	1.客户端填好用户名、密码、验证码后发送请求给服务器

​	2.服务器进行认证，认证通过后会将**用户的id、角色等信息放到payload中**，然后再根据服务器中存储的密钥来**生成一个JWT**，发送给客户端

​	3.客户端一般会将这个JWT保存在**localstorage**中，然后后续的请求会**携带这个JWT令牌**

​	4.服务器拿到JWT令牌之后，使用服务器中的密钥进行**解密**，解密出来之后，**再根据Header和Payload中的信息生成一个JWT然后和接收到的这个JWT进行对比**，来**判断信息是否被篡改**

​	5.如果没有篡改的话，会通过Payload中的用户id等信息来获取用户的信息



​	优点：

​	1.**无状态，服务端不需要保存JWT**，只需要保存密钥即可

​	2.没有使用Cookie机制，所以**可以避免CSRF攻击**

​	3.**适合移动端应用**

​	4.**对单点登录友好**，因为不是使用的Cookie机制，所以可以**避免跨域问题**

​	缺点：

​	1.如果**在JWT的有效期内**，**用户权限和密码修改后可能当前这个JWT依然有效**，比如等到过期时间到了之后才会失效

​	2.**JWT长度较大，会增加更多的网络开销**

​	3.**JWT要考虑续签问题**，我们的过期时间到了之后要考虑合理的续签，可以避免用户需要频繁的登录



#### 120、ArrayList和LinkedList的区别是什么？

​	1.ArrayList底层是基于数组的；LinkedList底层是基于双向链表

​	2.ArrayList支持随机访问；LinkedList不支持随机访问

​	3.ArrayList的插入和删除的时间复杂度受位置的影响；LinkedList如果是头插尾删的话时间复杂度是不受位置的影响的

​	4.ArrayList的空间开销浪费在需要在数组的尾部预留出一些空间来；LinkedList的空间浪费在每个节点都需要比ArrayList更多的空间



#### 121、HashSet、LinkedHashSet、TreeSet的区别是什么？

​	三者的区别主要是底层的数据结构不同，HashSet底层是HashMap,不需要保证顺序，只需要保证唯一性即可；LinkedHashSet底层是LinkedHashMap可以保证FIFO的顺序；TreeSet底层是红黑树，可以保证元素的顺序，可以定制排序。



#### 122、创建线程的几种方式有哪些？

​	1.通过**线程池**来创建

​	2.**继承Thread类**

​	3.通过**CompletableFuture**来创建

​	4.**实现Callable接口**

​	5.**实现Runnable接口**



#### 123、说一下Java中线程的几种状态？

​	1.New:创建状态

​	2.Runnable：就绪状态

​	3.Blocked:阻塞状态

​	4.Wait:等待状态

​	5.Wait-timeout：超时等待状态

​	6.销毁状态



#### 124、说一下你怎么理解的AQS？

​	AQS是抽象队列同步器的简称。内部使用一个**volatile修饰的state来标识共享资源的状态**，当一个线程去申请获取共享资源的时候，会先判断对应的state是不是为0，如果为0的话会将对应的共享资源分配给这个线程。如果当前共享资源被占用的话，那么会放到CLH中，**CLH是一个虚拟双向队列**，不是真正的队列实例，而是**将当前线程变成一个节点放到CLH队列中**，其中这个节点包括**线程的引用**、**当前节点在队列中的等待状态**、**前驱节点**、**后继节点**。



#### 125、基于AQS实现的锁有哪些？

​	ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock



#### 126、只是单纯使用@Async注解来标注一个方法有什么缺点？

​	1.无法使用线程池，可能会导致资源耗尽或者性能问题

​	2.使用@Async注解标注的方法无法继承调用者的事务

​	3.@Async注解标注的方法中出现的异常可能无法被调用者立即捕获，可以会导致异常静默处理或者丢掉

​	4.调试比较困难



#### 127、ConcurrentHashMap在JDK1.7和JDK1.8之间的区别？

​	1.jdk1.7之前解决哈希冲突使用了**拉链法**；而jdk1.8之后使用了**链表/红黑树**的结构来解决

​	2.jdk1.7之前使用**segment分段锁**来保证线程安全；jdk1.8之后使用**Node数组+synchronized+CAS**来保证线程安全，其中**synchronized只会锁链表/红黑树的首节点**

​	3.jdk1.7之前**并发度最大为Segment的个数**，**默认为16**；jdk1.8之后**并发度是Node数组的大小**，并发度更大



#### 128、JVM中的方法区是干什么的？

​	方法区会存储**虚拟机已经加载的** **类信息**、**字段信息**、**方法信息** 、**静态变量**、**常量** 等数据



#### 129、JVM内存模型在jdk1.7和jdk1.8之后有什么区别？

​	jdk1.7之前堆分为新生代、老年代、永久代；jdk1.8之后取消了永久代，在本地内存中多了元空间



#### 130、JVM中是如何判断两个类是否是同一个类的？

​	1.类名必须相同

​	2.两个类的类加载器必须相同

​	3.两个类的字节码文件必须相同

​	4.类中的字段、方法、构造函数签名必须相同



#### 131、详细说一下HashMap的put()的过程？

​	1.**先判断数组是不是为空或者大小是否为0**，如果**是的话就进行扩容**，否则往下走

​	2.根据**哈希函数**来**确定在数组中的位置**，如果**该位置是空的直接插入**，**插入后需要判断当前数组中的元素个数是不是大于阈值** ，如果**是的话就进行扩容**，如果**有元素**，**判断这个元素的key是不是和自己的key相同**，如果**相同直接覆盖**，否则往下走

​	3.**遍历这个位置的链表**，**依次判断链表中的数据的key是不是和自己相同**，**是的话直接覆盖**，不同的话当当前数据插入到链表中；在jdk1.8之前使用的是**头插法**，在jdk1.8之后使用的是**尾插法**



> 补充：HashMap中有个属性叫做**负载因子loadFactor** ,**表示数组中存放数据的疏密程度**。阈值的计算**throldsize=capacity*loadFactor**



#### 132、Stream流中终止操作都有什么?

​	1.foreach

​	2.toArray

​	3.collect

​	4.min、max

​	5.count

​	6.limit



#### 133、说一下可重复读隔离级别下的出现幻读的情况？

1. 事务A执行select * from table where id=5;

   此时是没有数据的，但是事务没有提交

   事务B执行insert into table(id) value(5); 事务B提交

   事务A去执行 **update** table set name='xxx' where id=5; 

   然后事务A再去执行select * from table where id=5; 发现多了一条数据

2. 事务A执行select * from table where id>100;  此时查出来一条数据 id=120

   事务B执行 insert into table(id) value(200); 事务B提交

   事务A执行 select * from table where id>100 **for update** ; 此时多了一条数据id=200;





#### 134、在最坏的情况下，几种常见的排序算法的时间复杂度为多少？

​	1.快速排序 O（n²）

​	2.冒牌排序O(n²)

​	3.希尔排序O(n²)

​	4.堆排序O(nlogn)

​	5.归并排序O(NlogN)



#### 135、说一下Redis中的基本数据类型？以及各自的使用场景

​	1.String：Redis是基于C语言来实现的，但是String没有**使用C语言中的字符串**，而是**自定义**了一个数据结构**SDS**。

​	好处是：**SDS的API是安全的，不会造成缓冲区溢出**；SDS**既可以存储文本数据又可以存储二进制数据**；**获取字符串长度**的时间复杂度为**O(1)**

​	使用场景：存储session、token等信息

​	2.List:redis中list数据结构是使用**双向链表**来实现的

​	使用场景：最新文章、最新动态

​	3.Hash:Redis中的Hash和Java8之前的类似，使用**数组+链表** 来实现的

​	使用场景：存储购物车、商品信息等

​	4.Set

​	使用场景：共同关注、共同好友、音乐推荐、好友推荐，抽奖等

​	5.ZSet

​	使用场景：直播间送礼排行榜、微信步数排行榜、话题热度排行榜等



#### 136、说一下Redis中的三种特殊数据结构以及它们的应用场景是什么？

​	1.Bitmap: 可以理解为**位数组**

​	使用场景：用户签到信息、活跃用户情况等

​	2.HyperLogLog

​	使用场景：数据量巨大的计数场景，比如热门网站每天/每周/每月的访问ip数，热门帖子的uv数等

​	3.GEO：底层基于ZSet来实现的

​	使用场景：附近的人、附近的店推荐等



#### 137、说一下SSE机制？

​	SSE是server-send-events的简称。是**服务端主动向客户端推送数据**的一种机制。基于HTTP协议实现。

​	SSE在HTTP的基础上，在客户端和服务器之间打开了一个单向通道，服务端响应的不再是客户端发来的一次性的数据包而是**text/event-stream**事件流，当有数据变更的时候，服务器端就会将数据推送给客户端。

​	

#### 138、SSE和WebSocket的区别？

​	1.SSE的开发成本低，WebSocket的开发成本比较高

​	2.SSE是基于HTTP协议的，**不需要单独的协议或者服务器来处理**；而WebSocket是**需要单独的服务器来处理协议**的

​	3.SSE**默认支持断线重连**，而WebSocket需要手动实现

​	4.SSE是**单向**的，又服务器给客户端推送数据；WebSocket是**全双工**的，客户端和服务器都可以发送和接收数据

​	5.SSE**只能传输文本信息**，对于二进制数据需要编码后传输；WebSocket支持二进制数据的传输



#### 139、说一下Dubbo中的几个角色是什么？

​	1.Container：服务运行容器，负责加载和运行服务提供者。

​	2.Provider: 服务提供者

​	3.Consumer:服务消费者

​	4.Registry:服务注册与发现的注册中心。服务提供者将地址注册到注册中心，注册中心将服务提供者的地址列表推给消费者。当一个服务提供者宕机或者下线的时候，注册中心会给消费者发送消息。

​	5.Monitor:监控者。统计服务调用的次数和时间。



#### 140、说一下Dubbo中的SPI机制?然后举个例子？

​	我们将**实现类**放到**配置文件**中，程序在运行的时候会**读取配置文件**，然后通过**反射**机制来加载实现类。

​	比如我们通过SPI实现一个自定义的负载均衡策略的话，我们自定义一个XXXLoadBlance类，实现LoadBlance接口，然后在这个类中实现自己的逻辑，然后将这个**类的路径**放到**META-INFO**下面的LoadBlance文件中即可。



#### 141、JDK8之后HashMap在解决哈希冲突的时候会使用链表+红黑树来实现，那么红黑树会退化成链表吗？

​	当红黑树的**节点个数小于6**的时候，会由红黑树退化为链表。

​	

#### 142、说一下Dubbo中的负载均衡策略有哪些？

​	1.**加权随机负载均衡**

​	2.**最小活跃数优先**的负载均衡，对于服务提供者来说，每收到一个请求活跃数就加一，执行完之后活跃数减一

​	3.**一致性哈希负载均衡**，Dubbo为了解决数据倾斜问题，引入了虚拟节点

​	4.**加权轮询负载均衡**，按照权重进行轮询负载均衡



#### 143、说一下你了解的内存泄露的场景？

​	1.**各种连接没有及时关闭**：比如数据库连接、网络连接等

​	2.**ThreadLocal使用不当**，用完没有及时删除

​	3.**当一个变量的作用域超出其使用范围，可能会导致被持续引用而无法回收**

​	4.**如果一个对象使用完成之后没有设置为null,可能会导致无法进行垃圾回收**

​	5.我们将对象放到了**静态集合**中，**使用完毕后没有及时从静态集合中删除**



#### 144、说一下什么是分布式事务？

​	我们一个系统可能会被**拆分**为**多个**不同的**服务**，每个服务可能又会有**各自的数据库**。我们的一组操作可能会涉及到多个服务，而又会**涉及到多个数据库**，所以导致产生了分布式事务。另外，**分库分表**的场景也会导致分布式事务的产生。



#### 145、什么是柔性事务？什么是刚性事务？

​	**柔性事务**简单的来说就是追求**最终一致性** 。**刚性事务**简单的来说就是追求**强一致性** 。

​	柔性事务常见的方案：TCC、MQ事务、本地消息表

​	刚性事务常见的方案：2PC（两阶段提交）、3PC（三阶段提交）



#### 146、说一下2PC和3PC中的几种角色？

​	1.AP：应用程序本身。

​	2.RM：资源管理器，事务的参与者，一般就是指数据库

​	3.TM：事务管理器，负责管理全局事务，给分布式事务分配唯一标识、监控事务的执行进度、负责事务的提交、回滚、失败恢复等



#### 147、说一下2PC的过程？

​	**准备阶段**

​	1.TM给所有的RM发送prepare消息

​	2.所有的RM收到消息后，开始执行本地数据库事务预操作，比如写redo log/undo log，**注意不会真的去提交事务**，然后给TM返回YES/NO结果

​	3.如果TM收到有RM返回了NO的话，就给所有的RM发送Rollback消息，所有RM收到Rollback消息后，将事务回滚，并释放资源

​	**提交阶段**

​	1.如果所有的RM都给TM返回了YES的话，TM给所有的RM发送commit消息

​	2.所有RM收到Commit消息后，进行本地数据库事务的提交，执行完成之后将资源释放，并给TM返回ACK消息

​	3.当TM收到所有的ACK消息之后，分布式事务结束

​	2PC的优缺点：

​	优点：常见的数据库如MySQL、Oracle都有自己的实现；针对的是数据的强一致性

​	缺点：依然会导致数据不一致性问题，比如在Commit阶段，TM给部分RM发送commit消息后宕机了，会导致剩余的RM没有进行事务的提交；如果TM在prepare阶段之后宕机了，那么所有的RM会阻塞在Commit阶段；在RMComimt之前会一直占有着资源



#### 148、说一下3PC的过程?

​	**CanCommit阶段**

​	1.TM给所有的RM发送CanCommit消息，询问RM能否执行本地数据库事务

​	2.RM收到CanCommit消息后，给TM返回YES/NO，或者超时未回复

​	**PreCommit阶段**

​	1.TM收到所有RM在CanCommit阶段返回的YES后，给所有的RM发送PreCommit消息

​	2.RM收到PreCommit消息后，进行本地数据库事务的预提交阶段，比如写redo log/undo log日志，并给TM返回YES/NO或者超时未回复

​	3.如果在PreCommit阶段，TM收到了NO或者超时未回复消息，那么TM给所有的RM发送Abort消息

​	4.RM收到Abort消息后，中断事务，并释放资源。分布式事务结束

​	**DoCommit阶段**

​	1.所有RM在PreCommit阶段都给RM返回了YES消息后，TM给所有的RM发送DoCommit消息

​	2.RM收到DoCommit消息后，进行本地数据库事务的提交，并给TM返回YES/NO/超时未回复

​	3.如果TM收到了NO或者超时未回复消息的话，给所有的RM发送Abort消息

​	4.RM收到Abort消息后，进行本地数据库事务的回滚，并释放资源。分布式事务结束

​	5.如果RM在PreCommit之后，在超时时间内未收到TM发送的DoCommit消息，那么会自动进行本地数据库事务的提交



#### 149、说一下什么是TCC以及它的执行过程？

​	TCC是补偿事务的简称，是Try、Confirm、Cancel三个阶段的简称。

​	1.Try阶段：尝试执行。会**预留**所需要的业务资源。

​	2.Confirm阶段：当Try阶段成功之后，会执行Confirm阶段，去操作Try阶段预留的业务资源。

​	3.Cancel阶段：当Try阶段失败会执行Cancel，去释放预留的业务资源。

​	TCC的Try、Confirm、Cancel阶段的代码都需要我们自己实现，所以属于业务侵入方案。

​	TCC在Try阶段失败后会执行Cancel阶段，当在Confirm和Cancel阶段失败后，会**记录事务日志并进行持久化**，然后针对Confrim和Cancel阶段进行重试，通常**重试次数为6次**，当重试后还没有成功则需要进行人工介入，当执行成功了，那么对应的事务日志则可以进行删除了。



#### 150、说一下TCC和2PC的区别？

​	1.2PC是需要**依赖于数据库层面的事务**的，而TCC是**基于代码**的

​	2.2PC在**Commit之前**会**一直持有资源**，会造成阻塞，而TCC是**不会一直持有资源的**

​	3.2PC不会对业务代码**有侵入**，而TCC**不会**对业务代码有侵入

​	4.2PC追求的是**强一致**，而TCC追求的是**最终一致**



#### 151、说一下柔性事务中的MQ事务？

​	MQ事务简单来说就是将生产消息、处理、消费做成一个原子操作。

​	下面基于RocketMQ来说一下MQ事务的过程：

​	1.生产者先给Broker发送一个半消息，这个消息消费者是看不到的

​	2.生产者执行本地事务，然后根据本地事务的执行结果给Broker发送Commit/Rollback消息

​	3.如果Broker收到了Rollback消息，则将半消息删除，如果收到了Commit消息，则对消费者可见

​	4.Broker在一定时间内如果没有收到生产者发来的Commit/Rollback消息的话，会去生产者中**反查**事务的执行结果，然后生产者给Broker发送Commit/Rollback消息

​	MQ事务的执行流程图如下：

​	![](https://s3.bmp.ovh/imgs/2024/08/25/9444b74ddf5abbfd.png)



#### 152、说一下你自己对于DDD的理解？

​	DDD是用来**控制复杂度**的。复杂度可以分成两类，一类是业务复杂度，另一类是技术复杂度。

​	针对业务复杂度来说，主要体现在两方面:

​	一方面是**业务流程复杂度**，针对流程很复杂的情况，我们一般可以**针对流程使用结构化分解**，使用Compose Method Parrten(**组合方法模式**)来进行流程的结构化分解

​	另一方面是业务概念复杂度，针对这个复杂度我们一般就是需要进行**统一语言**（主要体现在命名规范统一）、**领域建模**、**架构规划**

​	我们在需求分析之后，会针对这个系统进行**领域划分**，将系统分成不同的**域**，然后我们在每个**域中进行建模**，常见的用来进行建模的方法有**用例分析法**、**四色建模法**、**事件风暴**等。

​	建好领域模型之后，我们**再去开发对应的业务逻辑**。



#### 153、说一下如何优化深度分页查询？

​	查询偏移量过大的场景，我们称之为深度分页。比如

```sql
select * from table1 order by id limit 1000000,10;
```

​	优化方案：

​	1.通过**子查询来优化**，比如

```sql
select * from table where id>=(select id from table limit 1000000,1) limit 10;
```



​	2.如果id是**有序**的话，可以通过**范围查询**来优化

```sql
select * from table where id>=1000000 and id<=1000010 order by id;
```



​	3.使用延迟关联，也就是inner join的方式

```sql
select t1.* from table t1 inner join (select id from table limit 1000000,10) t2 on t1.id=t2.id;
```



#### 154、说一下Redis主从复制的过程？

​	1.slave给master发送一个数据同步的请求sync

​	2.master收到请求后，通过BGSAVE命令fork出一个子线程去生成RDB文件

​	3.master将RDB文件发送给slave

​	4.slave接收到RDB文件之后，读取并解析执行，此时slave达到了master执行BGSAVE的时候的状态

​	5.master会使用一个缓冲区保存BGSAVE之后接收到的写命令，然后将这些命令发送给slave

​	6.slave执行收到的命令，完成和master的同步

​	7.slave通过和master维护的长连接来进行命令传播，完成数据的同步



#### 155、Redis主从复制中读从机会读到过期的数据吗？

​	是有可能读到过期数据的。比如我们在master中通过expire命令设置了TTL为3s,但是因为网络延迟等各种原因，slave同步数据发生了延迟，当slave收到数据后，可能master中的TTL已经过去了一段时间，那么会导致master中的key已经过期了，但是在slave中可能还没有过期。解决方案：使用expireAT命令来设置TTL，设置的不是秒/毫秒，而是UNIX时间，这样就不会出现因为延迟同步导致的读取到过期的key了。



#### 156、什么是Redis的Sentinel模式？

​	其实就是在主从复制模式中增加了一个Sentinel(哨兵)的角色来监控Redis节点的运行状况，并帮助我们完成故障转移。

​	Sentinel模式下，我们为了保证Sentinel的**高可用**和**容错性**，一般是会部署多台Sentinel节点的，可以防止一台Sentinel对master的误判导致发生的故障转移；也可以防止因为单台Sentinel宕机导致的Sentinel模式不可用的情况



#### 157、说一下什么是Sentinel模式中的主观下线和客观下线？

​	Sentinel模式中，每个Sentinel节点每秒中是会给Redis集群中其他所有的节点发送PING请求，如果在规定的时候内没有收到合理的响应，那么该Sentinel节点就会认为对应的服务器下线了，这是**主观下线**，简单的来说就是**自己认为对象下线了**。如果有超过半数以上的Sentinel节点认为一个节点下单了，那么就称之为**客观下线**。



#### 158、Redis Sentinel模式中是如何进行故障转移的？

​	当有超过半数以上的Sentinel节点认为master宕机了，那么就会进行故障转移，首先**Sentinel集群中会通过Raft算法来选举一个Leader**让这个Sentinel节点负责故障转移。在进行故障转移的时候，Sentinel会按照下面的三种方式来决定哪个slave是新的master

​	1.**优先级**：可以对每一个slave节点设置一个优先级，**数字越小优先级越高**

​	2.如果优先级相同，则按照**与master的同步程度来选择**。优先选择与master**同步程度高**的slave作为新的master

​	3.如果上面的两个都相同，则**选择runid小的**slave作为新的master

​	

#### 159、红黑树与二叉平衡树相比有啥好处？

​	1.红黑树追求的是**相对平衡**，只需要保证黑节点平衡，而二叉平衡树追求的是**绝对平衡**

​	2.红黑树插入一个节点**最多只会进行三次旋转**就可以达到平衡，而二叉平衡树则**不确定旋转次数**

​	3.红黑树的实现没有二叉平衡树那么严格，所以**红黑树的实现比较简单**



#### 160、jdk8之后在解决哈希冲突的时候增加了红黑树的结构，相比链表来说有啥好处？

​	1.红黑树在查询、插入、删除的时候，时间复杂度为O(logn)；而链表的查询时间复杂度为O(n)

​	2.如果只使用链表的话，**当链表的长度太长的时候会导致查询效率急速下降**，使用**红黑树则可以提高查询效率**

​	3.使用**红黑树**可能会**节省更多的内存空间**，虽然红黑树中每个节点多个颜色，但是树的高度一般是小于节点个数的



#### 161、Redis Cluster中是如何确定key对应的哈希槽的？

​	首先对这个key使用**CRC16算法**得到一个校验值，然后用这个校验值**对16384进行取模**。



#### 162、Redis Cluster中为什么使用16384个哈希槽而不是使用65536个哈希槽？

​	1.Redis Cluster中各个节点之间是需要**发送心跳包**的，如果使用16384个槽心跳包的大小只有4k,如果使用65536个槽则心跳包的大小是8k，使用16384个槽可以减少网络带宽

​	2.Redis Cluster中节点不会超过1000个，所以没有必要使用65536个槽

​	3.哈希槽个数越少，对存储哈希槽信息的bitmap的压缩效果越好



#### 163、当Redis Cluster在进行动态扩容和缩容的时候，可以对外提供服务吗？如果可以说一下过程？

​	**可以对外提供服务**

​	在进行扩容和缩容的时候，会出现哈希槽重新分配的情况，此时访问key的过程如下：

​	1.如果key在重新分配哈希槽后没有发生变化，那么可以直接做出响应

​	2.如果key在重新分配之后还没有迁移走，那么也是可以直接做出响应的

​	3.如果key在迁移的过程中，会返回ASK错误码。客户端收到ASK错误码和新节点的地址之后,会给新的节点发送ASKING请求

​	4.客户端给新节点发送命令请求，但是此时依然是临时重定向的，后续对这个key的请求还是发送给原节点的

​	5.当key已经完成数据迁移之后，会返回MOVED错误码，说明发生了永久重定向，客户端以后对这个key的请求会发送给新的节点

> 补充： ASK重定向：临时重定向，后续对key的请求还是会发给原节点
>
> ​			MOVED重定向：永久重定向，后续对key的请求发送给新的节点



#### 164、说一下什么是RestFul API

​	通俗简单的来说其实就是通过url+http method就知道这个请求要干什么，客户端通过服务端返回的HTTP状态码就知道结果如何。

​	Rest Ful的架构可以总结为下面的三条：

​	1.每一个URI代表一种资源

​	2.客户端和服务器使用某种表现形式来传输资源，比如json、xml、image、text等

​	3.客户端通过HTTP动词，对服务器中的资源进行操作



#### 165、Redis的字符串为什么没有使用C语言自带的字符串而是自定义了结构体SDS

Redis自定义的数据结构SDS，它的结构体如下

```c
struct sdshdr{

  int free; // buf[]数组未使用字节的数量

  int len; // buf[]数组所保存的字符串的长度

  char buf[]; // 保存字符串的数组
}
```

1. SDS中使用len字段直接保存了字符串中的字符的长度，所以对于需要获取字符串长度的时间复杂度SDS是O(1),而C语言的是需要遍历一遍的是O(n)

2. C字符串只能保存文本数据，SDS字符串也可以保存二进制数据

3. C字符串的长度是固定的，每次修改字符串的长度都会引起内存的重新分配，而内存的重分配是比较耗时的；而SDS字符串有两种内存重分配策略，很好的解决了字符串在增长和缩短时候的内存分配问题 

   3.1 空间预分配
    针对字符串增长的操作，空间预分配策略不仅分配修改需要的字符串长度，还会额外分配未使用的free的长度。当再次进行修改时，判断如果发现free够用就不需要重新进行空间分配了。

    3.2 惰性空间释放
    针对字符串缩短的操作，惰性空间释放策略不会立即将内存空间回收，而是修改free的大小，用free记录下来，当字符串增长的时候可以直接使用这个free



#### 166、Redis持久化方式AOF的重写过程

1. 主进程检测到AOF文件大小达到了**阈值** ，触发AOF重写
2. 主进程**fork出一个子进程** ，由子进程去执行AOF重写的操作
3. 子进程去遍历主进程中所有的键值对生成一个新的AOF文件，**同时主进程依然去执行新来的Redis命令**，并将新到的命令写入到**AOF Rewrite Buffer**中
4. 子进程完成了快照时刻的AOF重写，通知主进程
5. 主进程去将AOF Rewrite Buffer中的命令**追加到新的AOF文件中**，然后删除旧的AOF文件，用新的AOF文件



#### 167、说一下Spring中的事务传播机制？

1. 默认的事务传播机制：**PROPAGATION_REQUIRED**

​		如果当前存在事务的话就加入该事务，如果当前不存在事务的话创建一个新事务。

2.  **PROPAGATION_SUPPORTS**

   如果当前存在事务则加入该事务；如果当前不存在事务则以非事务方式执行。

3. **PROPAGATION_MANDATORY**

   如果当前存在事务则加入该事务；如果当前不存在事务则抛出异常。

4. **Propagation.REQUIRES_NEW**

   创建一个新事务，如果当前存在事务则**挂起**当前的事务。

5. **Propagation.NOT_SUPPORTED**

   以非事务方式执行，如果当前存在事务则将当前的事务**挂起**。

6. **Propagation.NEVER**

   以非事务的方式执行，如果当前存在事务则抛出异常。

7. **Propagation.NESTED**

   如果当前存在事务，则在**嵌套事务**内执行；如果当前不存在事务，则创建一个事务。



#### 166、 为什么要分MVC三层开发？

1. 提高代码的可复用性：

   我们进行分层开发，我们的repository层对于持久层的操作可以被多个service来复用，service又可以被多个controller复用。

2. 可以更好的遵循单一职责原则

   分层开发各个层可以更好的各司其职，controller就负责和外部请求打交道，对参数进行校验，进行实体转换，而不需要关心具体的业务逻辑，不需要关心和持久层的交互问题。

   service层就专门负责进行业务逻辑的处理，不需要关心数据的来源。

   repository层就只需要关心和持久层的交互就可以了

3. 分层能起到隔离变化的作用

   如果我们的持久层从MySQL换成了Oracle又换成了Redis,分层后只需要修改repository层，对于service层和controller来说是不需要改变的，他们也不用去关心底层具体是如何实现和持久层进行交互的

4. 能更好的应对复杂性

5. 能提高代码的可测试性

6. 能更好的进行封装和抽象

