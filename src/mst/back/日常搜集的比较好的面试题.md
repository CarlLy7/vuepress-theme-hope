---
title: Java面试题
date: 2024-10-14
icon: line-md:chat-filled
---

写在开头：

​ 这篇文章用来记录日常搜集到的比较经典、或者比较有难度的面试题

#### 一、Spring 中的循环依赖

​ 题目：什么是 Spring 中的循环依赖？如何解决？

​ Spring 中的循环依赖：

​ Spring 中的循环依赖就是多个 Bean 对象循环依赖，比如 Bean A 依赖 Bean B ,Bean B 又依赖 Bean A

​ 如何解决？

​ 方案一：Spring 框架中使用三级循环来解决循环依赖。Spring 中的三级缓存对应的就是三个 Map

```java
//一级缓存
// Cache of singleton object;bean name to bean instance;
private final Map<String,Object> singletonObjects=new ConcurrentHashMap<>(256);
// 二级缓存
// cache of early singleton object;bean name to bean instance;
private final Map<String,Object> earlySingletonObjects=new HashMap<>(16);
// 三级缓存
// cache of singleton factory;bean name to ObjectFactory;
private final Map<String,ObjectFactory<?>> singletonFactories=new HashMap<>(16);
```

​

> 补充三级缓存：
>
> ​ 一级缓存：存放最终形态的 Bean。已经完成了初始化、属性赋值、实例化。我们获取 Bean 一般就是从一级缓存中获取 Bean
>
> ​ 二级缓存：存放半成品的 Bean（没有完成属性填充）。一般和三级缓存配合使用，三级缓存 getObject()方法得到的前期暴露对象就放到二级缓存中。可以保证 AOP 的时候多次调用三级缓存的 getObject()的时候只会生成一个代理对象而不会生成多个代理对象。
>
> ​ 三级缓存：存放 ObjectFactory。调用 getObject()可以生成原始的 Bean 或者代理对象。但是三级缓存只会对单例 Bean 生效。

​

​ 三级缓存解决循环依赖的大体流程：

1. Bean A 中依赖了 Bean B,在创建 A 的时候会去创建 B ，但是 Bean B 又依赖了 Bean A,所以又需要去创建 A，此时循环依赖了。
2. 在 B 创建 A 的时候，因为 A 还没有初始化完成，所以一级缓存和二级缓存中肯定是没有 A 的，所以去三级缓存中，调用 getObject()去获得一个 A 的 **前期暴露对象**
3. 然后将 A 的前期暴露对象从三级缓存中删除，放到二级缓存中。那么 B 就将这个 A 的前期暴露对象注入到依赖，来解决循环依赖问题。

> 注意： 非单例的 Bean 和 @Async 注解 Bean 是不支持使用三级缓存来实 现循环依赖的

​ 方案二：使用@Lazy 注解

​ 被@Lazy 注解注释的会进行懒加载/延迟加载。Bean A 中依赖 Bean B ,Bean B 中依赖 Bean A，但是 A 的构造方法使用了@Lazy 注解 这个例子。@Lazy 解决循环依赖的逻辑大致如下：

​ 在创建 A 的时候，发现 A 依赖 B，所以会创建一个 B 的 **代理对象** ，然后将 B 的代理对象注入到 A 中，完成 A 的创建。

​ 然后开始执行创建 B 的过程，B 中依赖 A 但是这个时候 A 已经创建完成了，所以 B 可以成功创建，不会发生循环依赖。

​ 注意： 之前发生循环依赖是因为 A 在创建的时候去**创建了一个 B 对象**引发了循环依赖， **使用了@Lazy 之后，A 只会去创建一个 B 的代理对象** 。

#### 二、Bean 的生命周期了解吗？

​ Bean 的生命周期简单来说可以分成四个阶段：**实例化->属性赋值->初始化->销毁**

​ 其中初始化的过程比较复杂，会先调用实现的 Aware 接口来进行增强。然后还可能调用 BeanPostProcessor 在初始化前后的处理。

​ 其中销毁并 **不会立即将这个 Bean 进行销毁** 。而是会 **注册相关的回调接口** ，然后再进行销毁。

#### 三、如何来设计一个数据迁移方案？

​ 首先一个大部人能够立刻想到的也是最 low 的方案就是： **停机迁移** 。

​ 下面说一个标准的 **不停机** 的数据迁移方案：

​ 一般不停机进行数据迁移的方案的流程如下：

​ ①、创建目标表

​ ②、用源表中的数据对目标表进行初始化：我们一般可以使用 **mysqldump** 工具进行数据的导入和导出

​ ③、进行第一次的数据校验与修复：

​ 在 **我们导出和导入数据的这段时间中，源表中的数据也是会变的** ，所以目标表进行初始化后我们需要进行第一次的校验和修复。比如我们可以使用表中的 **update_time** 字段在作为增量校验的标识。去查询源表中 update_time 大于目标表中的数据的数据，然后和目标表进行校验。 **修复数据** 的时候可以 **直接使用源表中的数据** 进行 **覆盖** 即可。

​ ④、开启 **双写模式** ，先写源表。读源表，**先写源表** ，然后再写目标表，**数据以源表为准**

​ ⑤、再次进行数据校验和修复

​ 在这一步也是为了保证源表和目标表中的数据保持一致，有两种方案，第一种方案是使用 update_time 更新时间戳来更新新的数据；第二种方案是利用源表的 binlog 来校验和修复目标表中的数据。

​ 方案一：**使用 update_time 更新时间戳来更新新的数据**

​ 我们可以定时查询源表和目标表中的 update_time 比较新的数据，然后比较源表和目标表中的数据是不是一致，如果不一致那个就用源表中的数据覆盖目标表。但是还会有一个问题就是我们 **源表中的数据删除了** 但是 **目标表中的数据还没有删除** 这个时候我们就需要一个 **反查机制** ，就是需要 **查询目标表的全部数据然后去和源表核对**，如果 **源表中不存在就在目标表中进行删除** 。

​ 方案二：**通过 binlog 日志来进行校验和修复数据**

​ 我们将 binlog 日志 **当做** 一个 **触发器** 。当我们 **接收到** binlog 日志之后就会利用 binlog 中的 **主键** 或者 **唯一索引** 去 **查询源表和目标表** 中的数据，然后进行 **校验** ，如果不一致则用源表中的数据对目标表中的数据进行覆盖。

​ ⑥、切换双写顺序，改成读目标表，先写目标表，然后再写源表

​ ⑦、完全切换到读写都只操作目标表

#### 四、@AutoWired 和@Resource 有什么区别？

​ 这是一个比较经典的 Java 面试题目。@Autowired 和@Resource 两个注解都可以用来注入 Bean。但是两者的区别可以简单总结如下：

1.  @AutoWired 是 Spring 提供的注解； @Resource 是 JDK 提供的注解

2.  @AutoWired 默认是通过 byType 进行注入的，而@Resource 默认是通过 byName 进行注入的。下面通过一个具体的例子来帮助理解：

    有一个接口 SmsService，这个接口有两个实现类分别为 SmsServiceImpl1 和 SmsServiceImpl2

    ```java
    // 下面使用@Autowired注入是会报错的，因为默认是通过byType通过类型来进行注入，但是此时这个接口有两个实现类，所以就无法找到具体的实现类
    @Autowired
    private SmsService smsService;
    // 通过指定名称来指定对应的实现类
    @Autowired
    @Qualifier(value="smsServiceImpl1")

    //下面使用@Resource注入会报错，因为默认是通过name来注入，但是此时没有smsService对应名字的Bean
    @Resource
    private SmsService smsService;
    //通过指定name来注入Bean,成功注入
    @Resource(name="smsServiceImpl2")
    private SmsService smsService;

    ```

    3. @Autowired 可以作用于方法、构造函数、字段、参数上；@Resource 不可以作用于构造函数和参数上

#### 五、SpringBoot 是如何实现自动装配的？

​ 其实在 Spring 框架中就已经有了自动装配的功能，Spring Boot 可以理解为通过 **SPI** 机制，做了进一步的优化和增强。

​ Spring Boot 在启动的时候会去加载外部 jar 中的 **META-INFO** 下的 **spring.factories** 文件。外部组件可以将自己的配置放到这个文件中，Spring Boot 会将里面的配置加载到 Spring 容器中。

​ 在使用 Spring Boot 的时候，**核心** 是通过一个 **@SpringBootApplication 注解** 实现自动装配的。这个注解其实是多个注解的复合注解，里面包含了 **@EnableAutoConfiguration** 、 **@ComponentScan** 、 **@SpringBootConfiguration** 这三个注解。

​ @SpringBootConfiguration 注解其实就是@Configuration 注解，允许在上下文中注册额外的 bean 或者导入其他配置类。

​ @ComponentScan 注解是去扫描指定包下面的所有的 bean,默认是扫描启动类包下的所有的类

​ **@EnableAutoConfiguration 注解是开启自动配置机制**，也是 Spring Boot 自动装配实现主要依赖的注解

​ 其实@EnableAutoConfiguration 只是一个简单的注解，它底层其实是通过 AutoConfigurationImportSelector 类来实现的。

![](https://s3.bmp.ovh/imgs/2024/05/17/9adfb7ad5387522b.png)

#### 六、什么是 TCP 的粘包问题？以及如何解决

​ 粘包问题： 当我们使用 TCP 协议进行发送消息的时候，**TCP** 是有可能会对 **消息进行分组** 的，当我们发送多条消息后，可能会出现多 **个消息的某一部分粘在了一个消息中** ，这就是 TCP 的粘包问题。 粘包问题的出现是 **不知道** 一个 **消息的边界** 在哪里，那就会导致 **无法** 正确的划分出一个有效的消息。

​ 解决方案：一般来说有三种粘包问题的解决方案，分别是：1. 固定长度的消息 2. 使用特殊字符作为边界 3. 自定义消息结构

​ 1. **固定长度的消息** ：每个消息的长度都是固定的，当读取到这个长度之后就认为读取完了一个消息。是最简单的方案，但是不灵活，一般在实际中 **基本不使用**这种方案。

2. **使用特殊字符作为边界** ：在一个完整的消息后面添加一个特殊的字符作为结束。当读取到这个特殊字符之后就认为读取完毕了一个完整的消息。
3. **自定义消息结构** ：自定义一个消息结构，比如包含包头和消息体，包头中声明这个消息的长度，然后在消息体中存放真正的消息，当读取到这个结构体之后，先读取包头，根据包头中的消息长度去消息体中读取数据。

#### 七、当我们在浏览器中输入一个地址到页面显示的过程是什么？

​ 1.**组装 HTTP 请求**

​ 当我们在浏览器中输入 url 的时候，浏览器会先将 **url 进行解析** ，生成发送给 web 服务器的请求信息，**生成 HTTP 请求**

​ 2.**DNS 解析**

​ 我们在 url 中输入的一般都是域名，那么如何通过这个 **域名** 得到对应的 **服务器的 IP 地址**，就需要 **DNS 解析** 。DNS 解析根据输入的域名得到对应的目标 IP 地址

​ 3.**通过协议栈进行包装**

​ 在经过 DNS 解析之后得到了 IP 地址，然后就通过 **协议栈** 层层对 HTTP 请求进行 **包装**，主要是添加 **各种协议** 的 **头信息**

​ 4.**添加 TCP 包头信息**

​ **HTTP 需要依赖 TCP 协议进行传输**。在这一步中 TCP 包头中包含了 **源端口** 和 **目标端口** 。 然后与目标进行 **三次握手** 来进行 **连接** 。最后在请求信息中 **添加上 TCP 包头信息** 。

​ 5.添加 IP 包头信息

​ **TCP 需要依赖 IP 协议进行传输**。在这一步中 IP 包头中包含了 **源 IP 地址** 和 **目标 IP 地址** 。最后在请求中添加上了 **IP 包头** 信息。

​ 6.添加 MAC 包头信息

​ MAC 包头信息中包含了 **源 MAC 地址** 和 **目标 MAC 地址** 。MAC 协议通过 **ARP 协议** 来找到目标 MAC 地址

​ 7.**网卡**

​ 网卡主要负责将 **数字信息转成电信号** 。网卡还会继续对请求信息进行添加。在请求的开头加上 **报头和起始帧分界符**，在请求的末尾加上 **检测错误的帧校验序列**

​ 8.**交换机**

​ 交换机负责将网络包原封不动的转发到路由器。

​ 9.**路由器**

​ 将网络包转发到下一个路由器或者目标设备。最终得到目标设备。 注意 **MAC 包头的目的就是找到路由器** ，路由器在接收到网络包后会将 **MAC 包头信息删除** 。

​ 10.服务端接收到网络包之后进行‘扒皮’

​ 服务端接收到网络包之后进行扒皮，然后执行对应的操作，将结果发送给客户端。客户端收到之后进行页面渲染

​

#### 八、TCP 如何保证传输的可靠性的？

​ 1.**基于数据块传输** ：TCP 会将应用数据分为 TCP 认为最合适的块来进行传输。

​ 2.**对失序数据包进行排序和去重** ：TCP 为了保证不丢包，会给每一个包一个序列号，有了序列号就可以对这些数据包进行排序和去重。

​ 3.**校验和** ：通过校验和来判断数据在传输过程中是否发生变化。

​ 4.**重传机制** ：当数据包发生丢包或者延迟的时候，TCP 有重传机制，包括基于计时器的重传机制、基于 ACK 的重传机制

​ 5.**流量控制** ：TCP 连接的每一方都有一个固定大小的缓冲区，TCP 的接收方只允许发送方发送接收方缓冲区大小的数据，流量控制 TCP 主要是使用**滑动窗口**来实现的。

​ 6.**拥塞控制** ：TCP 的发送方可以根据接收方的缓冲区大小或者网络的拥塞情况来控制自己的发送速度，TCP 是通过**拥塞窗口**来实现的。发送方自己维护一个拥塞窗口，其中发送方发送的数据大小是**拥塞窗口和滑动窗口的最小值**。

#### 九、TCP 是如何实现流量控制的?

​ TCP 使用**滑动窗口**来实现流量控制，主要是来控制发送方发送数据的速率，让接收方来得及接受，从而让发送方和接收方处于一种**动态平衡**。

​ 客户端和服务器端都有一个**发送窗口**和**接收窗口**，其中**发送窗口**由四部分组成：

​ 1.**已经发送并且被接收方确认的 TCP 段**

​ 2.**已经发送但是还没有被接收方确认的 TCP 段**

​ 3.**未发送并且接收方准备接收的 TCP 段**

​ 4.**未发送但是接收方不准备接收的 TCP 段**

​ **接收窗口**由三部分组成：

​ 1.**已经接收并且确认的 TCP 段**

​ 2.**等待接收但是允许发送方发送的 TCP 段**

​ 3.**不可接收且不允许发送方发送的 TCP 段**

​ 接收窗口是由接收方**动态调整**的。

#### 十、Redis 中的有序集合 ZSet 底层为什么使用跳表而不使用红黑树、B+树、平衡树

​ 与平衡树相比，跳表创建的初始就是为了 **避免** 平衡树中插入和删除的时候进行 **旋转维护平衡** 的问题。跳表的实现也比平衡树简单，迅速。

​ 与红黑树相比，在插入和删除的时候跳表 **不需要** 进行 **旋转和染色** 来 **维护黑平衡** ，跳表比红黑树实现简单。并且跳表的 **范围查询** 比红黑树效率高。

​ B+树主要是用于数据库中存储索引的，主要目的是 **减少磁盘 IO 的次数** 来提高查询的效率。但是对于 Redis 来说，是把数据存放在内存中的，所以 **不会存放大量的数据** ，所以没有必要使用 B+树来存放索引。另外 B+树在 **插入** 数据的时候可能会发生节点的 **分裂** 和 **合并** ，而跳表只需要在对应的索引位置添加元素，然后再 **随机维护一定高度的索引** 即可。

> ​ 补充 : 跳表中每级索引的个数是下一层的个数的一半，跳表中索引的高度为 h=（log 2^h） -1

#### 十一、Redis 过期 Key 删除策略

​ Redis 中针对过期 Key 的删除策略有两个，第一个是 **惰性删除** 、第二个是 **定期删除** 。

​ 惰性删除： **只会在查询 key 的时候** 对数据进行检查，如果 key 过期了才会删除。这种策略对 CPU 比较友好，但是会导致很多过期的 key 一直在内存中没有删除，所以对内存不是很友好。

​ 定期删除： Redis 会 **定期去扫描一部分 key** ,然后检查是不是过期，如果过期就会将 key 删除。这种策略对内存比较友好，但是对 CPU 的压力比较大。其中在定期删除策略有很多的细节，比如 **定期删除** 的 **频率** 可以通过配置文件中的 **hz** 参数来设置，hz=10 代表每秒执行 10 次定期删除策略。另外 hz 参数可以配合**dynamic-hz** 参数来使用，会 **自适应** 确定 hz 的值。并且在执行定期删除策略的时候会收到两个参数的影响，一个是 **执行时间的阈值** 另一个是 **过期 key 的比例** 。 如果本次定期删除策略执行的时间 **超过** 了 **执行时间阈值** 那么就会 **中断** 本次的定期删除。 如果本次定期删除中的过期 key 的比例 **超过** 了 **过期 key 的比例阈值** 的话就会重复执行定期删除。 如果本次定期删除的过期 key 的比例 **小于** 过期 key 的比例的时候，就会中断本次定时删除。

​ Redis 中默认使用的是 **惰性删除+定期删除配合** 的策略，这样可以对 CPU 和内存进行一个平衡。

#### 十二、什么是 Redis 的缓存击穿、缓存穿透、缓存雪崩？以及针对这三个问题的解决方法？

​ 缓存击穿:高并发访问下，**某个热点 key 过期了**，导致大量的请求来到了数据库层。解决方案： 合理设置热点数据的过期时间；加锁然后查询数据库再将数据缓存起来

​ 缓存穿透：访问缓存中一定不存在的 key，由于缓存没有命中，大量的请求来到了数据库层。解决方案： **对于不存在的数据缓存 null 值** ，但是要设置合理的过期时间；使用 **布隆过滤器** ；对用户 IP 进行 **限流** 。

​ 缓存击穿和缓存穿透的区别：缓存穿透是访问**一定不存在于缓存中的数据** 导致查询直接穿透到了数据库层；缓存击穿是访问一个存在的 key,**在 key 过期的一刻**，**同时有大量的请求** ，大量的请求来到了数据库层。

​ Redis 缓存雪崩一般是 **Redis 服务不可用** 或者 Redis 中 **大量 key 同时过期** ，导致**大量请求来到了数据库**，然后把数据库干宕机了，从而导致了服务器崩溃。解决方案： **随机设置过期时间** ，在基本的过期时间上再加一个随机值；**Redis 服务使用集群部署** 比如 Sentinel 或者 Cluster 方式；提前预热，将 **热点数据** 提前缓存到 redis 中。

#### 十三、Redis 可能发生阻塞的原因？

​ ①、执行 O(N)时间复杂度的命令

​ ②、查询大 Key

​ ③、删除大 Key

​ ④、Redis 执行完命令之后还没来得及写到 AOF 的时候 Redis 宕机了可能会阻塞后续其他命令的执行。

​ ⑤、使用 SAVE 命令来生成 RDB，而没有使用 bgSave 命令来生成 RDB 文件，会阻塞 Redis 主线程

​ ⑥、AOF 刷盘的时候导致阻塞

​ ⑦、AOF 重写的时候导致阻塞。因为在 AOF 重写的时候，新的 Redis 操作会放到 AOF 重写缓存区中，然后再将 AOF 重写缓冲区中的数据追加到 AOF 文件的末尾。这个过程可能会导致阻塞。

​ ⑧、清空 Redis

​ ⑨、Redis 扩缩容

​ ⑩、CPU 竞争，因为 Redis 是很消耗 CPU 的，如果你的 Redis 和对 CPU 消耗比较大的服务在同一台机器上的时候会对 Redis 的性能有很大的影响，可能发生阻塞。

​ ⑪、 网络问题导致 Redis 发生阻塞

#### 十四、Redis 和 Memcached 的异同

​ 相同：

​ 两者都是基于内存的，性能都很高

​ 两者都有过期 key 的删除策略

​ 不同：

​ Redis 支持更多的数据结构，而 Memcached 只支持 k-v 键值对

​ Redis 支持持久化，重启之后数据不会丢失，而 Memcached 不支持持久化，重启后数据会丢失

​ Redis 支持发布订阅模型、事务、lua 脚本等，而 Memcached 不支持

​ Redis 使用单线程执行命令，采用 IO 多路复用的模型。而 Memcached 是多线程，非阻塞 IO 复用的网络模型

​ Redis 支持惰性删除、定期删除的过期 key 删除策略。而 Memcached 只支持惰性删除

#### 十五、你知道缓存模式有哪些吗？

​ 1.**旁路缓存策略**

​ 写：**先写 db，然后删除 cache**

​ 读：**读 cache,如果存在直接返回；如果 cache 没有的话读 db,然后将结果放入 cacahe 中**，最后返回

​ 2.**读/写穿透策略**

​ 写：**先查 cacahe,如果 cache 中不存在直接更新 db;如果 cache 中存在则更新 cache,然后再更新 db**

​ 读：**先查 cache，有就直接返回；如果 cache 中没有则查询 db 然后写入 cache,再由 cache 返回**

​ 3.**异步缓存写入策略**

​ 写：先写入 cache 中，然后**由 cache 异步批量写入 db**

​ 读：**先读 cache，如果存在直接返回；如果 cache 不存在则读 db 然后写入 cache，最后返回**

#### 十六、请你介绍一下 MySQL 中的几种日志

​ MySQL 中有三个日志是比较重要的，分别是 **undo log** 、**redo log** 、**binlog** 。

​ undo log 是 MySQL 中用来进行 **回滚** 的日志，当一个事务开启的时候，在这个 **事务中** 进行的操作都会记录对应的 undo log 中，比如我们执行了一个 INSERT 操作，那么 undo log 中就记录一个 DELETE 操作，我们执行一个 DELETE 操作，undo log 中就记录一个 INSERT 操作。undo log 主要是用于我们在事务提交之前让这个事务进行了 **回滚** ，那么我们就需要依靠 undo log 中的日志将数据进行 **还原** ，还原到事务开始之前的时候。**当事务成功提交之后，本次事务的 undo log 也就没有了** 。

​ redo log 日志中记录了我们在 MySQL 中进行的 **增删改** 操作，**事务开始之后** 我们将对应的增删改操作都记录在 redo log 中，如果事务还 **没有提交** 但是发生了 **宕机** ，那么 MySQL 重启之后需要依靠 redo log 将这个事务中的操作复现回来。当然 redo log 的写入语义也是比较复杂的，具体来说就是： redo log 有一个 **buffer pool** ,写入 redo log 的时候会**先**将数据写到 redo log 的 **buffer pool** 中，然后**再**从 buffer pool 中刷新到**操作系统的 page cache 中** ，然后再由刷盘机制**最终刷到磁盘中**。所以说如果 redo log 没有成功刷新到磁盘中就宕机了，那么这个过程中的数据就会丢失了。

其中 redo log 刷新磁盘中的时机有对应的参数：**innodb_flush_log_at_trx_commit**

innodb_flush_log_at_trx_commit=0： **每秒** 刷新到磁盘一次，直接由 buffer pool 刷新到磁盘

innodb_flush_log_at_trx_commit=1: **每次事务提交之后**，将数据刷新到磁盘上。

innodb_flush_log_at_trx_commit=2： **事务每次提交的时候刷新到 page cache 中** ，然后**由操作系统决定什么时候将数据刷新到磁盘**

​ binlog: **二进制操作日志文件**。里面记录了 MySQL 的增删改操作，主要是用于进行 MySQL**出现故障之后进行数据恢复** 以及 **主从同步** 。其中 binlog 的写入是 **和 redo log 的写入结合在一起** 组成一个 **两阶段提交** 的，**先写入 redo log** ,这个阶段是 redo log 的 **prepare 阶段**，**成功之后写入 binlog ,写入成功之后，再进行 redo log 的提交** 。 binlog 也有对应的 **刷新到磁盘中的时机**，由参数 **sync_binlog**决定

**sync_binlog=0:由操作系统决定什么时候将 binlog 中的数据刷新到磁盘中**

**sync_binlog=N:N 个事务提交之后将数据刷新到磁盘中** 。

​ 总结： undo log 是用来进行**事务回滚**的日志，redo log 是**事务执行过程中**宕机之后进行**数据恢复**的，**保证事务的持久化**，binlog 是用来 MySQL**故障之后** **数据恢复和主从同步**的。

​

#### 十七、你知道什么是值传递、什么是引用传递吗？Java 使用的是什么？

​ 值传递就是将实参进行 **拷贝** ，生成一个 **副本** ，然后将副本传给方法，如果方法中 **对实参进行了修改** 也 **只会修改副本** ，**原始的** 实参的值是 **不会变** 的

​ 引用传递 **不会** 进行 **拷贝** ，会将原始的实参传给方法，所以方法中如果 **对实参进行修改** 会 **直接影响到原始的实参**

​ **Java 使用的是值传递** 。对于 **基本类型** 的实参来说，对实参进行 **拷贝** ，传递的是 **副本的值** ， **会生成副本** 。如果是 **引用对象** 的话，会将实参的 **引用对象在堆中的*地址* 进行拷贝** ，同样 **也会生成副本**。

#### 十八、你做过哪些 MySQL 的优化吗？

1. **添加索引** 。比如对联查作为条件的字段创建索引。排序使用的字段添加索引。尽可能的使用 **联合索引**。
2. **尽量避免多表 join 联查** 。
3. 避免使用 select _ 。 因为使用 select _ 查询可能导致无法使用覆盖索引。会消耗更多的 CPU。会传输更多的字段，增加网络传输的开销。
4. **使用子查询来优化深层分页** 。 比如 select id from tableA where id>(select id from tableA limit 100000,1) limit 10;
5. **更新和插入使用批量操作** 。
6. **查询慢 SQL** 。然后不断调整索引以及 SQL 语句来提高效率。
7. **避免索引失效** 。**like 查询不要%开头** 。 **不要使用 OR 并且两边有一个没有索引** 。**不要** 在 **索引列** 上进行 **类型转换** 或者 **使用函数** 。**in 后面的列表不要太大** ，不然容易走全表扫描。
8. **使用合适的字段类型** 。

#### 十九、ElasticSearch 的优化你知道吗？

1. 物理优化，使用更好的机器，更大的内存。
2. ES 中 **只保存** 会进行 **检索的字段** ，不进行检索的字段不保存，这样既可以节省内存空间，又可以提高检索效率。
3. ES 使用 **批量提交替代单条提交** ，比如一个场景是将 **数据库中的数据同步到 ES 中** ，那么我们可以批量提交。比如 **从 MQ 中消费消息保存到 ES 中** 的时候也可以使用批量消费，批量提交。
4. **优化分页查询** ，使用 search_after 来优化。
5. **冷热数据分离** 。**时间比较久** 或者 **搜索少** 的数据放到 **性能差点** 的 ES 机器中，**热数据** 放到 **性能高的 ES 机器** 中。其中我们可以使用 ES 的 **生命周期管理** 来进行冷热数据分离。
6. **调大 refresh 的时间间隔** 。 ES 会定期将内存中的数据刷新到磁盘中，增大这个时间间隔可以在一定程度少减少性能开销。
7. 擅于使用 keyword，不走分词器，可以提高查询效率
8. 开启慢查询配置来定位慢查询
9. 将多个字段使用 copy_to 合并为一个
10. 避免大型文档存储，单个文档不要超过 100M

#### 二十、说一下什么是数据库的三范式？

​ **第一范式** ：表中的各个**列**是**不可分割**的基本数据项。

​ **第二范式** ：**在第一范式的基础上** ，表中所有的**非主键属性完全依赖于主键** 。

​ **第三范式** ：**在第二范式的基础上** ，各个**非主键属性之间相互独立** ，**不存在传递依赖函数** 。

#### 二十一、你知道哪些线程安全的集合类？

1. ArrayBlockingQueue
2. LinkedBlockingQueue
3. ConcurrentHashMap
4. ConcurrentLinkedQueue
5. CopyOnWriteArrayList

​ ArrayBlockingQueue 和 LinkedBlockingQueue 的区别：①ArrayBlockingQueue 底层是基于**数组**实现的，而 LinkedBlockingQueue 底层是基于**链表**实现的；②ArrayBlockingQueue 是**有界队列**，**创建时需要指定大小**，而 LinkedBlockingQueue 初始化的时候可以指定大小也可以不指定大小，如果**不指定大小的话默认是 Integer.MAX_VALUE**也就是无界队列；③ArrayBlockingQueue 的**生产和消费使用同一把锁** ，而 LinkedBlockingQueue**生产和消费使用的是不同的锁**④ArrayBlockingQueue 需要**提前分配数组内存**，而 LinkedBlockingQueue 是**动态分配链表节点内存** ⑤ArrayBlockingQueue 支持公平和非公平两种锁访问机制，而 LinkedBolckingQueue 只支持非公平的锁访问机制

​

#### 二十二、说一下 HashMap 的初始容量，以及扩容机制？为什么在创建的时候指定了集合大小之后会变成 2 的幂次方？

​ HashMap 在创建的时候如果我们没有指定容量大小的时候，**默认大小是 16** 。

​ HashMap 在每次进行 **扩容** 的时候每次变成 **原来容量的两倍** 。

​ HashMap 在 **创建** 的时候如果我们 **指定了容量** 的大小的话，那么会 **调整为 2 的幂次方**。 目的是： 我们得到 **散列值** 之后一般需要对 **数组长度** 进行**取模** 运算，然后得到的值才是对应的位置。**hash%length** 的结果和 **(n-1)&hash** 的结果是一样的，但是 **&运算的效率比%运算的效率高很多** 。

#### 二十三、说一下什么是数据的零拷贝技术？

![](https://s3.bmp.ovh/imgs/2024/06/13/94635ad25bf318ad.png)

> 补充： 什么是 DMA 拷贝。 DMA 拷贝是在两个内存区域之间直接进行数据拷贝，而不需要依赖于 CPU 而是依赖于硬件特性。

#### 二十四、文件读写和网络发送接收的最小单位是字节，那么为什么 IO 流中还要出一个字符流呢？

​ 1、字符流是 JVM 虚拟机将字节流转换而来的，这个过程是比较耗时的

​ 2、如果我们不知道字符的编码格式的话，使用字节流的话读取出来的数据可能是乱码

#### 二十五、常见的字符编码格式所占的字节数？

​ utf8 中**英文占 1 个字节**，**中文占 3 个字节**。

​ Unicode 中**所有字符都占 2 个字节**

​ gbk 中**英文占 1 个字节**，**中文占 2 个字节**

#### 二十六、JVM 中如何判断一个对象是死亡对象？如何判断一个常量是废弃常量？如何判断一个类是无用的类？

​ 判断一个对象死亡的方法：

1.  引用计数法：当一个对象有一个引用的时候这个对象的引用计数器就加一，当一个引用释放掉这个对象的时候计数器就减一，当这个对象的引用计数器=0 的时候说明没有任何地方引用它了，就可以判断对象死亡，可以进行垃圾回收了。

2.  可达性分析算法：从一个“GC ROOTS”出发，然后向下搜索，如果 GC ROOTS 可以达到这个对象，说明这个对象是有用的，不能进行回收，如果一个对象不能从 GC ROOTS 到达的话，说明这个对象是无用的了，就可以进行垃圾回收了。

    可以作为 GC ROOTS 的对象有：

    - 虚拟机栈中引用的对象
    - 本地方法栈中引用的对象
    - 方法区中静态属性引用的对象
    - 方法区中常量引用的对象
    - JNI 引用的对象
    - 被同步锁引用的对象

​ 判断一个常量是废弃常量的方法：比如堆中的字符串常量池中存在字符串"abc"，如果没有任何 String 对象引用该字符串常量的话，说明这个常量是废弃常量

​

​ 判断一个类是无用类的方法：如果想要**判定一个类是无用的类** ，必须同时满足下面的三个条件：

1. **该类没有任何的对象实例**
2. **该类的 ClassLoader 已经被回收**
3. **该类对应的 Class 对象没有任何引用，也就是不能在任何地方通过反射访问这个类中的方法**

#### 二十七、说一下什么是类加载中的双亲委派模型？

​ 类加载器分为 **启动类加载器** 、**扩展类加载器** 、**应用程序类加载器** 、**自定义类加载器** , 其中**启动类加载器是最顶级的类加载器** 。

​ 当我们在进行类加载的时候，会进行下面的几个步骤：

​ step1: 首先判断当前类是不是已经被加载过了，如果已经被加载了就直接返回，如果没有被加载的话，才会尝试进行加载。

​ step2: 在进行类加载的时候，也 **不是** 自己这个类加载器直接加载，而是将类加载 **委托给父类加载器** 进行加载，然后父类加载器也执行 step1 和 step2

​ step3: 如果父类加载器反馈 **无法加载** 这个类的时候， **子类加载器** 才会尝试进行加载这个类

​ step4: 如果所有的类加载器都没有办法加载这个类的时候会 **抛出异常**

​ 如果我们想要**打破双亲委派模型**的话，我们在自定义类加载器中，继承 ClassLoader 后**重写 loadclass()方法** ，因为类在进行类加载的时候是会调用父类加载器的 loadclass()方法的，所以我们可以**在这个方法中自定义我们自己的逻辑** 。

​ 双亲委派模型的**好处** ：

1. **防止类的重复加载**
2. **防止 JAVA 核心 API 被篡改**

#### 二十八、Java 对象的创建过程是什么？

​ step1: **类加载检查**

​ step2: **分配内存**

​ 在类加载检查的时候就可以确定对象需要的内存大小，进行内存分配的时候有两种方法，一种是： **指针碰撞** ，另一种是 **空闲列表**

​ 指针碰撞:适用于 **堆内存规整** 的情况下。使用过的内存移动的一边，没有使用过的内存移动到另一边，中间使用分界指针来划分，我们只需要**移动** 这个 **分界指针** 就可以了

​ 空闲列表：适用于**堆内存不规整** 的情况下。虚拟机会维护一个列表，记录哪些内存是可以使用的，从可以使用的内存中选择一块分配这个对象即可。

​ **注意** ：在分配内存的时候会有 **线程安全** 问题，因为同一个类的对象可能同时被多个线程 new,所以一般使用 **CAS+重试** 的机制来保证线程安全。

​ step3: **初始化零值**

​ 保证了在 **不赋初始值** 的情况下就 **可以使用** ，初始化对象类型的零值

​ step4: **设置对象头**

​ step5: **执行 init 方法**

#### 二十九、说一下什么是 Java 中的 JMM?

​ JMM 是 Java 内存模型，**不是真实存在的** ，**而是一组规范** 。

​ **主内存** 中存放 **共享变量** ，其他的线程不能直接操作主内存中的变量，而是先将主内存中的变量**拷贝**到自己的工作内存中。然后在自己的工作内存中对这个共享变量进行修改，再将**修改后的结果写回到主内存中** ，然后**其他的线程**要拿主内存中**最新** 的共享变量的值。

​ JMM 保证了多线程下共享变量的**可见性** 、**原子性** 、**一致性** 。

​ 其中使用**volatile** 来保证可见性，一旦**修改了共享变量后** 就会**立刻刷新到主内存中** ，并且**每次读取的时候** 都**去主内存中读取最新的值** 。

​ 使用了 **synchronized** 来进行**互斥** ，保证了在**退出同步块的时候刷新数据到主内存中** ，**进入同步块之前先从主内存中读取数据** 。

#### 三十、==和 equals()的区别？

​ 对于**基本数据类型**来说，**==比较的是值** ，对于**引用类型** 来说， **== 比较的是引用的地址** 。**equals()**方法是 Object 类中的方法，如果我们的类**没有重写父类 Object 中的 equals()方法** 的话，比较的时候其实和 == 一样，**比较的是引用地址** ，如果重写的话会比较值。而且**equals()方法不能用于比较基本数据类型** 。String 类中的 equals()方法就是对 Object 类中的 equals()方法进行了重写。

​ 并且**一般重写 equals()方法必须重写 hashCode()方法** , 因为**相同的对象的 hashCode()的结果一定是一样的** ，如果我们没有重写的话，会出现 equals()方法判断两个对象是相等的，但是两个对象的 hashCode()结果不同的问题。

#### 三十一、CAS 的底层原理是什么？

​ CAS 的底层原理是**Unsafe 类+自旋** 来实现的。其中 Unsafe 类调用底层的 native 方法，来基于**cpu 的原子指令** 保证了原子性。

​ CAS 的优点就是对于读多写少的场景，比起悲观锁来性能更好。 缺点是：①**有 ABA 问题 ** ②**自旋循环时间长开销大** ③ **只能保证一个共享变量的原子操作**

#### 三十二、说一下什么是分布式系统中的 CAP 理论和 Base 理论？

​ CAP 理论是：**一致性** 、**可用性** 、**分区容错性** 的简称。

​ 在现在的互联网环境中，分区容错性是必须的，所以我们必须要保证 P，在保证 P 的前提下，一致性和可用性只能选择一个。也就是 AP 或者 CP，比如 Zookeeper 就是 CP，Euraka 是 AP。

​ Base 理论是：**基本可用** 、**软状态** 、**最终一致性** 的简称。其实可以理解为对 CAP 中的一致性和可用性的一种**折中**。没有保证强一致性，但是保证了数据的**最终一致性** 。数据会在**一定的时间内**达到最终的一致。

​ 其中 Base 理论中的**基本可用**是在一些情况下可以**牺牲系统的部分可用性** ，但是不代表系统不可用，比如**损失接口响应时间**、**部分接口不可用** 等等。

​ 其中**软状态** 就是**多个节点之间数据不一致的状态** 。

​ 其中**最终一致性**就是数据会在**一定的时间内**达到最终的所有节点上**数据一致** 的结果。

#### 三十三、介绍一下你知道的分布式系统的共识算法？

​ 分布式系统中的共识算法就是**分布式系统**中**多个节点** 就一个**提案** **达成共识** 的算法。最早的分布式系统的共识算法是 Paxos 算法，使用最多的是 Raft 算法。 Raft 算法是在 Paxos 算法的基础上演进而来的。

​ Paxos 算法：Paxos 算法其实就是提出了**共识算法**的思想，核心就是**多个节点就一个提案达成共识**。 所有的节点分成三个角色：**提议者** 、**接受者**、**学习者** 。 首先由**提议者**就一个问题**提出议案**，然后**发送给所有的接受者**，**接受者**对这个提议进行**投票** ，同意或者拒绝，当**半数以上**的接受者就一个提案**达成共识**的时候，那么这个提案就**通过**了，由**学习者**去**执行这个提案** ，并且最终**返回给客户端**。

​ 但是由于 Paxos 算法只是提出了思想，但是实现比较复杂，也没有具体落地。所以出现了目前使用比较多的，基于 Paxos 算法的简化以及落地方案：Raft 共识算法。

​ Raft 算法中，分为**Leader** 、**候选人** 、**Follower** 三个角色。其中每个 Leader 都对应自己的一个**任期** ，并且每个 Follower 都有一个**随机** 的超时时间，如果到达自己的超时时间内，**没有收到 Leader 或者候选人的消息的时候** ，就会**由 Follower 变为候选人** ，**任期加一** ，然后**给所有的节点** 发送选举请求，当收到**过半以上的节点**发来的同意请求后，就会**由候选人变成 Leader 节点**。

​ 并且对于 Raft 算法来说，日志**entry 只能由 Leader 来进行生成** ，然后 Follower 负责收到 Leader 发来的 entry 后对自己的日志文件进行更新。

#### 三十四、介绍一下 UUID 和雪花算法，以及两者的区别？

​ UUID 是全球唯一 id 的简称，算法的底层是基于**时间+MAC 地址**来生成一个唯一的**32 个字符串**的 ID。

​ 优点：使用简单

​ 缺点：依赖于时间，所以**可能发生重复 ID**的问题、**无序** 、没有业务性、不安全（基于 MAC 地址，可能会泄漏 MAC 地址）、消耗存储空间大。

​ 补充：使用 UUID 作为数据库的主键 ID 有什么**缺点** ：

​ ①、**存储空间较大** ，占用 128 位空间大小。

​ ②、可能会消耗更多的网络带宽。

​ ③、无序 ID，**排序性能较差** ，可读性也较差。

​ ④、**索引效率差** ，在往数据库中插入数据的时候会**更容易发生页分裂** ，**影响插入的性能** ，不利于高写的场景。

​

​ 雪花算法：原始的**雪花算法是由 64 位组成** ，分别为：

​ **符号位 时间戳 机房 ID 机器 ID 序列号**

​ **1 位 41 位 5 位 5 位 12 位**

​ 优点：生成速度快、有序 ID、灵活性好，可以对雪花算法的各个位进行更改。

​ 缺点：发生时钟偏移后会生成重复的 ID；依赖于机房 ID 和机器 ID，所以发生扩缩容的时候容易出现问题；ID 有序可能会导致业务数据泄漏。

​ UUID 和雪花算法两者的区别就是：UUID 是依赖于时间和 MAC 地址来生成的。而雪花算法是依赖于符号位、时间戳、机房、机器号、序列号来生成的。

​

#### 三十五、请你手写一个双重检查机制的单例模式？

```java
    public class Singleton {
        private static volatile Singleton uniqueInstance;

        public Singleton() {

        }

        public static Singleton getUniqueInstance() {
            if (uniqueInstance == null) {
                synchronized (Singleton.class) {
                    if (uniqueInstance == null) {
                        uniqueInstance = new Singleton();
                    }
                }
            }
            return uniqueInstance;
        }
    }
```

​ 为什么要进行两次检查？**第一次检查**是为了**避免**已经创建对象之后还进行了**无意义的加锁**；**第二次检查**则是为了**避免重复创建对象**。

#### 三十六、Mybatis 中推荐使用#{}而不是${}，为什么，使用#{}比起使用${}有什么优点？

​ #{}的好处有：

1. **可以防止 SQL 注入** 。使用#{}，Mybatis 会**自动将参数值进行转义**，防止发生 SQL 注入。而使用${}的话，Mybatis 会直接将**参数拼接到 SQL 中** ，会发生 SQL 注入问题。
2. **可以完成自动类型转换** 。使用#{}，Mybatis 可以根据参数类型完成**自动的类型转换**，而使用${},Mybatis**不会进行自动类型转换** ，只会进行 SQL 的拼接，所以会发生**类型不匹配**的问题。
3. **可读性与可维护性更好** 。使用#{}可读性和可维护性更好。

#### 三十七、MyBatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？

​ B 标签是**可以**定义在 A 标签的后面的，Mybatis 中所有的**标签都是顺序解析的** ，所以当解析到 A 标签的时候，发现 A 标签需要 B 标签，但是 B 标签还没有解析，所以 A 标签会被标记为**未解析标签** ，然后会**继续解析后面的标签** ，当解析完后面的所有标签后，也就是 B 标签也被解析完毕了。会**重新解析**所有标记为**未解析的标签** ，此时 A 标签就会被解析成功了。

​

#### 三十八、说一下 HTTPS 是如何保证通信的安全性的？

​ 首先 HTTPS 协议是基于**SSL/TLS 协议**的，而 SSL/TLS 协议又是基于**TCP 协议**的。HTTPS 在进行通信的时候**底层**其实是使用的**对称加密算法** ，只是为了保证对称加密算法密钥的安全性，**对于对称加密算法的密钥进行了非对称加密**。

​ 其中对于对称加密算法的密钥的加密过程涉及到了第三方机构**CA 机构** ，流程是这样的：

1. CA 机构会提供一个**证书文件** ，这个证书文件中**包含** 了**服务器的公钥**和一些其他的数据信息。然后 CA 机构对这个证书文件使用**HASH 算法**生成一个文件**Hash 值** 。进一步再使用**CA 的私钥**对这个证书文件的**Hash 值进行加密**生成一个数字签名，发送给服务器。
2. 服务器将这个数字签名和证书文件发送给客户端。
3. 客户端使用 CA 机构的**公钥**对数字证书进行解密，得到文件的 Hash 值。同时使用相同的 HASH 算法对证书文件进行运算，判断生成的 Hash 值和解密出的 Hash 值是不是相同，相同才被认可，否则认为文件被篡改了。
4. 使用文件中的**服务器的公钥**对自己生成的用来进行**对称加密的密钥**进行加密，然后将加密后的数据发送给服务器。
5. 服务器对这个数据使用**自己的私钥进行解密**，可以得到最终进行对称加密通信的时候使用的密钥。
6. 以后的通信中都使用这个密钥进行加解密通信。

#### 三十九、说一下 MySQL 中主键索引和普通索引的区别？

1. 主键索引的每个值都**不能重复** ，是**唯一**的；而普通索引是**可以有重复的** ，**不是唯一的**
2. 主键索引的值**不能为 null** ;而普通索引的值**可以为 null**
3. 如果我们在指定了表中的主键，那么插入数据的时候会自动创建一个唯一的索引；而普通索引需要手动创建
4. 主键索引使用了**聚簇索引** ，意味着**索引顺序和物理存储顺序是一致**的；而普通索引是**非聚簇索引** ，意味着**物理存储顺序和索引顺序不一致**

#### 四十、说一下什么是回表？什么情况下会发生回表操作？

​ 回表是指：通过索引找到对应的索引记录之后，依然需要**再次访问数据库** 来获取完整的行数据。

​ 出现回表操作有两种情况：1. 命中了非聚簇索引 2. 覆盖索引失效

1. **命中了非聚簇索引** ：当查询使用了非聚簇索引，**查询到的列不能完全包含在索引中**，需要**借助索引中的主键**再次去数据库中查询完整的行数据。
2. **覆盖索引失效**：如果查询的列，**没有完全被索引覆盖**，需要再次去数据库中查询完整的行数据。

​

#### 四十一、数据库的索引结构使用的是 B+树而不是哈希表、AVL 树、红黑树、二叉搜索树、B 树，是因为什么？

​ 哈希表对于**范围查询和排序查询的性能是非常差的** ，每次获取一个数据都需要进行一次回表。

​ 二叉搜索树在元素有序插入的情况下**会变成一个链表** ，这将会严重降低查询性能。

​ AVL 树在插入和删除的时候会通过旋转来保证自身的平衡性，所以插入和删除的性能比较差。另外 AVL 中的每一个节点只能存储一个数据，而查询每个节点都需要进行一次磁盘的 IO 过程，如果我们查询的数据在多个节点的时候将会发生多次的磁盘 IO，性能较差。

​ 红黑树是黑节点平衡的，所以在插入和删除的时候也是会通过旋转来保证黑节点平衡的，所以插入和删除的时候的性能较差。另外和 B+树比起来红黑树的树高还是比较高的，可能会导致查询某些数据的时候会发生多次的磁盘 IO，查询性能下降。

​ B 树的每个节点既可以存储 key 又可以存储 value 而 B+树的非叶子节点只可以存储 key,叶子节点才可以存储 key 和 value,所以 B 树相对于 B+树来说高度更高，查询数据的时候可能会发生更多的磁盘 IO，查询性能较低。

​ B 树在进行查找的时候可能还没有到叶子节点就已经查询到数据了，而 B+树的查询一定是从根节点到叶子节点的过程，所以 B+树的查询性能比 B 树更加稳定。

​ B+树的叶子节点之间有链表相连，而 B 树是独立的，所以 B 树的范围查询性能比 B+树更差。

#### 四十二、讲一下 JVM 的内存模型？

​ Java 的内存模型大体可以分为两个部分，一个是运行时数据区域，另一部分是本地内存。

​ 其中运行时数据区域又分为：堆（线程共享）、程序计数器（线程私有）、虚拟机栈（线程私有）、本地方法栈（线程私有）

​ 本地内存又分为：元空间、直接内存

![](https://s3.bmp.ovh/imgs/2026/01/21/4764cd3a824ce5d5.png)

![](https://s3.bmp.ovh/imgs/2026/01/21/0d2adf3b4ec4f668.png)

#### 四十三、TCP 如何实现拥塞控制的？

​ TCP 的发送方通过**拥塞窗口**来实现拥塞控制。TCP 拥塞控制使用四种算法来实现：**慢开始** 、**拥塞避免** 、**快重传** 、**快恢复**

​

#### 四十四、说一下什么是 MySQL 的 MVCC 机制？以及原理？

​ MVCC 是**多版本并发控制**的缩写。目的是**提高**数据库的**并发性**。

​ 当一个**事务执行读命令**的时候，会使用**快照**读取。在**事务开始**的时候，生成一个快照，**其他事务的操作**对于当前这个事务来说是**不可见**的。并且在生成的这个快照中存放着当前事务开始的时候，其他**活跃的事务(已经开启但是事务还没有提交的事务)的 id 列表**，这些事务 id 对应的事务相对于当前这个事务来说就是不可见的，**即使活跃的事务提交了，当前事务也是看不到的**。所以当前视图中的数据是不会收到其他事务的影响的。 当这个事务开始的时候，如果**某个数据行有多个版本**，那么会**读取不晚于当前时间的最新的数据**。

​ 当一个事务执行**写操作**的时候，会给当前某行数据**开启一个新的数据版本**，然后将数据插入到这个新的数据版本中。新版本的数据的修改不会影响到原始的数据版本。

​ 而且 MVCC 会**定期的清除老版本的视图**的。

​ MVCC 机制的实现需要借助于**Read View、隐藏字段、undo log**

​ 对于**可重复读**和**读已提交**隔离级别来说，MVCC 机制读操作**生成快照的时间是不同的**，对于**读已提交**隔离级别，**每次 select 之前都会生成一个快照** 。对于**可重复读**隔离级别来说，**事务开启之后，*第一次*select 之前才会生成快照**。

​ **可重复读**隔离级别使用**MVCC+临键锁**其实可以保证**不出现幻读**的问题。比如对于**普通的 select 读取**，使用 MVCC 机制，事务开启之后，第一次 select 之前生成 Read View，一直持续到事务提交。在此过程中如果有其他的事务对数据进行了插入，**对于当前这个事务来说也是不可见的** 。对于**select...for update、insert、update**这种**当前读**的命令来说，读到的行使用**行锁** ，同时使用**间隙锁**来锁住读到的行的**附近的范围数据**来保证不出现幻读。

#### 四十五、说一下堆中的分代结构？

​ Java 堆分为新生代和老年代。其中新生代又分为 Eden、幸存者 0 区（from 区），幸存者 1 区(to 区)，其中幸 from 区和 to 区是会不断变化的，谁上次是 from 区，那么下次就是 to 区。

#### 四十六、Minor Gc 和 Full GC 有什么不同呢？什么时候会触发 Minor Gc？什么时候会触发 Full Gc?

​ 其中**Minor Gc 针对的是新生代**，而**Full Gc**针对的是**整个 Java 的堆内存**。

​ 当我们创建一个对象的时候，**如果 Eden 的空间无法放下时**，会触发一次 Minor GC。

​ **触发 Full GC**的情况有如下几种：

1. 当创建一个大对象的时候，是会直接放到老年代中的，如果此时老年代中的空间无法放下的话，就会触发 Full GC
2. 每次在执行**Minor GC 之前**，都会先判断**老年代中的空闲空间是否能够存放新生代中的所有对象**，如果不能并且老年代中的**空闲空间小于历次新生代晋升的平均大小**的时候，会触发 Full GC
3. 当元空间大小到达设置的阈值的时候，会触发 Full GC

#### 四十七、说一下 TCP 的三次握手过程？

​ 1.**第一次握手** ：Client 发送带有**SYN 标志**的消息给 Server,然后 Client 进入**SYN_SEND 状态**

​ 2.**第二次握手** ：Server 发送带有**SYN+ACK 标志**的消息给 Client,然后 Server 进入**SYN_RECV 状态**

​ 3.**第三次握手** ：Client 发送带有**ACK 标志**的消息给 Server，然后双方进入**连接状态**

#### 四十八、为什么必须要进行三次握手？

​ TCP 建立连接进行三次握手的根本目的是保证通信双方发送和接收消息都是正常的。

​ 第一次握手，**Client 既不能确定自己发送正常，也不能确定自己接收正常**。Server 可以**确认自己接收正常，对方发送正常**，但是**不能确定自己发送正常**。

​ 第二次握手，**Client 可以确认自己发送和接收都正常**。**Server 不能确认自己发送正常**

​ 第三次握手，**Server 可以确认自己发送和接收都正常** 。

​

#### 四十九、说一下 TCP 的四次挥手过程？

​ 1.**第一次挥手** ：Client 给 Server 发送一个带有 FIN 标志的消息，Client 进入 FIN_WAIT-1 状态

​ 2.**第二次挥手** ：Server 给 Client 发送一个带有 ACK 标志的消息，Server 进入 CLOSE_WAIT 状态，Client 进入 FIN_WAIT-2 状态

​ 3.**第三次挥手** ：Server 给 Client 发送一个带有 FIN 标志的消息，Server 进入 LAST_ACK 状态

​ 4.**第四次挥手** ：Client 给 Server 发送一个带有 ACK 标志的消息，Server 进入 CLOSE 状态，Client 在等待 2\*MSL 时候后没有收到 Server 的消息，变成 CLOSE 状态

#### 五十、常见的垃圾收集算法有哪些？

​ 1. **标记-清除算法**

标记清除算法分为两个阶段，第一个阶段是标记阶段，对所有的不会被回收的对象进行标记；第二个阶段是清除阶段，会将所有没有被标记的对象进行回收

缺点：会产生大量的内存碎片；收集效率比较低

​ 2. **复制算法**

将内存一分为二，当回收的时候，将所有不会被回收的对象复制到另一半内存中，然后一次性将一半的内存进行回收。

缺点：内存空间减少，每次只能使用一半的内存；不适合老年代，大对象的复制过程很慢。

​ 3. **标记-整理算法**

分为两个阶段，第一个阶段是标记阶段，对所有存活的对象进行标记；第二个阶段是整理阶段，会把所有存活的对象移动到一端，然后将后面的所有空间释放。

​ 4. **分代垃圾收集算法**

针对不同的区域使用不同的垃圾收集算法，比如针对新生代可以使用标记-复制算法；针对老年代可以使用标记-清除/标记-整理算法

#### 五十一、常见的垃圾收集器有哪些？

​ **串行垃圾收集器**

​ **单线程**的垃圾收集器，只有一个线程来执行垃圾收集的任务，同时进行垃圾收集的时候会**将用户的工作线程暂停** ，所以会导致**长时间的 STW（stop the world）**。其中串行垃圾收集器对**新生代**使用了**标记-复制**算法；对**老年代**使用了**标记-整理**算法。

​ **并行垃圾收集器**

​ 并行垃圾收集器是**多线程**垃圾收集器，对**新生代**使用**标记-复制**算法；对**老年代**使用**标记-整理**算法。

​ **CMS 垃圾收集器**

​ 第一款真正意义上的**并发**垃圾收集器，垃圾收集和用户线程**基本**上**同时工作 ** 。采用了**标记-清除**的算法。但是更加复杂，具体如下:

​ **初始标记** ：暂停其他的所有线程，标记**与 root 直接相连**的所有对象，速度很快

​ **并发标记** ：同时开启用户线程和标记过程，在这个过程中用户线程可能会不断的改变引用域。所以会**记录下发生引用变化的地方**

​ **重新标记** ：对发生引用变化的地方再次进行标记

​ **并发清除** ：清除所有没有被标记的对象。

​ 缺点：对 CPU 资源敏感、容易产生**内存碎片**、无法处理**浮动垃圾**

> 补充 ： 浮动垃圾是指 CMS 垃圾收集器在**重新标记**和**并发清除**的过程中，**用户线程是一直在执行的**，用户线程可能会**创建对象**或者**更新对象的引用域**把**原来可达的变成了不可达对象**，这些**新对象**或者**不可达对象**在**本次**垃圾收集的过程中不会被回收，而是需要等到下一次的垃圾回收，被称为浮动垃圾。

​ CMS 垃圾收集器在 jdk9 中被标记为过时，在 jdk14 中被移除了。

​ **G1 垃圾收集器**

​ G1 垃圾收集器适合**多核 CPU**和**大内存**的机器上，是 jdk9 之后的默认垃圾收集器。既可以保证尽可能少的 STW 的时间，又可以保证较高的吞吐量。

​ G1 垃圾收集器从**整体**上看是基于**标记-整理**算法的，从**局部**看是基于**标记-复制算法**的。

​ G1 垃圾收集器有**可预测**的**停顿时间**模型，我们可以指定**在 M 毫秒的时间段内进行垃圾收集的时间不能超过 N 毫秒** ，实现原理是 G1 垃圾收集器在后台维护了一个**优先列表** ，在我们规定的垃圾收集时间内**优先对性价比最高的区域进行垃圾回收** 。

#### 五十二、说一下 MySQL 的架构，以及一条 SQL 语句的执行过程是什么？

​ MySQL 架构分为两层，一个是**Server 层**，另一个是**存储引擎层**。其中存储引擎层是**插件式可插拔**的。

​ Server 层分为**连接器**、**查询缓存（MySQL8 之后移除）**、**分析器**、**优化器**、**执行器**。

​ 首先客户端连接 MYSQL 的时候，会经过**连接器进行身份认证和权限认证**。

​ 对于一条**查询 SQL**来说，**先判断是不是有权限**，如果**没有权限报错**，有的话**先经过查询缓存**，查询缓存中 SQL 语句作为 key,结果集作为 value,**如果存在的话直接返回，不存在的话经过分析器**。分析器对 SQL 语句进行**词法分析**和**语法分析**，**再到达优化器** ，由优化器选择一个 MYSQL 认为**最优的执行方案**，当执行方案确定之后，**到达执行器**，执行 SQL,去**调用存储引擎的接口**，然后**返回数据** 。

​ 对于一个**更新 SQL**来说，先进行**权限认证**，如果**没有权限就报错**，有的话直接到达**分析器**，进行**词法分析**和**语法分析** 。然后经过**优化器**来确定方案，最后由**执行器**去调用**存储引擎**的接口。但是对于更新 SQL 来说，会**记录日志**，**执行器**会记录**binlog 日志**，**Innodb 存储引擎层**会记录**redo log 日志** 。其中 redo log 和 binlog 日志的记录组成了**两阶段提交**，先由存储引擎执行 redo log 的 prepare，然后由执行器记录 binlog，完成之后存储引擎再提交 redo log 日志。

​ 如果 redo log prepare 完成，binlog 记录完成，但是宕机了，恢复后会通过下面的两种方式来**保证数据一致性**：

1. 判断 redo log 日志是否完整，如果 redo log 日志完整，就直接提交
2. 如果 redo log 日志只 prepare 没有 commit,这个时候会检查 binlog 是不是完整，如果 binlog 完整的话 redo log commit，否则直接回滚。

#### 五十三、说一下 Explain 中各个列代表什么？

​ 1.**id**

​ SELECT 标识符，**同一个 id 的话从上往下依次执行**，**如果 id 不同的话，id 越大优先级越高** 。

​ 2.select_type

​ 查询类型，如果是普通查询为 simple,如果包含子查询的话，外层查询标识为 Primary,如果是 UNION 查询的话，标记为 UNION；子查询中的第一个 SELECT 标识为 SUBQUERY

​ 3.table

​ 查询的表名

​ 4.possible_keys

​ 查询**可能用到的索引**

​ 5.type

​ 查询执行的类型，值有 system>const>range>index>ALL

​ **const** ：代表表中最多只有一行匹配的数据，一次查询就能查到

​ **range** : **对索引进行了范围查询**

​ **index**: **查询遍历了整棵索引树**

​ **ALL** : **全表扫描**

​ 6.key

​ 查询真正用到的索引

​ 7.ken_len

​ 索引的长度

​ 8.rows

​ 查询实际扫描的行数

​ 9.ref

​ **在查询过程中使用索引时，索引列与哪个值或表达式进行比较**

​ **const** : 索引列与常量进行比较

​ **column_name**:索引列与某一列进行比较

​ **NULL** :索引列没有任何参考值

​ 10.filtered

​ 经过过滤后，**留下的行数与总行数的比值**，如果 filtered 值越小说明我们过滤掉的数据越多，索引越好。

#### 五十四、什么是自动拆装箱？以及什么时候会触发拆箱和装箱的操作？

​ 装箱：将基本数据类型变成对应的包装类型。

​ 拆箱： 将包装类型变成对应的基本数据类型

​ 注意： 如果频繁的拆装箱的话，也会严重影响程序的性能，所以要避免频繁的拆装箱。

​ 自动装箱举例： public void print(Integer val) 调用的时候使用 print(10)

​ 自动拆箱举例： public void print(int val) 调用的时候 Integer val=10;print(val)

#### 五十五、接口和抽象类有什么相同和不同？

​ 相同:

1. 都不能被实例化
2. 都可以定义抽象方法
3. 都可以定义有默认实现的方法

​ 不同：

1. 接口定义行为，实现一个接口就具备了接口中的所有行为，而抽象类多用于代码复用，强调的是所属关系
2. 一个类只能继承一个抽象类，但是可以实现多个接口
3. 接口中的成员变量只能使用 public static final 修饰，必须有初始值；抽象类中的成员变量默认 default,子类可以重新定义或者重新赋值

#### 五十六、什么是深拷贝、浅拷贝、引用拷贝?

​ 深拷贝：将整个对象完全复制，包括这个对象所包含的内部对象

​ 浅拷贝：在堆上创建一个对象，如果原对象内部有引用，则直接复制这个引用

​ 引用拷贝: 两个不同的引用指向同一个对象

#### 五十七、Java 中常见的 IO 模型？重点说一下 NIO 模型

​ BIO: 同步阻塞 IO 模型

​ 当**应用程序**调用**read**请求后，**阻塞等待**，直到数据**由内核拷贝到用户空间**中。

​ NIO: 同步非阻塞 IO 模型

​ 应用程序调用**select/epoll**来询问内核**数据是否准备就绪**了，当内核将数据准备就绪后**给应用程序发送一个 ready 请求**，然后**应用程序再去调用 read 请求**，但是在数据由内核拷贝到用户空间的时候依然是阻塞的。

​ 使用 I/O 多路复用模型，核心组件是**Buffer**、**Selector** 、**Channel** 。

​ 其中每个客户端**读写数据**会直接**和 buffer 进行数据交互**，而每个 buffer 又对应一个 channel,多个 channel**注册**到一个 Selector 上，我们可以通过一个线程来操作 selector 就能实现管理多个 client。

​ **读数据的时候是将 Channel 中的数据读到 Buffer 中，写数据的时候是将数据从 Buffer 写到 Channel 中，Channel 是一个全双工的数据通道** 。

​ Selector 是基于**事件驱动**的 IO 多路复用模型。Selector 会**轮询监听**注册在其上的 Channel,当一个 Channel 发生了**接收连接** 、**连接完成** 、**准备好进行读取** 、**准备好进行输入数据** 的事件后，Selector 就会监听到，然后将这个 Channel 加入到**就绪集合**中，然后执行对应的 IO 操作。

![](https://s3.bmp.ovh/imgs/2024/07/31/ce9822c6abd8db2d.png)

​ AIO: 异步 IO 模型

​ 异步非阻塞 IO 模型，当应用程序发起 read 请求后，**不阻塞**而是继续去执行别的任务，当内核将数据拷贝完之后，再通过**回调**来通知应用程序继续执行当前任务。

#### 五十八、什么是 Java 中的反射？以及反射的优缺点是什么？

​ Java 中的反射让我们可以在运行时分析对象，并可以执行对象中的方法,获取对象中的属性。

​ 优点： 可以让我们的代码更加灵活；为各种框架提供开箱即用的功能提供了方便。

​ 缺点： 性能稍微差点；会带来安全问题，比如**反射会逃脱泛型参数的安全检查** 。

#### 五十九、什么是 SPI？SPI 与 API 的区别是什么?

​ SPI 是服务提供者接口，将服务**调用方**和服务**实现方**进行**解耦**，提升程序的扩展性、可维护性。

​ **调用方**和**实现方**之间一般都是通过**接口**来进行连接，所以我们在调用方和实现方之间增加了一个接口层。

​ API 的**接口是由实现方来定义和实现的**，属于实现方 。而 SPI 的**接口是由调用方来定义的** ，属于调用方，不同的实现方按照调用方给的这个规则进行实现即可。

#### 六十、说一下 TCP/IP 四层模型和 OSI 七层模型

​ TCP/IP 四层模型：网络接口层、网络层、传输层、应用层

​ OSI 七层模型： 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层

#### 六十一、你知道 Java 中的哪些语法糖？

​ 增强 for 循环、try-with-resource、lambda 表达式、枚举、泛型、自动拆装箱、可变长参数

#### 六十二、AtomicInteger 底层是如何保证原子性的？

​ AtomicInteger 底层保证原子性是**无锁**的，通过**volatile**修饰 value,保证可见性，然后通过 unsafe 类来使用**CAS+重试机制**保证了原子性。

#### 六十三、说一下 CAS 的问题？

1.  **ABA 问题**

    如果我们的**V 初始值为 A**，然后在我们进行更新之前，由**另一个线程进行了修改改成了 B 又改回了 A**，那么当我们要进行提交的时候发现 V 还是 A 就认为 V 没有被修改过，**可以成功提交**，这就是 ABA 问题

    2. **循环时间长开销大**

    CAS 更新失败后会**不断的进行重试**，开销还是比较大的

    3. **只能保证一个共享变量的原子操作**

    CAS 只能保证**一个**共享变量的原子操作，如果涉及到**跨共享变量**的场景，CAS 是**无法保证原子性**的

#### 六十四、什么是偏向锁？

​ 偏向锁是 JVM 中的一种锁优化策略，主要来提高单线程环境下的锁性能。偏向锁可以减少单线程环境下的锁获取和释放。

​ 当一个线程第一次获取锁的时候，JVM 会将对象头中的锁标记为偏向模式，并将线程的 ID 记录在对象头中。

​ 对于已经偏向的锁，持有锁的线程再次访问资源的时候，不需要获取锁

​ 偏向锁的持有线程退出同步块的时候，不需要显式的释放锁，因为锁已经偏向该线程了。

​ 如果有其他线程尝试获取偏向锁的时候，偏向锁会升级为轻量级锁或者重量级锁

#### 六十五、说一下 synchronizd 的底层原理？

​ synchronized 是**基于 JVM 层面**的。并且针对 synchronized 修饰代码块和修饰方法的原理有所不同。

​ **synchronized 修饰代码块** ，通过**monitorenter**和**monitorexit**指令来标识，同步代码块的**起始位置**和**结束位置**。基于对象监视器来实现的。

​ **synchronized 修饰方法** ，通过**ACC_SYNCHRONIZED** 标志来标识这是一个同步方法。如果是**实例方法**会**尝试获取实例对象的锁**，如果是**静态方法**会尝试**获取当前 class 的锁** 。

#### 六十六、说一下线程池的几个核心参数是什么？

1. 核心线程数
2. 最大线程数
3. 工作队列
4. 存活时间
5. 时间单位
6. 拒绝策略
7. 线程工厂

#### 六十七、说一下线程池的工作流程是什么样子的？

​ 首先当一个任务到达的时候如果工作线程还有空闲的话，直接交给空闲的工作线程来工作，如果工作线程满了，先判断工作队列是不是已满，如果没有满就放在工作队列中，如果工作队列满了，会判断线程池中的最大线程数是不是达到了设置的值，如果没有达到那么就会启动线程去执行队列中的任务，然后把任务放在队列中；如果线程数达到了最大线程同时队列也已经满了，则会执行拒绝策略。

![](https://s3.bmp.ovh/imgs/2024/07/18/146fed88fe886397.png)

#### 六十八、CountDownLatch 和 CyclicBarrier 的区别是什么？

1. CountDownLatch 是**一次性**的，CyclicBarrier 是可以**重复使用**的
2. CountDownLatch 用于到**计数器达到 0**的时候，继续执行；而 CyclicBarrier 则是多个线程**同时**达到**某个屏障**的时候继续执行
3. CountDownLatch 多用于**一次性**的等待操作；而 CyclicBarrier 多用于**多次同步**的场景

#### 六十九、为什么不能把服务端发送的 ACK 和 FIN 合并起来，变成三次挥手？

​ 因为当服务端接收到客户端发来的 FIN 标志消息后，给客户端返回一个 ACK 标志的消息是告诉客户端，我知道你要关闭连接了。但是**服务端可能依然有数据需要进行传输**，当服务端把消息传输完毕之后，才会给客户段发送一个 FIN 标志的消息，告诉客户端我没有要发送的数据了，可以关闭连接。

​

#### 七十、什么是泛型？使用泛型的好处是什么？什么是泛型擦除机制？

​ 泛型是 Java 中的一个特性。

​ 使用泛型的好处是：① 可以增强代码的可读性和稳定性 ② 编译器在编译的时候对泛型参数进行类型检测，我们可以指定参数的类型是什么

​ **泛型擦除** ：编译器在**编译**的过程中，会将所有的**泛型都擦除** ，这就是泛型擦除机制。比如会将**T 类型擦除为 Object 类型** ，会将**T extends xxx 类型擦除为 xxx 类型**。

​ 擦除是为了**不创建新的类型**，**降低**虚拟机启动时的**开销** 。

​ 有了**泛型擦除机制** ，为什么还要使用泛型而不直接使用 Object 类型呢?

​ 1.使用泛型可以在**编译**的阶段完成**类型检测**

​ 2.编译器可以帮我们将返回结果进行自动的**类型转换**

​ 3.使用 Object 类型的话，需要自己**手动实现强制类型转化** ，增加了编码的复杂度，降低了代码的可读性

​ 4.泛型可以使用**自限定类型** ，比如 T extends Comparable

#### 七十一、JDK 动态代理和 CGLIB 动态代理的区别？

​ JDK 动态代理**只能代理实现了接口的类**或者**接口** ，而**不能代理没有实现接口的类** 。而 CGLIB 动态代理可以代理没有实现接口的类。

​ **CGLIB 动态代理** 的底层其实是**生成**一个**被代理类的子类**，然后来实现对目标类的代理。所以 CGLIB**无法代理**被 final 修饰的类和方法

​ JDK 动态代理的性能比 CGLIB 动态代理的性能更高。

#### 七十二、静态代理和动态代理的区别是什么？

​ **静态代理**会在**编译**的时候将对应的**接口** 、**实现类** 、**代理对象**加载成为 class 文件；而**动态代理**是在**运行**的时候生成**类字节码**，然后**加载到 JVM 中** 。

​ 静态代理的**灵活性**比动态代理**差很多**。如果我们要在一个接口中增加一个方法，那么**对应的接口和实现类都需要进行修改**；动态代理比较灵活，可以**直接代理实现类** ，并且**不需要**针对**每一个目标类都创建一个代理类** 。

#### 七十三、HTTP 协议是无状态的，那么应该如何保存用户状态？

​ 使用**Session**来保存用户状态，最经典的场景就是购物车，因为 HTTP 协议是无状态的，添加购物车的时候我们不知道是哪个用户来添加的，所以我们一般是由**服务器端**生成一个 Session,使用这个 Session 来**标识** 、**跟踪**用户。**客户端**将 Session 信息保存在**Cookie**中进行用户的追踪。如果**Cookie 被禁止了** ，一般是通过**URL 重写**，**将 SessionID 写到 URL 的后面** 。

#### 七十四、说说 HTTP1.0 和 HTTP1.1 的区别？HTTP1.1 和 HTTP2.0 的区别？HTTP2.0 和 HTTP3.0 的区别

​ HTTP1.0 和 HTTP1.1 的区别：①HTTP1.0 是**短连接**，HTTP1.1 是**长连接**②HTTP1.1 增加了**更多的状态码**③HTTP1.1 增加了**更多的缓存策略**④HTTP1.1 可以节省带宽，HTTP1.0 不能只传输对象中的一部分，**只能将整个对象传输**，而 HTTP1.1 是**可以只传输对象的一部分的**，并且 HTTP1.0**不支持断点续传**

​ HTTP1.1 和 HTTP2.0 的区别：①HTTP2.0 使用了**多路复用**，多个请求可以使用**同一个 TCP 连接**，而 HTTP1.1 每个请求都需要一个独立的连接 ②HTTP1.1 只能对**body 进行压缩**，**不能**对**header 进行压缩**，而 HTTP2.0 可以对 header 进行压缩 ③HTTP2.0 使用**二进制帧**的格式进行传输，而 HTTP1.1 使用**文本格式**进行传输 ④HTTP2.0 支持**服务器推送**，我们可以将多余的信息一起推送给客户端，而 HTTP1.1 不可以

​ HTTP2.0 和 HTTP3.0 的区别：①HTTP2.0 是基于**TCP 协议**的，而 HTTP3.0 是基于**QUIC 协议**的，底层是 UDP 的改进 ②HTTP2.0 需要**三次握手**，而 HTTP3.0 只需要**一次握手**③HTTP2.0 多个请求复用一个 TCP 连接，如果一个请求发生了丢包问题会**阻塞**其他的请求，而 HTTP3.0 一个连接建立多个独立的数据流，各个数据流之间不影响，发生丢包问题不会发生阻塞 ④HTTP3.0 发生丢包、延迟等网络问题后可以**更快的进行恢复和重传**

#### 七十五、Cookie 和 Session 的区别？

​ **Session**是**服务器**用来**记录用户状态**的，是由**服务器生成和存储**的，更加**安全**。

​ **Cookie**是保存在**客户端**的，如果使用 Cookie 的话**敏感数据不要保存在 Cookie 中**或者进行**加密保存**，然后由**服务器进行解密**。

#### 七十六、Kafka 消息消费失败后会不会卡住？

​ Kafka 消息消费失败后，**不会卡住** ，当**达到重试次数**后依然无法处理的话，就会**跳过这个消息**，继续消费后面的消息。Kafka 中**默认重试次数为 10 次**，并且**重试时间为 0**，也就是**立即重试**。我们可以引入死信队列，将重试后依然无法成功消费的消息放到死信队列中，然后进行人工干预。

#### 七十七、ElasticSearch 中 keyword 和 text 的区别是什么？

​ **keyword 不走分词器**，而**text 走分词器**，并且 keyword 的查询效率更高。

#### 七十八、DNS 服务器有哪些？

​ 1.**根 DNS 服务器** ：全世界有**13 组**，**记录顶级域 DNS 服务器的 IP 地址** 。

​ 2.**顶级域 DNS 服务器**：比如 com、net、org、edu, **记录权威 DNS 服务器的 IP 地址** 。

​ 3.**权威 DNS 服务器**

​ 4.**本地 DNS 服务器** ：每个互联网服务提供商都有一个自己的本地 DNS 服务器，当主机发起 DNS 请求后，该请求发到本地 DNS 服务器上然后起着一个代理的作用，将 DNS 请求发到 DNS 层次结构中。

#### 七十九、说一下 ArrayList 的扩容机制？

​ 当我们调用 ArrayList 的无参构造方法的时候，默认是创建了一个空数组，当我们**放进去第一个元素的时候才扩容为 10**，之后如果超过 ArrayList 的容量的时候，每次**扩容为原来容量大小的 1.5 倍左右**。当我们往 ArrayList 中添加元素的时候，**先判断添加之后的容量是不是会超过当前容量**，如果超过就会执行扩容。

```java
int newCapacity=oldCapicity+(oldCapacity>>1);
```

#### 八十、HashMap 为什么线程不安全？

​ **JDK7**的 HashMap 在**多线程**中会发生**扩容导致死循环**、**数据丢失**问题，JDK8 之后虽然没有了扩容导致死循环问题，但是**依然存在数据丢失问题**。

​ **JDK7**在**多线程扩容**的时候采用的是**头插法**，会导致链表中的节点指向错误的位置，形成了**环形链表** ，导致查询数据的时候发生了死循环，**JDK8**之后将头插法改成了**尾插法**来避免了死循环问题。

​ 数据丢失问题举个例子：有两个线程 1，2，**同时执行 put 操作**，线程 1 在插入数据的时候，判断发生了哈希冲突，此时 CPU 时间片结束了，线程 1 挂起来，**线程 2**判断发生了哈希冲突，解决后**先完成了数据的插入**，此时线程 1 又获得了 CPU 时间片，因为之前已经完成了哈希冲突的判断了，直接插入数据，导致线程 2 插入的数据被线程 1 插入的数据覆盖了。

#### 八十一、ConcurrentHashMap 为什么 key、value 不能为 null?

​ 主要是因为**二义性**的问题。对于**多线程环境**下，我们**不能使用 ConcurrentHashMap 的 containskey(key)来判断这个 key 是不是存在** ，所以如果我们 key、value 为 null,我们**无法判断本身就不存在还是存在就是 null**

​ 但是对于 HashMap 来说，key 是可以作为 null 的，因为**单线程环境**下是**可以使用 containsKey(key)来判断是不是存在这个 key**的。

#### 八十二、ThreadLocal 的 key 是**弱引用**，那么在 ThreadLocal.get()的时候，发生**GC**之后，key 是否为**null**

​ 在 ThreadLocal.get()的时候，其实在**调用这个方法的时候是存在强引用的**，所以此时**发生 GC 之后，key 是不会被回收的**，是**不会变成 null 的**，但是 ThreadLocalMap 中的 key 是 ThreadLocal 的**弱引用**，所以如果我们**没有调用 get()方法**的时候发生了 GC 的话，**key 是可能被回收变成 null 的** ，此时**会出现 key 为 null**，但是 value 不为 null 的情况，如果这种 ThreadLocalMap 多的话，就会造成**内存泄漏** 。

#### 八十三、说一下 ThreadLocalMap 中的 Hash 算法?

​ **每创建一个 ThreadLocal 对象**，这个**ThreadLocal.nextHashCode**就会增加一个**斐波那契数** ，然后使用这个**斐波那契数作为哈希因子** ，然后会让**哈希值分布的更加均匀** 。

#### 八十四、说一下 ThreadLocalMap 是如何处理哈希冲突的？

​ 因为 ThreadLocalMap**底层没有使用链表** ，所以在发生哈希冲突的时候使用的是**开放寻址法** 。当通过哈希算法计算哈希值来确定**slot 槽位** ，如果这个 slot 槽位已经有数据了，如果 entry 中的**key 和当前的 key 相等的话** ，直接**进行更新** ；如果 entry 中的 key 和当前的 key**不同**则会向后扫描，**如果碰到了 key 相同的 entry 进行更新**，如果没有碰到 key 相同的 entry 碰到了**slot 槽位 null 的话** ，**直接插入** 。

#### 八十五、说一下 ThreadLocalMap 的两种过期 key 的清除方式？

​ ThreadLocalMap 中的**过期 key**的清除方式有两种，**探测式清除** 、**启发式清除** 。

​ 探测式清除，启发式清除都是**遍历每个 slot 然后寻找 key 为 null 需要被清除的 entry** ,然后进行清除。但是探测式清除和启发式清除的**执行时机**是不同的，探测式清除是在执行 get(),set(),rehash()方法的时候会进行触发。而**启发式清除可以在任何时候触发** ，不一定是在扩容和 rehash 的时候继续触发，所以可以更灵活的管理内存。

#### 八十六、说一下 ThreadLocalMap 的扩容机制？

​ 当我们在执行**ThreadLocalMap.set()** 方法的时候**可能会触发清除** ，清除之后如果**entry 的数量超过了阈值**,即 size>=threshold，（补充：**threshold=len\*2/3**)。然后会**触发 rehash()方法** ，在执行 rehash()的时候会进行**过期 key 的清除** ，如果清除完成之后**size>=3/4threshold 的话** ，则会**触发扩容** ，**扩容成原来容量的 2 倍** 。

#### 八十七、CompletableFuture 的底层原理？

​ CompletableFuture 实现了**Future**和**CompletionStage**两个接口，其中 Future 接口是**异步编程**中的一种**设计模式** ，我们可以得到异步任务的结果，CompletionStage 可以将一个任务分为**多个阶段或者步骤** ，然后可以将这些阶段和步骤**编排组合**起来完成一个任务。

​ 所以 CompletableFuture 是基于这两个接口来实现的。

#### 八十八、什么是通配符？通配符的好处是什么？

​ 通配符是**？** 。**泛型类型是固定的** ，某些场景使用起来不灵活。通配符可以**允许类型参数变化** ，用来解决**泛型参数无法协变**的问题。

​

#### 八十九、通配符？和常用的泛型 T 有什么区别？

​ 1.**T 可以用于声明变量或常量，而？不可以**

​ 2.**T 在编译期间会被擦除为 Object，而?用于捕获具体类型**

​ 3.**T 一般用来声明泛型类和方法，而？一般用来作为泛型方法的调用代码或形参**

#### 九十、说一下什么是上边界通配符和下边界通配符？

​ **上边界通配符**：**extends**指定传入的类型实参必须是指定类型的**子类** 。比如<? extends Person> 指定实参比如是 Person 的子类

​ **下边界通配符** ：**super**指定传入的类型实参必须是指定类型的**父类** 。比如<? super Employee> 指定实参必须是 Employee 的父类

#### 九十一、泛型有哪些限制？

​ 1.**只能声明不能实例化 T 泛型变量**

​ 2.**不能用 static 修饰泛型变量**

​ 3.**泛型参数不能是基本数据类型，必须是 Object 的子类**，所以需要用对应的包装类型

​ 4.**不能实例化泛型数组**

#### 九十二、什么情况会导致@Transactional 注解失效

​ 1.@Transactional 注解其实是基于 Spring AOP 来实现的。如果我们的**@Transactional 注解加在了非 public 方法上** ，会导致@Transactional 注解失效。

​ 2.**手动捕获异常但是没有抛出异常** ，会导致@Transactional 失效

​ 3.**@Transactional 标注的方法内部调用了同一个类中的其他@Transactional 注解标注的方法**

#### 九十三、说一下 MySQL 主从复制的过程是什么？

​ 1.**主库将数据库中的变化写入 binlog 中**

​ 2.**从库连接主库**

​ 3.**从库创建一个 io 线程请求获取主库更新的 binlog**

​ 4.**主库创建一个 binlog dump 线程来发送 binlog,从库的 io 线程负责接收 binlog**

​ 5.**从库的 io 线程将接收到的 binlog 写入到 relay log 中**

​ 6.**从库的 SQL 线程读取 relay log 同步数据到本地**

#### 九十四、什么是水平分库、什么是垂直分库、什么是水平分表、什么是垂直分表？

​ **垂直分库**：**将单一数据库按照业务进行划分，每个业务使用单独的数据库**

​ **水平分库**：**把一个数据表按照一定的规则拆分到不同的数据库中，每个库放在不同的服务器上**

​ **垂直分表**：**将一个表按照不同的列进行拆分，拆成多个表**

​ **水平分表**： 将一个多行的表按照一定的规则拆成多张表，比如 1~30w 放在一张表，30w~60w 放在另一张表

#### 九十五、常见的分片算法有哪些？

​ 1.**哈希算法** ：根据分片键进行哈希运算，确定分表位置，数据随机分布，分布的较均匀

​ 2.**一致性哈希算法** ：相比于哈希算法有更好的扩展性

​ 3.**范围分片** ：按照特定的范围区间来进行分配数据。

​ 4.**地理位置分片** ：根据地理位置来进行分片

#### 九十六、如何减少数据库的主从延迟问题？

​ 1.**从库使用主库性能一致或者更好的机器**

​ 2.**避免使用大事务和慢 sql**，将一个大事务拆成**批量操作**，对慢 sql 进行**优化**

​ 3.**增加网络带宽**

​ 4.**从库的数量应该合理安排**，**不要设置太多的从库** ，如果有太多的从库，可以对从库进行**分层**，让上层的从库再将数据同步到下层从库

​ 5.从库在进行数据同步的时候既需要执行主从的写操作，又要执行到来的读操作，所以会消耗很多 CPU 资源，所以我们可以**增加缓存**或者**使用一主多从的架构**来减轻单一从库的读写压力。

#### 九十七、为什么第四次挥手客户端需要等待 2\*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？

​ 因为在第四次挥手是客户端给服务端发送 ACK 标志的消息，服务端可能没有收到，导致服务端一直给客户端发送带有 FIN 标志的消息，如果客户端在 2*MSL 内再次收到了服务端发来的 FIN 标志的消息后，会重新发送带有 ACK 标志的消息，并重新等待 2 * MSL 时间，**防止服务端没有收到 ACK 而不断给客户端发送 FIN** 。

#### 九十八、Redis 持久化策略有哪些？详细说一下 AOF 的流程是什么？

​ Redis 的持久化策略有三种，**RDB、AOF、RDB+AOF 混合模式**。

​ AOF 的流程：1.**命令追加 append 到 AOF 缓冲区中** 2.AOF 缓冲区调用 write 将缓冲区中的内容写到**操作系统缓冲区**中 3.系统缓冲区调用**fsync**将系统缓冲区中的数据**持久化到磁盘中** 。

#### 九十九、AOF 持久化方式有哪些？

​ AOF 的持久化方式就是 fsync 的时机，主要有三种：

​ 1.**appnedfsync always**: 主线程 write 后立刻调用 fsync 进行刷盘

​ 2.**appendfsync everysec:** 主线程调用 write 后立刻返回，由后台线程每秒调用 fsync 进行刷盘

​ 3.**appendfsync no** : 主线程调用 write 立即返回，由操作系统自己决定什么时候调用 fsync 进行刷盘

​

#### 一百、AOF 追加文件为什么在执行完命令之后而不是在执行命令之前？

​ 1.避免了语法检查，命令执行后就不需要进行语法检查了

​ 2.不会阻塞命令的执行

​ 缺点：

​ 1.会阻塞后面的命令的执行

​ 2.如果命令执行完后还没有写入 aof 文件中发生了宕机，那么会丢失数据

#### 一百零一、AOF 校验机制了解吗？

​ AOF 会对**文件内容**使用**CRC64 算法**计算得到一个数字，**保存在文件的末尾** 。当我们启动 Redis 的时候，会**对 AOF 文件中的内容进行 CRC64 算法计算得到一个校验码**，然后**用这个校验码和 AOF 文件末尾的校验码进行比较** ，如果不一致会报错。

> 补充：CRC64 算法是一种**64 位循环冗余校验算法**。多用于检测数据在传输和存储过程中是否出现错误。

#### 一百零二、AOF 和 RDB 的优缺点是什么？

​ AOF 的优缺点:

​ 优点：可读性好；可以做到秒级持久化；

​ 缺点：生成的 aof 文件体积比较大；数据恢复的时候其实是依次执行 aof 文件中的命令，所以恢复时间比较久

​ RDB 优缺点：

​ 优点：生成的 rdb 文件是压缩后的二进制文件，体积小；数据恢复速度快

​ 缺点：不同版本的 redis 之间可能存在 RDB 文件的兼容性问题；无法做到秒级持久化；可读性差；

#### 一百零三、ES 中的各种概念你知道吗?

​ index: 相当于 MySQL 中的表

​ document: 相当于 MySQL 中的行

​ mapping: 相当于 MySQL 中表的定义

​ filed: 相当于 MySQL 中的列

#### 一百零四、为什么 Redis 会有内存碎片问题？

​ 1.Redis 在申请内存的时候**会申请比需要存储的内存更多的内存**，比如实际需要存储的内存需要 100MB，那么 Redis 可能会向操作系统申请 200MB 的内存

​ 2.**频繁的修改 Redis 中的数据也会导致内存碎片的产生** 。因为当 Redis 中的键删除的时候，Redis 不会轻易将内存归还给操作系统

#### 一百零五、TCP 和 UDP 的区别是什么？

​ 1.**TCP 是面向连接的** ，建立连接需要三次握手，释放连接需要四次挥手，而 UDP 不是面向连接的。

​ 2.**TCP 可以保证可靠传输**，而 UDP 不能保证可靠传输，只负责发出去，发出去之后就不管了。

​ 3.**TCP 是有状态的**，会记录消息是否发送了，是否被成功接收了。而**UDP 是无状态的**

​ 4.**TCP 的首部开销比 UDP 大**

​ 5.**TCP 的传输效率比 UDP 低**

​ 6.**TCP 只支持点对点通信**，而 UDP 支持**一对一**、**一对多**、**多对一**、**多对多**

​ 7.**TCP 面向字节流，UDP 面向报文**

#### 一百零六、说一下使用 TCP 的协议和使用 UDP 的协议有哪些？

​ 使用 TCP 的协议：**HTTP 协议**、**FTP 协议**、**SMTP 协议**、**SSH 协议**、**POP3 协议**

​ 使用 UDP 的协议：**HTTP3.0 协议**、**DHCP 协议**、**DNS 域名系统（其实它同时支持 TCP 和 UDP）**

#### 一百零七、IPV4 和 IPV6 的区别是什么？

​ 1.IPV4 和 IPV6 的最主要的区别就是 IPV6 可以分配更多的 IP 地址。

​ 2.IPV4 是用.分割的，而 IPV6 是用:或者::分割的

#### 一百零八、如何获取客户端真实的 IP 地址?

​ 1.通过**请求头**中的**X-Forwarded-For**获取，但是不可靠，因为 X-Forwarded-For 是可以篡改的

​ 2.通过**TCP Options 字段**承载真实 IP 地址。

#### 一百零九、说一下什么是 NAT 协议？

​ NAT 协议是**网络地址转换**。主要用于**不同网络之间进行 IP 地址转换** 。我们的一个**局域网中的所有设备**可以通过 NAT 协议**映射成一个公网 IP 地址接入万维网中** ，从而实现了**多个设备通过单一的公有 IP 地址访问互联网**，既可以**缓解 IPV4 地址不够用的问题**，又可以**隐藏局域网中的网络拓扑结构**，使得**外部网络无法直接访问局域网中的设备**，**提高了局域网的安全性** 。

#### 110、说一下 ARP 协议的工作过程？

​ ARP 协议是用来进行 IP 地址和 MAC 地址之间转换的。ARP 的工作过程也分为两类，第一类是同一个局域网下的 MAC 寻址。第二类是不同子网中的网络设备的 MAC 寻址。

​ ARP 协议的核心是 ARP 表，每个网络设备都会维护一个 ARP 表，其中存放 IP 地址和 MAC 地址的映射。ARP 表中的数据以<IP 地址，MAC 地址，TTL>三元组的形式保存。

​ **同一个局域网中的设备进行 MAC 寻址的过程**（主机 A 将消息发送给主机 B）：

​ 1.主机 A**先查询自己的 ARP 表**，看看有没有对应的主机 B 的 IP 地址和 MAC 地址的映射，如果有就直接找到了主机 B 的 MAC 地址

​ 2.如果没有主机 B 对应的 MAC 地址，则**主机 A 会发生一个广播**，同一局域网中的所有的网络设备都会接收到这个广播消息，然后通过**判断这个广播消息中的目的 IP 地址是不是自己的 IP 地址**，如果不是则直接丢弃，如果是自己的 IP 地址，则先将这个广播中的**源 IP 地址和源 MAC 地址放到自己的 ARP 表中**，然后再给主机 A 发送自己的 MAC 地址

​ 3.主机 A 收到消息后，将主机 B 的 IP 地址和 MAC 地址放到自己的 ARP 表中

​ **不同子网中的网络设备的 MAC 寻址过程**（主机 A 发送消息给主机 B）：

​ 1.主机 A 先**判断自己的 ARP 表中是否存在**主机 B 的 IP 地址和 MAC 地址的映射关系

​ 2.由于目标主机和主机 A 不在同一个局域网中，所以**ARP 请求无法直接到达**，这时候**路由器**会根据**路由表**将 IP 数据包转发给目标局域网

​ 3.数据包到达目标局域网之后，主机 B 会进行**ARP 应答**，**提供自己的 MAC 地址**

​ 4.主机 A 接收到 ARP 应答后，会将主机 B 的 IP 地址和 MAC 地址的映射关系保存到自己的 ARP 表中

#### 111、Redisson 如何实现的分布式锁？

​ Redisson 实现分布式锁，其实**底层还是依赖于 Redis**,依赖于 Redis 的命令：**Set key value EX 3 NX**

​ 但是 Redisson 在此基础上增加了**看门狗机制**，会根据你的业务是否处理完来对锁的**过期时间进行续期** ，**默认过期时间是 30s** ,然后**每过 10s 后进行判断是否需要续期**，如果**需要续期就再将过期时间设置为 30s** ；

​ 其中 Redisson 在进行判断是否续期的时候，会进行**异步续期** ，判断是不是当前持有锁的线程，然后再**使用 Lua 脚本来进行续期** 。

#### 112、什么是 Gossip 协议？Gossip 协议的传播模式有哪些？Gossip 协议有什么优缺点？

​ Gossip 协议是**分布式系统**中用来进行**数据/信息共享**的协议。

​ Gossip 协议的传播模式：**反熵模式**、**谣言传播**

​ 反熵模式：**熵代表两个节点之间的数据混乱程度**。通过反熵模式可以将两个节点之间的数据进行同步达到**最终的一致性**。其中反熵模式有**推、拉、推拉结合三种方法**。**推：将自己的数据推给别的节点，让它来和自己进行数据同步** ；**拉：拉取别的节点的数据来和自己的数据进行同步** ；**推拉：将自己的数据推给别的节点，同时拉去别的节点的数据，然后来进行数据的同步** 。

​ 缺点：反熵模式的缺点是如果我们**节点数量比较多**，并且**节点数量会动态的变化的话**，那么我们的反熵模式就不太适合了。并且因为是会**将全部的数据进行传输**，所以对网络的**带宽消耗还是比较大** 。

​ 一般我们在使用反熵模式的时候会设计成一个**闭环**，而不是随机选择一个节点来进行反熵，这样可以让所有的节点中的数据达到**最终一致性** 。

​ **谣言模式**：当一个节点**接收到新的数据**的时候，会变成**活跃节点**，然后将数据**向外扩散**，当新的节点收到数据后又会变成新的活跃节点继续向外扩散。

> 注意：谣言模式只会传输新的数据而反熵模式则会将所有的数据进行传输

​ 总结：Gossip 协议的优缺点：

​ 优点：**去中心化**，数据可以很快的在多个分布式服务器之间进行**传播和同步**；**理解性好**；**支持节点数量的动态变化**；

​ 缺点：因为数据的同步可能需要经过多个轮次的传播，所以**会存在数据不一致的问题** ，但是会**达到最终一致性** ；**对网络带宽的消耗比较多**；可能会存在**消息冗余**的问题，**谣言模式中会随机选择节点进行传播**，所以会出现一个节点收到多个相同消息的情况；**不允许存在恶意节点** 。

#### 113、synchronized 和 ReentrantLock 有什么区别？

​ 1.synchronized 是不可中断锁；而 ReentrantLock 是可中断锁

​ 2.synchronized 只支持非公平锁；ReentrantLock 支持公平锁和非公平锁

​ 3.synchronized 是基于 JVM 层面的；ReentrantLock 是基于 API 层面的

​ 4.ReentrantLock 有超时、轮询等功能

#### 114、说一下 Java 中的四种权限修饰符？

​ 1.**public** :**相同包**或者**不同包**下的**所有类**都可以访问

​ 2.**protected** ：**同一个包下的类**都可以访问；**不同包下的子类**可以访问，但是其他类不可以访问

​ 3.**无权限修饰符（default）** ：**只能被同一个包中的类访问**

​ 4.**private** ：**只能被当前类访问**

#### 115、多服务器节点下 Session-Cookie 方案如何做？

​ 1.可以通过**特定的哈希策略**，将**同一个用户的请求转发到固定的机器上**，这样只需要在一台机器上存储该用户的 Session 信息就可以了

​ 2.在**所有服务器上**都存放所有用户的 Session 信息，多个服务器节点会**进行数据的同步**

​ 3.**使用 Spring Session 框架**，可以借助外部的**分布式存储系统**比如**Redis**、**Mongodb**来存储用户的 Session 信息

​

#### 116、什么是 CSRF 攻击和 XSS 攻击？

​ CSRF 攻击：跨站请求伪造，简单来说就是用你的身份发送一些不好的请求。

​ XSS 攻击：跨站脚本攻击，攻击者通过各种方式将恶意代码注入到用户的页面上，来窃取用户的信息

#### 117、为什么 Cookie 不能防止 CSRF 攻击但是 Token 却可以？

​ **Cookie 中携带后端生成的 SessionId**,我们客户端的每次请求都携带这个 Cookie，里面就携带了这个 SessionId 然后由服务端进行验证，CSRF 攻击的话，可以获取到你的 Cookie 中的 SessionId 信息，然后伪装成你发送一些不好的请求。而如果是使用**Token**的话，Token 一般是存储在**localstorage**中的，CSRF 攻击的话，是无法把这个 token 给服务端发送过去的。

#### 118、说一下什么是 OAuth2.0?

​ OAuth2.0 是一个第三方授权协议，是一种规范，一般用来我们接入了第三方的登录系统的时候，比如我们在我们的系统里面接入了允许用户通过微信登陆，然后我们拿着微信开放的用户信息来登录我们的系统，那么我们就需要使用 OAuth2.0 协议了。具体的流程如下：

​ 1.用户从我们系统点击微信登录，跳转到微信 APP 中

​ 2.**微信 APP 会给用户一个授权请求**，用户点击同意授权才会往下走

​ 3.我们系统会拿着用户的授权信息去微信的**授权服务器**去申请授权，微信认证通过了，会给我们系统返回一个**token**

​ 4.我们系统再拿着这个 token 去微信的**资源服务器**，申请获取这个用户的信息

​ 5.微信的资源服务器对这个**token 进行认证**，认证通过后会**把用户的信息给我们系统**

![](https://s3.bmp.ovh/imgs/2024/11/26/336bf3273bdb4a7e.jpg)

#### 119、什么是 JWT？使用 JWT 有什么优缺点？

​ JWT 其实就是一个**JSON 格式的字符串**，用来进行**认证授权**。其中 JWT 由三部分组成：**Header**、**Payload**、**Signature**

​ 其中 Header 里面主要保存使用的**加密算法**、**token 类型**。对结果**使用 Base64 加密后保存**

​ **Payload**里面包含各种声明信息，对结果使用**Base64 加密**后保存

​ Signature 会根据**Header 和 Payload 中的信息**再使用**密钥+Header 中的签名算法**进行签名。

​ 最后这三个字符串中间使用**"."来进行分割**

​ 我们使用 JWT 来进行认证和授权的流程是这样的：

​ 1.客户端填好用户名、密码、验证码后发送请求给服务器

​ 2.服务器进行认证，认证通过后会将**用户的 id、角色等信息放到 payload 中**，然后再根据服务器中存储的密钥来**生成一个 JWT**，发送给客户端

​ 3.客户端一般会将这个 JWT 保存在**localstorage**中，然后后续的请求会**携带这个 JWT 令牌**

​ 4.服务器拿到 JWT 令牌之后，使用服务器中的密钥进行**解密**，解密出来之后，**再根据 Header 和 Payload 中的信息生成一个 JWT 然后和接收到的这个 JWT 进行对比**，来**判断信息是否被篡改**

​ 5.如果没有篡改的话，会通过 Payload 中的用户 id 等信息来获取用户的信息

​ 优点：

​ 1.**无状态，服务端不需要保存 JWT**，只需要保存密钥即可

​ 2.没有使用 Cookie 机制，所以**可以避免 CSRF 攻击**

​ 3.**适合移动端应用**

​ 4.**对单点登录友好**，因为不是使用的 Cookie 机制，所以可以**避免跨域问题**

​ 缺点：

​ 1.如果**在 JWT 的有效期内**，**用户权限和密码修改后可能当前这个 JWT 依然有效**，比如等到过期时间到了之后才会失效

​ 2.**JWT 长度较大，会增加更多的网络开销**

​ 3.**JWT 要考虑续签问题**，我们的过期时间到了之后要考虑合理的续签，可以避免用户需要频繁的登录

#### 120、ArrayList 和 LinkedList 的区别是什么？

​ 1.ArrayList 底层是基于数组的；LinkedList 底层是基于双向链表

​ 2.ArrayList 支持随机访问；LinkedList 不支持随机访问

​ 3.ArrayList 的插入和删除的时间复杂度受位置的影响；LinkedList 如果是头插尾删的话时间复杂度是不受位置的影响的

​ 4.ArrayList 的空间开销浪费在需要在数组的尾部预留出一些空间来；LinkedList 的空间浪费在每个节点都需要比 ArrayList 更多的空间

#### 121、HashSet、LinkedHashSet、TreeSet 的区别是什么？

​ 三者的区别主要是底层的数据结构不同，HashSet 底层是 HashMap,不需要保证顺序，只需要保证唯一性即可；LinkedHashSet 底层是 LinkedHashMap 可以保证 FIFO 的顺序；TreeSet 底层是红黑树，可以保证元素的顺序，可以定制排序。

#### 122、创建线程的几种方式有哪些？

​ 1.通过**线程池**来创建

​ 2.**继承 Thread 类**

​ 3.通过**CompletableFuture**来创建

​ 4.**实现 Callable 接口**

​ 5.**实现 Runnable 接口**

#### 123、说一下 Java 中线程的几种状态？

​ 1.New:创建状态

​ 2.Runnable：就绪状态

​ 3.Blocked:阻塞状态

​ 4.Wait:等待状态

​ 5.Wait-timeout：超时等待状态

​ 6.销毁状态

#### 124、说一下你怎么理解的 AQS？

​ AQS 是抽象队列同步器的简称。内部使用一个**volatile 修饰的 state 来标识共享资源的状态**，当一个线程去申请获取共享资源的时候，会先判断对应的 state 是不是为 0，如果为 0 的话会将对应的共享资源分配给这个线程。如果当前共享资源被占用的话，那么会放到 CLH 中，**CLH 是一个虚拟双向队列**，不是真正的队列实例，而是**将当前线程变成一个节点放到 CLH 队列中**，其中这个节点包括**线程的引用**、**当前节点在队列中的等待状态**、**前驱节点**、**后继节点**。

#### 125、基于 AQS 实现的锁有哪些？

​ ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock

#### 126、只是单纯使用@Async 注解来标注一个方法有什么缺点？

​ 1.无法使用线程池，可能会导致资源耗尽或者性能问题

​ 2.使用@Async 注解标注的方法无法继承调用者的事务

​ 3.@Async 注解标注的方法中出现的异常可能无法被调用者立即捕获，可以会导致异常静默处理或者丢掉

​ 4.调试比较困难

#### 127、ConcurrentHashMap 在 JDK1.7 和 JDK1.8 之间的区别？

​ 1.jdk1.7 之前解决哈希冲突使用了**拉链法**；而 jdk1.8 之后使用了**链表/红黑树**的结构来解决

​ 2.jdk1.7 之前使用**segment 分段锁**来保证线程安全；jdk1.8 之后使用**Node 数组+synchronized+CAS**来保证线程安全，其中**synchronized 只会锁链表/红黑树的首节点**

​ 3.jdk1.7 之前**并发度最大为 Segment 的个数**，**默认为 16**；jdk1.8 之后**并发度是 Node 数组的大小**，并发度更大

#### 128、JVM 中的方法区是干什么的？

​ 方法区会存储**虚拟机已经加载的** **类信息**、**字段信息**、**方法信息** 、**静态变量**、**常量** 等数据

#### 129、JVM 内存模型在 jdk1.7 和 jdk1.8 之后有什么区别？

​ jdk1.7 之前堆分为新生代、老年代、永久代；jdk1.8 之后取消了永久代，在本地内存中多了元空间

#### 130、JVM 中是如何判断两个类是否是同一个类的？

​ 1.类名必须相同

​ 2.两个类的类加载器必须相同

​ 3.两个类的字节码文件必须相同

​ 4.类中的字段、方法、构造函数签名必须相同

#### 131、详细说一下 HashMap 的 put()的过程？

​ 1.**先判断数组是不是为空或者大小是否为 0**，如果**是的话就进行扩容**，否则往下走

​ 2.根据**哈希函数**来**确定在数组中的位置**，如果**该位置是空的直接插入**，**插入后需要判断当前数组中的元素个数是不是大于阈值** ，如果**是的话就进行扩容**，如果**有元素**，**判断这个元素的 key 是不是和自己的 key 相同**，如果**相同直接覆盖**，否则往下走

​ 3.**遍历这个位置的链表**，**依次判断链表中的数据的 key 是不是和自己相同**，**是的话直接覆盖**，不同的话当当前数据插入到链表中；在 jdk1.8 之前使用的是**头插法**，在 jdk1.8 之后使用的是**尾插法**

> 补充：HashMap 中有个属性叫做**负载因子 loadFactor** ,**表示数组中存放数据的疏密程度**。阈值的计算**throldsize=capacity\*loadFactor**

#### 132、Stream 流中终止操作都有什么?

​ 1.foreach

​ 2.toArray

​ 3.collect

​ 4.min、max

​ 5.count

​ 6.limit

#### 133、说一下可重复读隔离级别下的出现幻读的情况？

1. 事务 A 执行 select \* from table where id=5;

   此时是没有数据的，但是事务没有提交

   事务 B 执行 insert into table(id) value(5); 事务 B 提交

   事务 A 去执行 **update** table set name='xxx' where id=5;

   然后事务 A 再去执行 select \* from table where id=5; 发现多了一条数据

2. 事务 A 执行 select \* from table where id>100; 此时查出来一条数据 id=120

   事务 B 执行 insert into table(id) value(200); 事务 B 提交

   事务 A 执行 select \* from table where id>100 **for update** ; 此时多了一条数据 id=200;

#### 134、在最坏的情况下，几种常见的排序算法的时间复杂度为多少？

​ 1.快速排序 O（n²）

​ 2.冒牌排序 O(n²)

​ 3.希尔排序 O(n²)

​ 4.堆排序 O(nlogn)

​ 5.归并排序 O(NlogN)

#### 135、说一下 Redis 中的基本数据类型？以及各自的使用场景

​ 1.String：Redis 是基于 C 语言来实现的，但是 String 没有**使用 C 语言中的字符串**，而是**自定义**了一个数据结构**SDS**。

​ 好处是：**SDS 的 API 是安全的，不会造成缓冲区溢出**；SDS**既可以存储文本数据又可以存储二进制数据**；**获取字符串长度**的时间复杂度为**O(1)**

​ 使用场景：存储 session、token 等信息

​ 2.List:redis 中 list 数据结构是使用**双向链表**来实现的

​ 使用场景：最新文章、最新动态

​ 3.Hash:Redis 中的 Hash 和 Java8 之前的类似，使用**数组+链表** 来实现的

​ 使用场景：存储购物车、商品信息等

​ 4.Set

​ 使用场景：共同关注、共同好友、音乐推荐、好友推荐，抽奖等

​ 5.ZSet

​ 使用场景：直播间送礼排行榜、微信步数排行榜、话题热度排行榜等

#### 136、说一下 Redis 中的三种特殊数据结构以及它们的应用场景是什么？

​ 1.Bitmap: 可以理解为**位数组**

​ 使用场景：用户签到信息、活跃用户情况等

​ 2.HyperLogLog

​ 使用场景：数据量巨大的计数场景，比如热门网站每天/每周/每月的访问 ip 数，热门帖子的 uv 数等

​ 3.GEO：底层基于 ZSet 来实现的

​ 使用场景：附近的人、附近的店推荐等

#### 137、说一下 SSE 机制？

​ SSE 是 server-send-events 的简称。是**服务端主动向客户端推送数据**的一种机制。基于 HTTP 协议实现。

​ SSE 在 HTTP 的基础上，在客户端和服务器之间打开了一个单向通道，服务端响应的不再是客户端发来的一次性的数据包而是**text/event-stream**事件流，当有数据变更的时候，服务器端就会将数据推送给客户端。

​

#### 138、SSE 和 WebSocket 的区别？

​ 1.SSE 的开发成本低，WebSocket 的开发成本比较高

​ 2.SSE 是基于 HTTP 协议的，**不需要单独的协议或者服务器来处理**；而 WebSocket 是**需要单独的服务器来处理协议**的

​ 3.SSE**默认支持断线重连**，而 WebSocket 需要手动实现

​ 4.SSE 是**单向**的，又服务器给客户端推送数据；WebSocket 是**全双工**的，客户端和服务器都可以发送和接收数据

​ 5.SSE**只能传输文本信息**，对于二进制数据需要编码后传输；WebSocket 支持二进制数据的传输

#### 139、说一下 Dubbo 中的几个角色是什么？

​ 1.Container：服务运行容器，负责加载和运行服务提供者。

​ 2.Provider: 服务提供者

​ 3.Consumer:服务消费者

​ 4.Registry:服务注册与发现的注册中心。服务提供者将地址注册到注册中心，注册中心将服务提供者的地址列表推给消费者。当一个服务提供者宕机或者下线的时候，注册中心会给消费者发送消息。

​ 5.Monitor:监控者。统计服务调用的次数和时间。

#### 140、说一下 Dubbo 中的 SPI 机制?然后举个例子？

​ 我们将**实现类**放到**配置文件**中，程序在运行的时候会**读取配置文件**，然后通过**反射**机制来加载实现类。

​ 比如我们通过 SPI 实现一个自定义的负载均衡策略的话，我们自定义一个 XXXLoadBlance 类，实现 LoadBlance 接口，然后在这个类中实现自己的逻辑，然后将这个**类的路径**放到**META-INFO**下面的 LoadBlance 文件中即可。

#### 141、JDK8 之后 HashMap 在解决哈希冲突的时候会使用链表+红黑树来实现，那么红黑树会退化成链表吗？

​ 当红黑树的**节点个数小于 6**的时候，会由红黑树退化为链表。

​

#### 142、说一下 Dubbo 中的负载均衡策略有哪些？

​ 1.**加权随机负载均衡**

​ 2.**最小活跃数优先**的负载均衡，对于服务提供者来说，每收到一个请求活跃数就加一，执行完之后活跃数减一

​ 3.**一致性哈希负载均衡**，Dubbo 为了解决数据倾斜问题，引入了虚拟节点

​ 4.**加权轮询负载均衡**，按照权重进行轮询负载均衡

#### 143、说一下你了解的内存泄露的场景？

​ 1.**各种连接没有及时关闭**：比如数据库连接、网络连接等

​ 2.**ThreadLocal 使用不当**，用完没有及时删除

​ 3.**当一个变量的作用域超出其使用范围，可能会导致被持续引用而无法回收**

​ 4.**如果一个对象使用完成之后没有设置为 null,可能会导致无法进行垃圾回收**

​ 5.我们将对象放到了**静态集合**中，**使用完毕后没有及时从静态集合中删除**

#### 144、说一下什么是分布式事务？

​ 我们一个系统可能会被**拆分**为**多个**不同的**服务**，每个服务可能又会有**各自的数据库**。我们的一组操作可能会涉及到多个服务，而又会**涉及到多个数据库**，所以导致产生了分布式事务。另外，**分库分表**的场景也会导致分布式事务的产生。

#### 145、什么是柔性事务？什么是刚性事务？

​ **柔性事务**简单的来说就是追求**最终一致性** 。**刚性事务**简单的来说就是追求**强一致性** 。

​ 柔性事务常见的方案：TCC、MQ 事务、本地消息表

​ 刚性事务常见的方案：2PC（两阶段提交）、3PC（三阶段提交）

#### 146、说一下 2PC 和 3PC 中的几种角色？

​ 1.AP：应用程序本身。

​ 2.RM：资源管理器，事务的参与者，一般就是指数据库

​ 3.TM：事务管理器，负责管理全局事务，给分布式事务分配唯一标识、监控事务的执行进度、负责事务的提交、回滚、失败恢复等

#### 147、说一下 2PC 的过程？

​ **准备阶段**

​ 1.TM 给所有的 RM 发送 prepare 消息

​ 2.所有的 RM 收到消息后，开始执行本地数据库事务预操作，比如写 redo log/undo log，**注意不会真的去提交事务**，然后给 TM 返回 YES/NO 结果

​ 3.如果 TM 收到有 RM 返回了 NO 的话，就给所有的 RM 发送 Rollback 消息，所有 RM 收到 Rollback 消息后，将事务回滚，并释放资源

​ **提交阶段**

​ 1.如果所有的 RM 都给 TM 返回了 YES 的话，TM 给所有的 RM 发送 commit 消息

​ 2.所有 RM 收到 Commit 消息后，进行本地数据库事务的提交，执行完成之后将资源释放，并给 TM 返回 ACK 消息

​ 3.当 TM 收到所有的 ACK 消息之后，分布式事务结束

​ 2PC 的优缺点：

​ 优点：常见的数据库如 MySQL、Oracle 都有自己的实现；针对的是数据的强一致性

​ 缺点：依然会导致数据不一致性问题，比如在 Commit 阶段，TM 给部分 RM 发送 commit 消息后宕机了，会导致剩余的 RM 没有进行事务的提交；如果 TM 在 prepare 阶段之后宕机了，那么所有的 RM 会阻塞在 Commit 阶段；在 RMComimt 之前会一直占有着资源

#### 148、说一下 3PC 的过程?

​ **CanCommit 阶段**

​ 1.TM 给所有的 RM 发送 CanCommit 消息，询问 RM 能否执行本地数据库事务

​ 2.RM 收到 CanCommit 消息后，给 TM 返回 YES/NO，或者超时未回复

​ **PreCommit 阶段**

​ 1.TM 收到所有 RM 在 CanCommit 阶段返回的 YES 后，给所有的 RM 发送 PreCommit 消息

​ 2.RM 收到 PreCommit 消息后，进行本地数据库事务的预提交阶段，比如写 redo log/undo log 日志，并给 TM 返回 YES/NO 或者超时未回复

​ 3.如果在 PreCommit 阶段，TM 收到了 NO 或者超时未回复消息，那么 TM 给所有的 RM 发送 Abort 消息

​ 4.RM 收到 Abort 消息后，中断事务，并释放资源。分布式事务结束

​ **DoCommit 阶段**

​ 1.所有 RM 在 PreCommit 阶段都给 RM 返回了 YES 消息后，TM 给所有的 RM 发送 DoCommit 消息

​ 2.RM 收到 DoCommit 消息后，进行本地数据库事务的提交，并给 TM 返回 YES/NO/超时未回复

​ 3.如果 TM 收到了 NO 或者超时未回复消息的话，给所有的 RM 发送 Abort 消息

​ 4.RM 收到 Abort 消息后，进行本地数据库事务的回滚，并释放资源。分布式事务结束

​ 5.如果 RM 在 PreCommit 之后，在超时时间内未收到 TM 发送的 DoCommit 消息，那么会自动进行本地数据库事务的提交

#### 149、说一下什么是 TCC 以及它的执行过程？

​ TCC 是补偿事务的简称，是 Try、Confirm、Cancel 三个阶段的简称。

​ 1.Try 阶段：尝试执行。会**预留**所需要的业务资源。

​ 2.Confirm 阶段：当 Try 阶段成功之后，会执行 Confirm 阶段，去操作 Try 阶段预留的业务资源。

​ 3.Cancel 阶段：当 Try 阶段失败会执行 Cancel，去释放预留的业务资源。

​ TCC 的 Try、Confirm、Cancel 阶段的代码都需要我们自己实现，所以属于业务侵入方案。

​ TCC 在 Try 阶段失败后会执行 Cancel 阶段，当在 Confirm 和 Cancel 阶段失败后，会**记录事务日志并进行持久化**，然后针对 Confrim 和 Cancel 阶段进行重试，通常**重试次数为 6 次**，当重试后还没有成功则需要进行人工介入，当执行成功了，那么对应的事务日志则可以进行删除了。

#### 150、说一下 TCC 和 2PC 的区别？

​ 1.2PC 是需要**依赖于数据库层面的事务**的，而 TCC 是**基于代码**的

​ 2.2PC 在**Commit 之前**会**一直持有资源**，会造成阻塞，而 TCC 是**不会一直持有资源的**

​ 3.2PC 不会对业务代码**有侵入**，而 TCC**不会**对业务代码有侵入

​ 4.2PC 追求的是**强一致**，而 TCC 追求的是**最终一致**

#### 151、说一下柔性事务中的 MQ 事务？

​ MQ 事务简单来说就是将生产消息、处理、消费做成一个原子操作。

​ 下面基于 RocketMQ 来说一下 MQ 事务的过程：

​ 1.生产者先给 Broker 发送一个半消息，这个消息消费者是看不到的

​ 2.生产者执行本地事务，然后根据本地事务的执行结果给 Broker 发送 Commit/Rollback 消息

​ 3.如果 Broker 收到了 Rollback 消息，则将半消息删除，如果收到了 Commit 消息，则对消费者可见

​ 4.Broker 在一定时间内如果没有收到生产者发来的 Commit/Rollback 消息的话，会去生产者中**反查**事务的执行结果，然后生产者给 Broker 发送 Commit/Rollback 消息

​ MQ 事务的执行流程图如下：

​ ![](https://s3.bmp.ovh/imgs/2024/08/25/9444b74ddf5abbfd.png)

#### 152、说一下你自己对于 DDD 的理解？

​ DDD 是用来**控制复杂度**的。复杂度可以分成两类，一类是业务复杂度，另一类是技术复杂度。

​ 针对业务复杂度来说，主要体现在两方面:

​ 一方面是**业务流程复杂度**，针对流程很复杂的情况，我们一般可以**针对流程使用结构化分解**，使用 Compose Method Parrten(**组合方法模式**)来进行流程的结构化分解

​ 另一方面是业务概念复杂度，针对这个复杂度我们一般就是需要进行**统一语言**（主要体现在命名规范统一）、**领域建模**、**架构规划**

​ 我们在需求分析之后，会针对这个系统进行**领域划分**，将系统分成不同的**域**，然后我们在每个**域中进行建模**，常见的用来进行建模的方法有**用例分析法**、**四色建模法**、**事件风暴**等。

​ 建好领域模型之后，我们**再去开发对应的业务逻辑**。

#### 153、说一下如何优化深度分页查询？

​ 查询偏移量过大的场景，我们称之为深度分页。比如

```sql
select * from table1 order by id limit 1000000,10;
```

​ 优化方案：

​ 1.通过**子查询来优化**，比如

```sql
select * from table where id>=(select id from table limit 1000000,1) limit 10;
```

​ 2.如果 id 是**有序**的话，可以通过**范围查询**来优化

```sql
select * from table where id>=1000000 and id<=1000010 order by id;
```

​ 3.使用延迟关联，也就是 inner join 的方式

```sql
select t1.* from table t1 inner join (select id from table limit 1000000,10) t2 on t1.id=t2.id;
```

#### 154、说一下 Redis 主从复制的过程？

​ 1.slave 给 master 发送一个数据同步的请求 sync

​ 2.master 收到请求后，通过 BGSAVE 命令 fork 出一个子线程去生成 RDB 文件

​ 3.master 将 RDB 文件发送给 slave

​ 4.slave 接收到 RDB 文件之后，读取并解析执行，此时 slave 达到了 master 执行 BGSAVE 的时候的状态

​ 5.master 会使用一个缓冲区保存 BGSAVE 之后接收到的写命令，然后将这些命令发送给 slave

​ 6.slave 执行收到的命令，完成和 master 的同步

​ 7.slave 通过和 master 维护的长连接来进行命令传播，完成数据的同步

#### 155、Redis 主从复制中读从机会读到过期的数据吗？

​ 是有可能读到过期数据的。比如我们在 master 中通过 expire 命令设置了 TTL 为 3s,但是因为网络延迟等各种原因，slave 同步数据发生了延迟，当 slave 收到数据后，可能 master 中的 TTL 已经过去了一段时间，那么会导致 master 中的 key 已经过期了，但是在 slave 中可能还没有过期。解决方案：使用 expireAT 命令来设置 TTL，设置的不是秒/毫秒，而是 UNIX 时间，这样就不会出现因为延迟同步导致的读取到过期的 key 了。

#### 156、什么是 Redis 的 Sentinel 模式？

​ 其实就是在主从复制模式中增加了一个 Sentinel(哨兵)的角色来监控 Redis 节点的运行状况，并帮助我们完成故障转移。

​ Sentinel 模式下，我们为了保证 Sentinel 的**高可用**和**容错性**，一般是会部署多台 Sentinel 节点的，可以防止一台 Sentinel 对 master 的误判导致发生的故障转移；也可以防止因为单台 Sentinel 宕机导致的 Sentinel 模式不可用的情况

#### 157、说一下什么是 Sentinel 模式中的主观下线和客观下线？

​ Sentinel 模式中，每个 Sentinel 节点每秒中是会给 Redis 集群中其他所有的节点发送 PING 请求，如果在规定的时候内没有收到合理的响应，那么该 Sentinel 节点就会认为对应的服务器下线了，这是**主观下线**，简单的来说就是**自己认为对象下线了**。如果有超过半数以上的 Sentinel 节点认为一个节点下单了，那么就称之为**客观下线**。

#### 158、Redis Sentinel 模式中是如何进行故障转移的？

​ 当有超过半数以上的 Sentinel 节点认为 master 宕机了，那么就会进行故障转移，首先**Sentinel 集群中会通过 Raft 算法来选举一个 Leader**让这个 Sentinel 节点负责故障转移。在进行故障转移的时候，Sentinel 会按照下面的三种方式来决定哪个 slave 是新的 master

​ 1.**优先级**：可以对每一个 slave 节点设置一个优先级，**数字越小优先级越高**

​ 2.如果优先级相同，则按照**与 master 的同步程度来选择**。优先选择与 master**同步程度高**的 slave 作为新的 master

​ 3.如果上面的两个都相同，则**选择 runid 小的**slave 作为新的 master

​

#### 159、红黑树与二叉平衡树相比有啥好处？

​ 1.红黑树追求的是**相对平衡**，只需要保证黑节点平衡，而二叉平衡树追求的是**绝对平衡**

​ 2.红黑树插入一个节点**最多只会进行三次旋转**就可以达到平衡，而二叉平衡树则**不确定旋转次数**

​ 3.红黑树的实现没有二叉平衡树那么严格，所以**红黑树的实现比较简单**

#### 160、jdk8 之后在解决哈希冲突的时候增加了红黑树的结构，相比链表来说有啥好处？

​ 1.红黑树在查询、插入、删除的时候，时间复杂度为 O(logn)；而链表的查询时间复杂度为 O(n)

​ 2.如果只使用链表的话，**当链表的长度太长的时候会导致查询效率急速下降**，使用**红黑树则可以提高查询效率**

​ 3.使用**红黑树**可能会**节省更多的内存空间**，虽然红黑树中每个节点多个颜色，但是树的高度一般是小于节点个数的

#### 161、Redis Cluster 中是如何确定 key 对应的哈希槽的？

​ 首先对这个 key 使用**CRC16 算法**得到一个校验值，然后用这个校验值**对 16384 进行取模**。

#### 162、Redis Cluster 中为什么使用 16384 个哈希槽而不是使用 65536 个哈希槽？

​ 1.Redis Cluster 中各个节点之间是需要**发送心跳包**的，如果使用 16384 个槽心跳包的大小只有 4k,如果使用 65536 个槽则心跳包的大小是 8k，使用 16384 个槽可以减少网络带宽

​ 2.Redis Cluster 中节点不会超过 1000 个，所以没有必要使用 65536 个槽

​ 3.哈希槽个数越少，对存储哈希槽信息的 bitmap 的压缩效果越好

#### 163、当 Redis Cluster 在进行动态扩容和缩容的时候，可以对外提供服务吗？如果可以说一下过程？

​ **可以对外提供服务**

​ 在进行扩容和缩容的时候，会出现哈希槽重新分配的情况，此时访问 key 的过程如下：

​ 1.如果 key 在重新分配哈希槽后没有发生变化，那么可以直接做出响应

​ 2.如果 key 在重新分配之后还没有迁移走，那么也是可以直接做出响应的

​ 3.如果 key 在迁移的过程中，会返回 ASK 错误码。客户端收到 ASK 错误码和新节点的地址之后,会给新的节点发送 ASKING 请求

​ 4.客户端给新节点发送命令请求，但是此时依然是临时重定向的，后续对这个 key 的请求还是发送给原节点的

​ 5.当 key 已经完成数据迁移之后，会返回 MOVED 错误码，说明发生了永久重定向，客户端以后对这个 key 的请求会发送给新的节点

> 补充： ASK 重定向：临时重定向，后续对 key 的请求还是会发给原节点
>
> ​ MOVED 重定向：永久重定向，后续对 key 的请求发送给新的节点

#### 164、说一下什么是 RestFul API

​ 通俗简单的来说其实就是通过 url+http method 就知道这个请求要干什么，客户端通过服务端返回的 HTTP 状态码就知道结果如何。

​ Rest Ful 的架构可以总结为下面的三条：

​ 1.每一个 URI 代表一种资源

​ 2.客户端和服务器使用某种表现形式来传输资源，比如 json、xml、image、text 等

​ 3.客户端通过 HTTP 动词，对服务器中的资源进行操作

#### 165、Redis 的字符串为什么没有使用 C 语言自带的字符串而是自定义了结构体 SDS

Redis 自定义的数据结构 SDS，它的结构体如下

```c
struct sdshdr{

  int free; // buf[]数组未使用字节的数量

  int len; // buf[]数组所保存的字符串的长度

  char buf[]; // 保存字符串的数组
}
```

1. SDS 中使用 len 字段直接保存了字符串中的字符的长度，所以对于需要获取字符串长度的时间复杂度 SDS 是 O(1),而 C 语言的是需要遍历一遍的是 O(n)

2. C 字符串只能保存文本数据，SDS 字符串也可以保存二进制数据

3. C 字符串的长度是固定的，每次修改字符串的长度都会引起内存的重新分配，而内存的重分配是比较耗时的；而 SDS 字符串有两种内存重分配策略，很好的解决了字符串在增长和缩短时候的内存分配问题

   3.1 空间预分配
   针对字符串增长的操作，空间预分配策略不仅分配修改需要的字符串长度，还会额外分配未使用的 free 的长度。当再次进行修改时，判断如果发现 free 够用就不需要重新进行空间分配了。

   3.2 惰性空间释放
   针对字符串缩短的操作，惰性空间释放策略不会立即将内存空间回收，而是修改 free 的大小，用 free 记录下来，当字符串增长的时候可以直接使用这个 free

#### 166、Redis 持久化方式 AOF 的重写过程

1. 主进程检测到 AOF 文件大小达到了**阈值** ，触发 AOF 重写
2. 主进程**fork 出一个子进程** ，由子进程去执行 AOF 重写的操作
3. 子进程去遍历主进程中所有的键值对生成一个新的 AOF 文件，**同时主进程依然去执行新来的 Redis 命令**，并将新到的命令写入到**AOF Rewrite Buffer**中
4. 子进程完成了快照时刻的 AOF 重写，通知主进程
5. 主进程去将 AOF Rewrite Buffer 中的命令**追加到新的 AOF 文件中**，然后删除旧的 AOF 文件，用新的 AOF 文件

#### 167、说一下 Spring 中的事务传播机制？

1. 默认的事务传播机制：**PROPAGATION_REQUIRED**

​ 如果当前存在事务的话就加入该事务，如果当前不存在事务的话创建一个新事务。

2.  **PROPAGATION_SUPPORTS**

如果当前存在事务则加入该事务；如果当前不存在事务则以非事务方式执行。

3. **PROPAGATION_MANDATORY**

   如果当前存在事务则加入该事务；如果当前不存在事务则抛出异常。

4. **Propagation.REQUIRES_NEW**

   创建一个新事务，如果当前存在事务则**挂起**当前的事务。

5. **Propagation.NOT_SUPPORTED**

   以非事务方式执行，如果当前存在事务则将当前的事务**挂起**。

6. **Propagation.NEVER**

   以非事务的方式执行，如果当前存在事务则抛出异常。

7. **Propagation.NESTED**

   如果当前存在事务，则在**嵌套事务**内执行；如果当前不存在事务，则创建一个事务。

#### 166、 为什么要分 MVC 三层开发？

1. 提高代码的可复用性：

   我们进行分层开发，我们的 repository 层对于持久层的操作可以被多个 service 来复用，service 又可以被多个 controller 复用。

2. 可以更好的遵循单一职责原则

   分层开发各个层可以更好的各司其职，controller 就负责和外部请求打交道，对参数进行校验，进行实体转换，而不需要关心具体的业务逻辑，不需要关心和持久层的交互问题。

   service 层就专门负责进行业务逻辑的处理，不需要关心数据的来源。

   repository 层就只需要关心和持久层的交互就可以了

3. 分层能起到隔离变化的作用

   如果我们的持久层从 MySQL 换成了 Oracle 又换成了 Redis,分层后只需要修改 repository 层，对于 service 层和 controller 来说是不需要改变的，他们也不用去关心底层具体是如何实现和持久层进行交互的

4. 能更好的应对复杂性

5. 能提高代码的可测试性

6. 能更好的进行封装和抽象

#### 167、你在工作中进行过线上 JVM 调优吗？说一下你是怎么做的？

答：线上的问题其实可以归结为两大类问题，第一类问题是**CPU 飙升甚至长期达到 100%**；第二类问题就是**内存泄漏导致 OOM 或者内存大量使用问题**

**针对 CPU 飙升问题**：

针对 CPU 飙升问题又可以从两个方面来思考，第一个方面是：**代码质量问题导致 CPU 飙升**，比如死循环等；第二个方面是：**频繁 GC 导致 CPU 飙升**

具体排查步骤一般是：

① 执行**top 命令**去查看 CPU 占用高的进程，此时我们**定位到了进程级别**了

② 执行**top -Hp [进程 id]**来查看这个进程里面 CPU 占用高的线程是什么，但是这个命令给我们返回来的结果我们要记得转成 16 进制，因为下面会用到，到目前为止我们已经**定位到了线程级别**了。

③ 执行**jstack [进程 id] > [文件名]**，将你的这个进程的**栈调用信息**打印出来，但是这个文件中存放的线程 id 是十六进制的，所以可以用第二步得到的线程 id 进行搜索了

④ 定位到线程之后，你可以看一下线程的状态，如果线程状态是**Runnable**，大概率是代码质量问题，比如**死循环、复杂计算、高频方法调用**，你可以仔细看一下栈信息，里面会打印出来代码的行数，你可以去代码中进行定位。如果线程的状态是**Blocked/Waiting**，那你你就要考虑是不是因为锁竞争或者出现死锁问题了

⑤ 如果线程大量出现**GC task thread 状态**，那么你就要考虑是否是频繁 GC 导致的问题了。

⑥ 如果你怀疑是频繁 GC 导致的问题，那么你可以执行命令**jstat -gc [进程 id] 1000 5**,这个命令的意思是每 1 秒打印一次进程的 GC 情况，打印 5 次，通过 jstat 命令打印的结果中，可以看到各个内存空间的使用情况以及 YongGc、Full GC 的次数和时间

> 我在工作中还真遇到了一次 CPU 飙升的问题，具体来说就是使用了 Disruptor 然后没有合理的设置等待策略，我设置的等待策略是让步等待策略（YieldWaitStrategy）导致大量占用 CPU,CPU 基本一直保持 100%，导致这个机器的其他的服务直接不跑了，但是我们的系统必须要保证 Disruptor 这个服务的性能，所以我们最终的解决方案是将 Disruptor 服务单独部署服务器，这个服务器只部署 Disruptor 服务，不部署其他的服务，部署了其他的服务，其他服务基本得不到 CPU 的调用机会

总结：相对来说，CPU 飙升问题的定位是比较简单的。

**针对 OOM 类型或者是内存大量使用问题**：

首先我们一般在运行 jar 程序的时候都会增加打印 OOM 异常的 dump 的命令的，具体来说就是

> -XX:+HeapDumpOnOutOfMemoryError
>
> -XX:HeapDumpPath=xxx

在遇到内存大量占用甚至出现 OOM 问题的时候，**第一步肯定是打印日志快照**，比如**通过 jmap dump 命令将堆信息 dump 下来**，然后还需要将此时的**栈调用信息**导出来，也就是需要结合**jstack 命令**，然后再借助于**jstat 命令来将一段时间的 GC 信息打印出来**。上面的这三个主要的日志打印出来之后我们就可以快速进行问题处理了，比如重启服务器、将服务器从网关中摘除掉等，然后我们再离线慢慢的分析出现 OOM 的问题是什么。

一般都可以先借助**堆分析可视化工具**，比如**MAT**、**在线网站 fast thread(推荐)**来分析一下堆信息，他们会自动给出他们认为的问题点。

常见的 OOM 一般有四种情况

1. java.lang.OutOfMemoryError: Java heap space
2. java.lang.OutOfMemoryError: Metaspace
3. java.lang.OutOfMemoryError: GC overhead limit exceeded
4. java.lang.OutOfMemoryError: Direct buffer memory

这四种不同的类型的 OOM 一般分析思路也是不一样的。

最常见的问题应该是 Java heap space OOM 和 GC overhead limit exceeded OOM，这两类可以等价为一样的，都是堆内存不足了。

首先遇到这类问题，我们要先**结合 jstat 命令的日志看一下是不是老年代占用很大，然后 Full GC 之后老年代降不下来**。如果是这样的话要先考虑一下**是不是有强引用一直得不到释放，或者静态集合一直不释放**。

具体的可能要去看是修改代码还是适当的扩大一下堆内存的空间

针对元空间 OOM 的类型一般都是类太多导致的，我目前没有遇到过这类问题。但是你可以用下面几个角度考虑：**缓存代理类、禁用热加载、修复 ClassLoader 泄漏、限制脚本动态生成**

针对 Direct buffer memory OOM，这类问题是**堆外内存不足**导致的，一般是需要我们**限制一下直接内存的大小**的。

::: tip
我在公司中一共遇到了两次 OOM,两次 OOM 都是 java heap space OOM 类型的 OOM。

第一次的问题定位是用户导入了一个超大 excel 文件，后端在加载的时候没有分批处理，而是一次性将所有的数据加载到内存中直接导致 OOM 了，对象太多了，存不下了

第二次的问题定位是 Snail Job 这个定时任务框架打印了太多的日志导致的 OOM，原因是开发在代码中将大量的查询的结果打印到 Snail job 的日志中了。

首先在定位问题的时候，会先看一下此时的 JVM 的内存空间分配是不是大小不是很小，如果不是很小的话就要去结合 jstack 导出来的栈信息去看一下代码问题，然后考虑是修改代码还是适当的调大一下堆内存，我们上面的两个都是修改的代码，而不是调整的堆内存大小。

现在随着 JVM 的发现，其实 JVM 调优更简单了，基本上都使用默认的参数就够用了。

:::

#### 168、 Nginx 高性能的原理是什么

1. **Nginx 使用 Master-Worker 多进程模式**
2. **基于 epoll 的事件驱动**
3. **使用了协程**
4. **可以使用零拷贝来优化磁盘 I/O**

下面我画了一个 Nginx 的简单的原理图

![Nginx高性能原理.png](https://s3.bmp.ovh/2026/01/29/Xs4xlQjV.png)

下面我会基于这个图来说一下高性能的原理：

首先 Nginx 采用了**Master-Worker 多进程的进程模式**，有一个 Master，他可以管理多个 Worker,这个 Worker 的数量是你自己可以设置的，**一般不要超过 CPU 的核数**。**Master 进程不处理请求，真正的工作进程是 Worker 进程**。

**每一个 Worker 进程都是单线程的**，为什么设计单线程呢？因为**可以避免锁竞争+上下文切换**。虽然 Worker 进程是单线程的但是**一个 Worker 可以连接多个 Scoket**，这个 Socket 的数量也是你自己可以设置的。在 Worker 和 Socket 的连接这里就使用了**多路复用模型**。

**Worker 进程是运行在用户态的**。**Socket 是运行在内核态的**。

在 Linux 系统中，Nginx 的 Worker 进程会使用**epoll 给内核态发送一个请求询问内核态是否有 Socket 就绪**，但是发送完成之后**Worker 进程并不会阻塞**在这里等待内核态的返回而是可以继续执行其他任务。当内核态的**任一 Socket 就绪之后**会使用**epoll 的通知机制**来通知用户态的 Worker 进程数据就绪，用户态的 Worker 接收到 epoll 通知后就会处理 Socket 的请求。

虽然每个 Worker 是单线程运行的，但是**线程内部使用了协程来提高效率**。

::: tip info

补充：

协程比线程高性能的原因是什么：当协程遇到阻塞之后会自己**主动释放**，然后其他的协程接着跑，而线程遇到阻塞之后不会自己主动释放需要**等待 CPU 调度**。所以协程阻塞后会迅速切换另一个协程去执行任务，而线程咋会卡在这里浪费时间。

**epoll: Linux 提供的一种高效 I/O 多路复用机制，用来在单线程中同时监听大量文件描述符的就绪事件。**

:::
